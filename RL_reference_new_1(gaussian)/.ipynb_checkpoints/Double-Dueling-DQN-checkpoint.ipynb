{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe15f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe15f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe15f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe15f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4abe1080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4abe10f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a1c9128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a1c9128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a1c9128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a1c9128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10ada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10ada0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10ada0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10ada0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10aeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10aeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10aeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10aeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10abe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10abe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10abe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f8c4a10abe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8c4a10a908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 -0.1 1\n",
      "1000 1.1 1\n",
      "1500 1.2 1\n",
      "2000 -1.6 1\n",
      "2500 -0.1 1\n",
      "3000 -0.3 1\n",
      "3500 -0.6 1\n",
      "4000 0.3 1\n",
      "4500 -0.2 1\n",
      "5000 0.8 1\n",
      "5500 -0.4 1\n",
      "6000 0.2 1\n",
      "6500 1.4 1\n",
      "7000 0.3 1\n",
      "7500 1.1 1\n",
      "8000 -0.2 1\n",
      "8500 0.1 1\n",
      "9000 0.1 1\n",
      "9500 0.8 1\n",
      "10000 0.4 1\n",
      "10500 0.8 0.9549999999999828\n",
      "11000 -0.1 0.9099999999999655\n",
      "11500 1.0 0.8649999999999483\n",
      "12000 0.0 0.819999999999931\n",
      "12500 -0.8 0.7749999999999138\n",
      "13000 -0.3 0.7299999999998965\n",
      "13500 1.0 0.6849999999998793\n",
      "14000 0.3 0.639999999999862\n",
      "14500 -0.6 0.5949999999998448\n",
      "15000 -0.5 0.5499999999998275\n",
      "15500 -0.1 0.5049999999998103\n",
      "16000 -0.2 0.4599999999998177\n",
      "16500 0.6 0.41499999999982823\n",
      "17000 0.6 0.36999999999983874\n",
      "17500 0.3 0.32499999999984924\n",
      "18000 0.3 0.27999999999985975\n",
      "18500 0.1 0.23499999999986562\n",
      "19000 0.2 0.18999999999986225\n",
      "19500 -0.1 0.14499999999985888\n",
      "20000 -0.5 0.09999999999985551\n",
      "20500 0.1 0.09999999999985551\n",
      "21000 0.2 0.09999999999985551\n",
      "21500 -0.3 0.09999999999985551\n",
      "22000 0.5 0.09999999999985551\n",
      "22500 0.1 0.09999999999985551\n",
      "23000 0.7 0.09999999999985551\n",
      "23500 0.6 0.09999999999985551\n",
      "24000 0.1 0.09999999999985551\n",
      "24500 0.3 0.09999999999985551\n",
      "25000 0.0 0.09999999999985551\n",
      "25500 0.0 0.09999999999985551\n",
      "26000 0.1 0.09999999999985551\n",
      "26500 0.0 0.09999999999985551\n",
      "27000 0.2 0.09999999999985551\n",
      "27500 -0.1 0.09999999999985551\n",
      "28000 1.0 0.09999999999985551\n",
      "28500 0.2 0.09999999999985551\n",
      "29000 0.6 0.09999999999985551\n",
      "29500 -0.3 0.09999999999985551\n",
      "30000 -0.3 0.09999999999985551\n",
      "30500 0.1 0.09999999999985551\n",
      "31000 0.0 0.09999999999985551\n",
      "31500 0.1 0.09999999999985551\n",
      "32000 0.0 0.09999999999985551\n",
      "32500 -0.1 0.09999999999985551\n",
      "33000 0.2 0.09999999999985551\n",
      "33500 -0.2 0.09999999999985551\n",
      "34000 0.3 0.09999999999985551\n",
      "34500 0.2 0.09999999999985551\n",
      "35000 0.5 0.09999999999985551\n",
      "35500 0.8 0.09999999999985551\n",
      "36000 0.2 0.09999999999985551\n",
      "36500 0.1 0.09999999999985551\n",
      "37000 0.3 0.09999999999985551\n",
      "37500 -0.1 0.09999999999985551\n",
      "38000 0.4 0.09999999999985551\n",
      "38500 0.4 0.09999999999985551\n",
      "39000 0.2 0.09999999999985551\n",
      "39500 0.7 0.09999999999985551\n",
      "40000 0.6 0.09999999999985551\n",
      "40500 0.5 0.09999999999985551\n",
      "41000 0.8 0.09999999999985551\n",
      "41500 0.1 0.09999999999985551\n",
      "42000 0.5 0.09999999999985551\n",
      "42500 0.5 0.09999999999985551\n",
      "43000 1.0 0.09999999999985551\n",
      "43500 0.0 0.09999999999985551\n",
      "44000 0.5 0.09999999999985551\n",
      "44500 0.7 0.09999999999985551\n",
      "45000 -0.1 0.09999999999985551\n",
      "45500 0.1 0.09999999999985551\n",
      "46000 -0.2 0.09999999999985551\n",
      "46500 0.9 0.09999999999985551\n",
      "47000 1.8 0.09999999999985551\n",
      "47500 0.8 0.09999999999985551\n",
      "48000 0.0 0.09999999999985551\n",
      "48500 0.2 0.09999999999985551\n",
      "49000 1.2 0.09999999999985551\n",
      "49500 0.8 0.09999999999985551\n",
      "50000 0.4 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.2 0.09999999999985551\n",
      "51000 0.5 0.09999999999985551\n",
      "51500 1.2 0.09999999999985551\n",
      "52000 0.9 0.09999999999985551\n",
      "52500 0.2 0.09999999999985551\n",
      "53000 1.2 0.09999999999985551\n",
      "53500 0.7 0.09999999999985551\n",
      "54000 1.0 0.09999999999985551\n",
      "54500 1.0 0.09999999999985551\n",
      "55000 0.0 0.09999999999985551\n",
      "55500 0.2 0.09999999999985551\n",
      "56000 0.8 0.09999999999985551\n",
      "56500 0.4 0.09999999999985551\n",
      "57000 2.1 0.09999999999985551\n",
      "57500 1.0 0.09999999999985551\n",
      "58000 0.9 0.09999999999985551\n",
      "58500 0.9 0.09999999999985551\n",
      "59000 0.3 0.09999999999985551\n",
      "59500 0.8 0.09999999999985551\n",
      "60000 0.1 0.09999999999985551\n",
      "60500 1.0 0.09999999999985551\n",
      "61000 2.1 0.09999999999985551\n",
      "61500 1.0 0.09999999999985551\n",
      "62000 1.5 0.09999999999985551\n",
      "62500 1.0 0.09999999999985551\n",
      "63000 0.4 0.09999999999985551\n",
      "63500 0.8 0.09999999999985551\n",
      "64000 1.4 0.09999999999985551\n",
      "64500 1.2 0.09999999999985551\n",
      "65000 0.9 0.09999999999985551\n",
      "65500 1.5 0.09999999999985551\n",
      "66000 1.9 0.09999999999985551\n",
      "66500 0.5 0.09999999999985551\n",
      "67000 2.1 0.09999999999985551\n",
      "67500 1.0 0.09999999999985551\n",
      "68000 1.7 0.09999999999985551\n",
      "68500 2.2 0.09999999999985551\n",
      "69000 4.1 0.09999999999985551\n",
      "69500 2.4 0.09999999999985551\n",
      "70000 1.5 0.09999999999985551\n",
      "70500 2.0 0.09999999999985551\n",
      "71000 1.8 0.09999999999985551\n",
      "71500 2.1 0.09999999999985551\n",
      "72000 2.4 0.09999999999985551\n",
      "72500 1.9 0.09999999999985551\n",
      "73000 3.2 0.09999999999985551\n",
      "73500 2.0 0.09999999999985551\n",
      "74000 2.2 0.09999999999985551\n",
      "74500 2.4 0.09999999999985551\n",
      "75000 2.4 0.09999999999985551\n",
      "75500 2.8 0.09999999999985551\n",
      "76000 2.3 0.09999999999985551\n",
      "76500 3.7 0.09999999999985551\n",
      "77000 2.3 0.09999999999985551\n",
      "77500 3.9 0.09999999999985551\n",
      "78000 2.8 0.09999999999985551\n",
      "78500 2.1 0.09999999999985551\n",
      "79000 3.5 0.09999999999985551\n",
      "79500 2.6 0.09999999999985551\n",
      "80000 3.6 0.09999999999985551\n",
      "80500 4.5 0.09999999999985551\n",
      "81000 3.3 0.09999999999985551\n",
      "81500 2.8 0.09999999999985551\n",
      "82000 4.2 0.09999999999985551\n",
      "82500 5.3 0.09999999999985551\n",
      "83000 3.7 0.09999999999985551\n",
      "83500 2.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84000 5.9 0.09999999999985551\n",
      "84500 4.2 0.09999999999985551\n",
      "85000 3.7 0.09999999999985551\n",
      "85500 3.4 0.09999999999985551\n",
      "86000 4.5 0.09999999999985551\n",
      "86500 4.6 0.09999999999985551\n",
      "87000 6.0 0.09999999999985551\n",
      "87500 3.7 0.09999999999985551\n",
      "88000 4.3 0.09999999999985551\n",
      "88500 6.6 0.09999999999985551\n",
      "89000 5.0 0.09999999999985551\n",
      "89500 4.7 0.09999999999985551\n",
      "90000 5.1 0.09999999999985551\n",
      "90500 6.2 0.09999999999985551\n",
      "91000 6.7 0.09999999999985551\n",
      "91500 6.8 0.09999999999985551\n",
      "92000 6.1 0.09999999999985551\n",
      "92500 8.2 0.09999999999985551\n",
      "93000 5.6 0.09999999999985551\n",
      "93500 7.5 0.09999999999985551\n",
      "94000 4.6 0.09999999999985551\n",
      "94500 6.9 0.09999999999985551\n",
      "95000 5.7 0.09999999999985551\n",
      "95500 5.6 0.09999999999985551\n",
      "96000 5.4 0.09999999999985551\n",
      "96500 6.1 0.09999999999985551\n",
      "97000 6.4 0.09999999999985551\n",
      "97500 5.0 0.09999999999985551\n",
      "98000 3.9 0.09999999999985551\n",
      "98500 5.4 0.09999999999985551\n",
      "99000 7.7 0.09999999999985551\n",
      "99500 7.5 0.09999999999985551\n",
      "100000 8.5 0.09999999999985551\n",
      "Saved Model\n",
      "100500 8.5 0.09999999999985551\n",
      "101000 7.4 0.09999999999985551\n",
      "101500 6.9 0.09999999999985551\n",
      "102000 8.0 0.09999999999985551\n",
      "102500 7.3 0.09999999999985551\n",
      "103000 5.0 0.09999999999985551\n",
      "103500 8.0 0.09999999999985551\n",
      "104000 6.7 0.09999999999985551\n",
      "104500 7.7 0.09999999999985551\n",
      "105000 8.1 0.09999999999985551\n",
      "105500 8.9 0.09999999999985551\n",
      "106000 8.7 0.09999999999985551\n",
      "106500 6.6 0.09999999999985551\n",
      "107000 5.9 0.09999999999985551\n",
      "107500 5.5 0.09999999999985551\n",
      "108000 9.1 0.09999999999985551\n",
      "108500 5.8 0.09999999999985551\n",
      "109000 9.3 0.09999999999985551\n",
      "109500 7.2 0.09999999999985551\n",
      "110000 7.5 0.09999999999985551\n",
      "110500 9.3 0.09999999999985551\n",
      "111000 9.0 0.09999999999985551\n",
      "111500 7.6 0.09999999999985551\n",
      "112000 7.1 0.09999999999985551\n",
      "112500 7.1 0.09999999999985551\n",
      "113000 7.5 0.09999999999985551\n",
      "113500 10.2 0.09999999999985551\n",
      "114000 9.0 0.09999999999985551\n",
      "114500 7.3 0.09999999999985551\n",
      "115000 4.3 0.09999999999985551\n",
      "115500 8.4 0.09999999999985551\n",
      "116000 9.5 0.09999999999985551\n",
      "116500 8.8 0.09999999999985551\n",
      "117000 8.0 0.09999999999985551\n",
      "117500 8.0 0.09999999999985551\n",
      "118000 6.9 0.09999999999985551\n",
      "118500 8.9 0.09999999999985551\n",
      "119000 11.5 0.09999999999985551\n",
      "119500 8.2 0.09999999999985551\n",
      "120000 6.8 0.09999999999985551\n",
      "120500 8.3 0.09999999999985551\n",
      "121000 10.8 0.09999999999985551\n",
      "121500 9.1 0.09999999999985551\n",
      "122000 9.2 0.09999999999985551\n",
      "122500 9.0 0.09999999999985551\n",
      "123000 8.4 0.09999999999985551\n",
      "123500 6.6 0.09999999999985551\n",
      "124000 9.7 0.09999999999985551\n",
      "124500 9.5 0.09999999999985551\n",
      "125000 8.6 0.09999999999985551\n",
      "125500 8.4 0.09999999999985551\n",
      "126000 6.9 0.09999999999985551\n",
      "126500 8.8 0.09999999999985551\n",
      "127000 9.5 0.09999999999985551\n",
      "127500 8.4 0.09999999999985551\n",
      "128000 9.3 0.09999999999985551\n",
      "128500 9.3 0.09999999999985551\n",
      "129000 7.4 0.09999999999985551\n",
      "129500 10.2 0.09999999999985551\n",
      "130000 9.7 0.09999999999985551\n",
      "130500 7.4 0.09999999999985551\n",
      "131000 10.5 0.09999999999985551\n",
      "131500 9.1 0.09999999999985551\n",
      "132000 8.3 0.09999999999985551\n",
      "132500 10.5 0.09999999999985551\n",
      "133000 10.2 0.09999999999985551\n",
      "133500 9.5 0.09999999999985551\n",
      "134000 9.2 0.09999999999985551\n",
      "134500 9.7 0.09999999999985551\n",
      "135000 10.6 0.09999999999985551\n",
      "135500 9.8 0.09999999999985551\n",
      "136000 8.5 0.09999999999985551\n",
      "136500 10.1 0.09999999999985551\n",
      "137000 10.0 0.09999999999985551\n",
      "137500 6.7 0.09999999999985551\n",
      "138000 6.9 0.09999999999985551\n",
      "138500 7.4 0.09999999999985551\n",
      "139000 8.3 0.09999999999985551\n",
      "139500 9.7 0.09999999999985551\n",
      "140000 10.9 0.09999999999985551\n",
      "140500 9.5 0.09999999999985551\n",
      "141000 8.4 0.09999999999985551\n",
      "141500 11.4 0.09999999999985551\n",
      "142000 7.9 0.09999999999985551\n",
      "142500 9.8 0.09999999999985551\n",
      "143000 9.7 0.09999999999985551\n",
      "143500 8.4 0.09999999999985551\n",
      "144000 7.8 0.09999999999985551\n",
      "144500 8.0 0.09999999999985551\n",
      "145000 9.8 0.09999999999985551\n",
      "145500 8.9 0.09999999999985551\n",
      "146000 8.4 0.09999999999985551\n",
      "146500 9.6 0.09999999999985551\n",
      "147000 7.5 0.09999999999985551\n",
      "147500 8.9 0.09999999999985551\n",
      "148000 9.2 0.09999999999985551\n",
      "148500 7.8 0.09999999999985551\n",
      "149000 8.6 0.09999999999985551\n",
      "149500 8.6 0.09999999999985551\n",
      "150000 7.7 0.09999999999985551\n",
      "Saved Model\n",
      "150500 7.6 0.09999999999985551\n",
      "151000 9.4 0.09999999999985551\n",
      "151500 8.4 0.09999999999985551\n",
      "152000 10.7 0.09999999999985551\n",
      "152500 9.8 0.09999999999985551\n",
      "153000 10.0 0.09999999999985551\n",
      "153500 6.5 0.09999999999985551\n",
      "154000 8.8 0.09999999999985551\n",
      "154500 8.0 0.09999999999985551\n",
      "155000 10.7 0.09999999999985551\n",
      "155500 6.8 0.09999999999985551\n",
      "156000 8.7 0.09999999999985551\n",
      "156500 6.9 0.09999999999985551\n",
      "157000 6.5 0.09999999999985551\n",
      "157500 6.8 0.09999999999985551\n",
      "158000 8.0 0.09999999999985551\n",
      "158500 9.4 0.09999999999985551\n",
      "159000 7.7 0.09999999999985551\n",
      "159500 10.3 0.09999999999985551\n",
      "160000 9.1 0.09999999999985551\n",
      "160500 8.0 0.09999999999985551\n",
      "161000 9.4 0.09999999999985551\n",
      "161500 11.2 0.09999999999985551\n",
      "162000 9.6 0.09999999999985551\n",
      "162500 8.8 0.09999999999985551\n",
      "163000 8.5 0.09999999999985551\n",
      "163500 6.5 0.09999999999985551\n",
      "164000 10.0 0.09999999999985551\n",
      "164500 9.6 0.09999999999985551\n",
      "165000 9.1 0.09999999999985551\n",
      "165500 9.8 0.09999999999985551\n",
      "166000 11.6 0.09999999999985551\n",
      "166500 8.3 0.09999999999985551\n",
      "167000 9.9 0.09999999999985551\n",
      "167500 7.0 0.09999999999985551\n",
      "168000 7.8 0.09999999999985551\n",
      "168500 9.1 0.09999999999985551\n",
      "169000 11.0 0.09999999999985551\n",
      "169500 8.6 0.09999999999985551\n",
      "170000 8.1 0.09999999999985551\n",
      "170500 10.4 0.09999999999985551\n",
      "171000 9.5 0.09999999999985551\n",
      "171500 8.0 0.09999999999985551\n",
      "172000 10.4 0.09999999999985551\n",
      "172500 11.2 0.09999999999985551\n",
      "173000 10.6 0.09999999999985551\n",
      "173500 7.3 0.09999999999985551\n",
      "174000 8.9 0.09999999999985551\n",
      "174500 8.4 0.09999999999985551\n",
      "175000 10.0 0.09999999999985551\n",
      "175500 8.7 0.09999999999985551\n",
      "176000 7.3 0.09999999999985551\n",
      "176500 9.8 0.09999999999985551\n",
      "177000 9.6 0.09999999999985551\n",
      "177500 6.1 0.09999999999985551\n",
      "178000 10.9 0.09999999999985551\n",
      "178500 6.2 0.09999999999985551\n",
      "179000 9.1 0.09999999999985551\n",
      "179500 8.1 0.09999999999985551\n",
      "180000 8.5 0.09999999999985551\n",
      "180500 10.1 0.09999999999985551\n",
      "181000 10.0 0.09999999999985551\n",
      "181500 9.4 0.09999999999985551\n",
      "182000 9.5 0.09999999999985551\n",
      "182500 8.7 0.09999999999985551\n",
      "183000 6.0 0.09999999999985551\n",
      "183500 12.8 0.09999999999985551\n",
      "184000 11.3 0.09999999999985551\n",
      "184500 10.1 0.09999999999985551\n",
      "185000 8.7 0.09999999999985551\n",
      "185500 7.8 0.09999999999985551\n",
      "186000 9.5 0.09999999999985551\n",
      "186500 8.7 0.09999999999985551\n",
      "187000 10.1 0.09999999999985551\n",
      "187500 7.3 0.09999999999985551\n",
      "188000 10.4 0.09999999999985551\n",
      "188500 9.1 0.09999999999985551\n",
      "189000 9.7 0.09999999999985551\n",
      "189500 9.9 0.09999999999985551\n",
      "190000 11.9 0.09999999999985551\n",
      "190500 9.4 0.09999999999985551\n",
      "191000 10.1 0.09999999999985551\n",
      "191500 7.5 0.09999999999985551\n",
      "192000 11.1 0.09999999999985551\n",
      "192500 7.9 0.09999999999985551\n",
      "193000 8.3 0.09999999999985551\n",
      "193500 8.9 0.09999999999985551\n",
      "194000 7.7 0.09999999999985551\n",
      "194500 9.4 0.09999999999985551\n",
      "195000 11.0 0.09999999999985551\n",
      "195500 11.2 0.09999999999985551\n",
      "196000 9.9 0.09999999999985551\n",
      "196500 11.0 0.09999999999985551\n",
      "197000 10.8 0.09999999999985551\n",
      "197500 8.3 0.09999999999985551\n",
      "198000 10.6 0.09999999999985551\n",
      "198500 8.3 0.09999999999985551\n",
      "199000 11.4 0.09999999999985551\n",
      "199500 10.4 0.09999999999985551\n",
      "200000 7.8 0.09999999999985551\n",
      "Saved Model\n",
      "200500 10.3 0.09999999999985551\n",
      "201000 9.5 0.09999999999985551\n",
      "201500 9.3 0.09999999999985551\n",
      "202000 8.5 0.09999999999985551\n",
      "202500 7.4 0.09999999999985551\n",
      "203000 10.3 0.09999999999985551\n",
      "203500 8.5 0.09999999999985551\n",
      "204000 7.8 0.09999999999985551\n",
      "204500 8.0 0.09999999999985551\n",
      "205000 7.9 0.09999999999985551\n",
      "205500 10.4 0.09999999999985551\n",
      "206000 9.7 0.09999999999985551\n",
      "206500 10.1 0.09999999999985551\n",
      "207000 7.8 0.09999999999985551\n",
      "207500 8.1 0.09999999999985551\n",
      "208000 11.9 0.09999999999985551\n",
      "208500 9.5 0.09999999999985551\n",
      "209000 7.6 0.09999999999985551\n",
      "209500 10.3 0.09999999999985551\n",
      "210000 11.1 0.09999999999985551\n",
      "210500 10.3 0.09999999999985551\n",
      "211000 12.0 0.09999999999985551\n",
      "211500 8.6 0.09999999999985551\n",
      "212000 10.9 0.09999999999985551\n",
      "212500 9.3 0.09999999999985551\n",
      "213000 9.9 0.09999999999985551\n",
      "213500 9.0 0.09999999999985551\n",
      "214000 7.4 0.09999999999985551\n",
      "214500 8.1 0.09999999999985551\n",
      "215000 10.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215500 12.6 0.09999999999985551\n",
      "216000 10.1 0.09999999999985551\n",
      "216500 6.2 0.09999999999985551\n",
      "217000 11.3 0.09999999999985551\n",
      "217500 7.6 0.09999999999985551\n",
      "218000 9.0 0.09999999999985551\n",
      "218500 10.0 0.09999999999985551\n",
      "219000 11.0 0.09999999999985551\n",
      "219500 9.4 0.09999999999985551\n",
      "220000 10.3 0.09999999999985551\n",
      "220500 9.0 0.09999999999985551\n",
      "221000 8.8 0.09999999999985551\n",
      "221500 9.5 0.09999999999985551\n",
      "222000 12.4 0.09999999999985551\n",
      "222500 9.0 0.09999999999985551\n",
      "223000 8.2 0.09999999999985551\n",
      "223500 10.1 0.09999999999985551\n",
      "224000 9.3 0.09999999999985551\n",
      "224500 10.0 0.09999999999985551\n",
      "225000 10.8 0.09999999999985551\n",
      "225500 10.3 0.09999999999985551\n",
      "226000 9.4 0.09999999999985551\n",
      "226500 10.1 0.09999999999985551\n",
      "227000 8.7 0.09999999999985551\n",
      "227500 10.5 0.09999999999985551\n",
      "228000 9.7 0.09999999999985551\n",
      "228500 7.0 0.09999999999985551\n",
      "229000 10.6 0.09999999999985551\n",
      "229500 9.4 0.09999999999985551\n",
      "230000 9.9 0.09999999999985551\n",
      "230500 10.5 0.09999999999985551\n",
      "231000 11.8 0.09999999999985551\n",
      "231500 8.7 0.09999999999985551\n",
      "232000 8.9 0.09999999999985551\n",
      "232500 8.3 0.09999999999985551\n",
      "233000 10.5 0.09999999999985551\n",
      "233500 9.5 0.09999999999985551\n",
      "234000 8.6 0.09999999999985551\n",
      "234500 11.4 0.09999999999985551\n",
      "235000 7.6 0.09999999999985551\n",
      "235500 6.7 0.09999999999985551\n",
      "236000 9.0 0.09999999999985551\n",
      "236500 10.8 0.09999999999985551\n",
      "237000 11.1 0.09999999999985551\n",
      "237500 9.4 0.09999999999985551\n",
      "238000 10.5 0.09999999999985551\n",
      "238500 12.9 0.09999999999985551\n",
      "239000 9.3 0.09999999999985551\n",
      "239500 11.2 0.09999999999985551\n",
      "240000 10.9 0.09999999999985551\n",
      "240500 9.7 0.09999999999985551\n",
      "241000 8.0 0.09999999999985551\n",
      "241500 7.8 0.09999999999985551\n",
      "242000 9.1 0.09999999999985551\n",
      "242500 9.0 0.09999999999985551\n",
      "243000 9.3 0.09999999999985551\n",
      "243500 10.0 0.09999999999985551\n",
      "244000 9.7 0.09999999999985551\n",
      "244500 10.2 0.09999999999985551\n",
      "245000 8.7 0.09999999999985551\n",
      "245500 8.4 0.09999999999985551\n",
      "246000 10.7 0.09999999999985551\n",
      "246500 8.2 0.09999999999985551\n",
      "247000 9.1 0.09999999999985551\n",
      "247500 8.3 0.09999999999985551\n",
      "248000 8.7 0.09999999999985551\n",
      "248500 9.0 0.09999999999985551\n",
      "249000 8.8 0.09999999999985551\n",
      "249500 8.3 0.09999999999985551\n",
      "250000 9.0 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 11.5 0.09999999999985551\n",
      "251000 11.7 0.09999999999985551\n",
      "251500 8.5 0.09999999999985551\n",
      "252000 12.4 0.09999999999985551\n",
      "252500 11.2 0.09999999999985551\n",
      "253000 10.9 0.09999999999985551\n",
      "253500 10.0 0.09999999999985551\n",
      "254000 10.5 0.09999999999985551\n",
      "254500 6.6 0.09999999999985551\n",
      "255000 9.0 0.09999999999985551\n",
      "255500 10.6 0.09999999999985551\n",
      "256000 12.5 0.09999999999985551\n",
      "256500 9.0 0.09999999999985551\n",
      "257000 8.8 0.09999999999985551\n",
      "257500 8.1 0.09999999999985551\n",
      "258000 11.7 0.09999999999985551\n",
      "258500 10.2 0.09999999999985551\n",
      "259000 8.5 0.09999999999985551\n",
      "259500 10.7 0.09999999999985551\n",
      "260000 9.4 0.09999999999985551\n",
      "260500 8.9 0.09999999999985551\n",
      "261000 9.9 0.09999999999985551\n",
      "261500 10.8 0.09999999999985551\n",
      "262000 12.2 0.09999999999985551\n",
      "262500 10.0 0.09999999999985551\n",
      "263000 9.6 0.09999999999985551\n",
      "263500 8.6 0.09999999999985551\n",
      "264000 13.7 0.09999999999985551\n",
      "264500 11.2 0.09999999999985551\n",
      "265000 10.0 0.09999999999985551\n",
      "265500 9.7 0.09999999999985551\n",
      "266000 10.0 0.09999999999985551\n",
      "266500 10.9 0.09999999999985551\n",
      "267000 11.0 0.09999999999985551\n",
      "267500 12.2 0.09999999999985551\n",
      "268000 8.4 0.09999999999985551\n",
      "268500 10.5 0.09999999999985551\n",
      "269000 11.0 0.09999999999985551\n",
      "269500 10.2 0.09999999999985551\n",
      "270000 9.1 0.09999999999985551\n",
      "270500 8.4 0.09999999999985551\n",
      "271000 7.2 0.09999999999985551\n",
      "271500 10.2 0.09999999999985551\n",
      "272000 13.1 0.09999999999985551\n",
      "272500 10.3 0.09999999999985551\n",
      "273000 8.8 0.09999999999985551\n",
      "273500 11.4 0.09999999999985551\n",
      "274000 10.0 0.09999999999985551\n",
      "274500 9.0 0.09999999999985551\n",
      "275000 9.4 0.09999999999985551\n",
      "275500 8.7 0.09999999999985551\n",
      "276000 9.4 0.09999999999985551\n",
      "276500 10.6 0.09999999999985551\n",
      "277000 9.3 0.09999999999985551\n",
      "277500 9.0 0.09999999999985551\n",
      "278000 10.8 0.09999999999985551\n",
      "278500 8.3 0.09999999999985551\n",
      "279000 11.0 0.09999999999985551\n",
      "279500 12.4 0.09999999999985551\n",
      "280000 11.1 0.09999999999985551\n",
      "280500 10.8 0.09999999999985551\n",
      "281000 8.3 0.09999999999985551\n",
      "281500 11.3 0.09999999999985551\n",
      "282000 8.4 0.09999999999985551\n",
      "282500 9.9 0.09999999999985551\n",
      "283000 7.3 0.09999999999985551\n",
      "283500 10.4 0.09999999999985551\n",
      "284000 9.9 0.09999999999985551\n",
      "284500 8.0 0.09999999999985551\n",
      "285000 9.3 0.09999999999985551\n",
      "285500 9.8 0.09999999999985551\n",
      "286000 11.0 0.09999999999985551\n",
      "286500 10.7 0.09999999999985551\n",
      "287000 8.2 0.09999999999985551\n",
      "287500 10.1 0.09999999999985551\n",
      "288000 11.0 0.09999999999985551\n",
      "288500 10.7 0.09999999999985551\n",
      "289000 11.6 0.09999999999985551\n",
      "289500 8.8 0.09999999999985551\n",
      "290000 9.2 0.09999999999985551\n",
      "290500 10.5 0.09999999999985551\n",
      "291000 10.5 0.09999999999985551\n",
      "291500 11.9 0.09999999999985551\n",
      "292000 9.3 0.09999999999985551\n",
      "292500 11.3 0.09999999999985551\n",
      "293000 9.3 0.09999999999985551\n",
      "293500 12.1 0.09999999999985551\n",
      "294000 9.1 0.09999999999985551\n",
      "294500 9.1 0.09999999999985551\n",
      "295000 9.8 0.09999999999985551\n",
      "295500 11.0 0.09999999999985551\n",
      "296000 10.3 0.09999999999985551\n",
      "296500 9.9 0.09999999999985551\n",
      "297000 10.0 0.09999999999985551\n",
      "297500 7.1 0.09999999999985551\n",
      "298000 10.5 0.09999999999985551\n",
      "298500 10.6 0.09999999999985551\n",
      "299000 8.5 0.09999999999985551\n",
      "299500 7.2 0.09999999999985551\n",
      "300000 8.5 0.09999999999985551\n",
      "Saved Model\n",
      "300500 9.5 0.09999999999985551\n",
      "301000 9.1 0.09999999999985551\n",
      "301500 12.0 0.09999999999985551\n",
      "302000 10.4 0.09999999999985551\n",
      "302500 11.9 0.09999999999985551\n",
      "303000 9.9 0.09999999999985551\n",
      "303500 11.1 0.09999999999985551\n",
      "304000 11.8 0.09999999999985551\n",
      "304500 9.0 0.09999999999985551\n",
      "305000 9.7 0.09999999999985551\n",
      "305500 10.7 0.09999999999985551\n",
      "306000 12.7 0.09999999999985551\n",
      "306500 10.6 0.09999999999985551\n",
      "307000 11.8 0.09999999999985551\n",
      "307500 11.6 0.09999999999985551\n",
      "308000 9.4 0.09999999999985551\n",
      "308500 10.1 0.09999999999985551\n",
      "309000 11.4 0.09999999999985551\n",
      "309500 12.2 0.09999999999985551\n",
      "310000 8.3 0.09999999999985551\n",
      "310500 10.5 0.09999999999985551\n",
      "311000 9.6 0.09999999999985551\n",
      "311500 11.4 0.09999999999985551\n",
      "312000 9.1 0.09999999999985551\n",
      "312500 10.0 0.09999999999985551\n",
      "313000 8.5 0.09999999999985551\n",
      "313500 10.9 0.09999999999985551\n",
      "314000 9.3 0.09999999999985551\n",
      "314500 7.1 0.09999999999985551\n",
      "315000 10.8 0.09999999999985551\n",
      "315500 11.9 0.09999999999985551\n",
      "316000 7.6 0.09999999999985551\n",
      "316500 13.0 0.09999999999985551\n",
      "317000 9.5 0.09999999999985551\n",
      "317500 9.0 0.09999999999985551\n",
      "318000 10.5 0.09999999999985551\n",
      "318500 11.0 0.09999999999985551\n",
      "319000 11.1 0.09999999999985551\n",
      "319500 11.4 0.09999999999985551\n",
      "320000 8.7 0.09999999999985551\n",
      "320500 10.6 0.09999999999985551\n",
      "321000 8.1 0.09999999999985551\n",
      "321500 9.3 0.09999999999985551\n",
      "322000 10.0 0.09999999999985551\n",
      "322500 10.9 0.09999999999985551\n",
      "323000 12.4 0.09999999999985551\n",
      "323500 8.0 0.09999999999985551\n",
      "324000 10.5 0.09999999999985551\n",
      "324500 9.3 0.09999999999985551\n",
      "325000 9.7 0.09999999999985551\n",
      "325500 11.0 0.09999999999985551\n",
      "326000 8.8 0.09999999999985551\n",
      "326500 11.5 0.09999999999985551\n",
      "327000 10.9 0.09999999999985551\n",
      "327500 11.6 0.09999999999985551\n",
      "328000 11.0 0.09999999999985551\n",
      "328500 12.4 0.09999999999985551\n",
      "329000 11.6 0.09999999999985551\n",
      "329500 8.0 0.09999999999985551\n",
      "330000 12.0 0.09999999999985551\n",
      "330500 9.0 0.09999999999985551\n",
      "331000 7.1 0.09999999999985551\n",
      "331500 10.7 0.09999999999985551\n",
      "332000 13.8 0.09999999999985551\n",
      "332500 8.4 0.09999999999985551\n",
      "333000 9.7 0.09999999999985551\n",
      "333500 10.4 0.09999999999985551\n",
      "334000 9.3 0.09999999999985551\n",
      "334500 10.2 0.09999999999985551\n",
      "335000 10.1 0.09999999999985551\n",
      "335500 9.2 0.09999999999985551\n",
      "336000 10.2 0.09999999999985551\n",
      "336500 8.4 0.09999999999985551\n",
      "337000 8.7 0.09999999999985551\n",
      "337500 10.4 0.09999999999985551\n",
      "338000 10.1 0.09999999999985551\n",
      "338500 9.1 0.09999999999985551\n",
      "339000 12.1 0.09999999999985551\n",
      "339500 7.5 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340000 8.6 0.09999999999985551\n",
      "340500 9.7 0.09999999999985551\n",
      "341000 10.3 0.09999999999985551\n",
      "341500 9.7 0.09999999999985551\n",
      "342000 10.9 0.09999999999985551\n",
      "342500 8.7 0.09999999999985551\n",
      "343000 11.2 0.09999999999985551\n",
      "343500 10.3 0.09999999999985551\n",
      "344000 12.1 0.09999999999985551\n",
      "344500 9.4 0.09999999999985551\n",
      "345000 10.8 0.09999999999985551\n",
      "345500 8.4 0.09999999999985551\n",
      "346000 9.3 0.09999999999985551\n",
      "346500 9.6 0.09999999999985551\n",
      "347000 8.5 0.09999999999985551\n",
      "347500 10.1 0.09999999999985551\n",
      "348000 10.6 0.09999999999985551\n",
      "348500 11.7 0.09999999999985551\n",
      "349000 11.2 0.09999999999985551\n",
      "349500 13.3 0.09999999999985551\n",
      "350000 9.3 0.09999999999985551\n",
      "Saved Model\n",
      "350500 9.5 0.09999999999985551\n",
      "351000 10.5 0.09999999999985551\n",
      "351500 8.8 0.09999999999985551\n",
      "352000 11.6 0.09999999999985551\n",
      "352500 11.2 0.09999999999985551\n",
      "353000 11.0 0.09999999999985551\n",
      "353500 12.2 0.09999999999985551\n",
      "354000 12.5 0.09999999999985551\n",
      "354500 9.9 0.09999999999985551\n",
      "355000 9.4 0.09999999999985551\n",
      "355500 11.1 0.09999999999985551\n",
      "356000 8.9 0.09999999999985551\n",
      "356500 11.2 0.09999999999985551\n",
      "357000 9.8 0.09999999999985551\n",
      "357500 10.4 0.09999999999985551\n",
      "358000 10.9 0.09999999999985551\n",
      "358500 9.3 0.09999999999985551\n",
      "359000 11.7 0.09999999999985551\n",
      "359500 8.4 0.09999999999985551\n",
      "360000 10.5 0.09999999999985551\n",
      "360500 11.3 0.09999999999985551\n",
      "361000 11.9 0.09999999999985551\n",
      "361500 13.2 0.09999999999985551\n",
      "362000 10.2 0.09999999999985551\n",
      "362500 9.6 0.09999999999985551\n",
      "363000 8.3 0.09999999999985551\n",
      "363500 10.5 0.09999999999985551\n",
      "364000 12.7 0.09999999999985551\n",
      "364500 11.9 0.09999999999985551\n",
      "365000 10.3 0.09999999999985551\n",
      "365500 11.0 0.09999999999985551\n",
      "366000 11.1 0.09999999999985551\n",
      "366500 8.7 0.09999999999985551\n",
      "367000 9.8 0.09999999999985551\n",
      "367500 12.6 0.09999999999985551\n",
      "368000 9.7 0.09999999999985551\n",
      "368500 11.7 0.09999999999985551\n",
      "369000 9.8 0.09999999999985551\n",
      "369500 10.7 0.09999999999985551\n",
      "370000 9.9 0.09999999999985551\n",
      "370500 10.6 0.09999999999985551\n",
      "371000 11.8 0.09999999999985551\n",
      "371500 10.1 0.09999999999985551\n",
      "372000 10.7 0.09999999999985551\n",
      "372500 9.9 0.09999999999985551\n",
      "373000 11.5 0.09999999999985551\n",
      "373500 10.9 0.09999999999985551\n",
      "374000 9.0 0.09999999999985551\n",
      "374500 11.8 0.09999999999985551\n",
      "375000 9.6 0.09999999999985551\n",
      "375500 9.9 0.09999999999985551\n",
      "376000 8.1 0.09999999999985551\n",
      "376500 10.6 0.09999999999985551\n",
      "377000 10.6 0.09999999999985551\n",
      "377500 9.0 0.09999999999985551\n",
      "378000 10.0 0.09999999999985551\n",
      "378500 12.3 0.09999999999985551\n",
      "379000 11.7 0.09999999999985551\n",
      "379500 10.5 0.09999999999985551\n",
      "380000 11.2 0.09999999999985551\n",
      "380500 12.1 0.09999999999985551\n",
      "381000 9.0 0.09999999999985551\n",
      "381500 8.9 0.09999999999985551\n",
      "382000 9.6 0.09999999999985551\n",
      "382500 11.0 0.09999999999985551\n",
      "383000 10.4 0.09999999999985551\n",
      "383500 11.0 0.09999999999985551\n",
      "384000 9.9 0.09999999999985551\n",
      "384500 9.9 0.09999999999985551\n",
      "385000 9.6 0.09999999999985551\n",
      "385500 8.9 0.09999999999985551\n",
      "386000 10.3 0.09999999999985551\n",
      "386500 12.0 0.09999999999985551\n",
      "387000 10.1 0.09999999999985551\n",
      "387500 10.5 0.09999999999985551\n",
      "388000 10.0 0.09999999999985551\n",
      "388500 10.8 0.09999999999985551\n",
      "389000 9.6 0.09999999999985551\n",
      "389500 10.7 0.09999999999985551\n",
      "390000 11.0 0.09999999999985551\n",
      "390500 13.4 0.09999999999985551\n",
      "391000 9.1 0.09999999999985551\n",
      "391500 11.7 0.09999999999985551\n",
      "392000 8.8 0.09999999999985551\n",
      "392500 10.6 0.09999999999985551\n",
      "393000 10.8 0.09999999999985551\n",
      "393500 11.5 0.09999999999985551\n",
      "394000 10.8 0.09999999999985551\n",
      "394500 11.3 0.09999999999985551\n",
      "395000 12.1 0.09999999999985551\n",
      "395500 10.1 0.09999999999985551\n",
      "396000 8.4 0.09999999999985551\n",
      "396500 13.4 0.09999999999985551\n",
      "397000 10.9 0.09999999999985551\n",
      "397500 10.8 0.09999999999985551\n",
      "398000 7.7 0.09999999999985551\n",
      "398500 9.8 0.09999999999985551\n",
      "399000 8.6 0.09999999999985551\n",
      "399500 11.4 0.09999999999985551\n",
      "400000 11.4 0.09999999999985551\n",
      "Saved Model\n",
      "400500 10.6 0.09999999999985551\n",
      "401000 10.7 0.09999999999985551\n",
      "401500 12.1 0.09999999999985551\n",
      "402000 9.2 0.09999999999985551\n",
      "402500 12.4 0.09999999999985551\n",
      "403000 12.0 0.09999999999985551\n",
      "403500 10.9 0.09999999999985551\n",
      "404000 11.1 0.09999999999985551\n",
      "404500 7.8 0.09999999999985551\n",
      "405000 13.1 0.09999999999985551\n",
      "405500 11.0 0.09999999999985551\n",
      "406000 11.1 0.09999999999985551\n",
      "406500 9.6 0.09999999999985551\n",
      "407000 8.9 0.09999999999985551\n",
      "407500 9.9 0.09999999999985551\n",
      "408000 12.3 0.09999999999985551\n",
      "408500 12.2 0.09999999999985551\n",
      "409000 10.6 0.09999999999985551\n",
      "409500 9.7 0.09999999999985551\n",
      "410000 12.2 0.09999999999985551\n",
      "410500 12.0 0.09999999999985551\n",
      "411000 9.8 0.09999999999985551\n",
      "411500 11.4 0.09999999999985551\n",
      "412000 10.2 0.09999999999985551\n",
      "412500 10.4 0.09999999999985551\n",
      "413000 10.6 0.09999999999985551\n",
      "413500 11.1 0.09999999999985551\n",
      "414000 11.1 0.09999999999985551\n",
      "414500 11.8 0.09999999999985551\n",
      "415000 8.6 0.09999999999985551\n",
      "415500 8.9 0.09999999999985551\n",
      "416000 14.2 0.09999999999985551\n",
      "416500 10.4 0.09999999999985551\n",
      "417000 8.8 0.09999999999985551\n",
      "417500 9.5 0.09999999999985551\n",
      "418000 10.2 0.09999999999985551\n",
      "418500 11.2 0.09999999999985551\n",
      "419000 8.1 0.09999999999985551\n",
      "419500 9.9 0.09999999999985551\n",
      "420000 10.0 0.09999999999985551\n",
      "420500 7.9 0.09999999999985551\n",
      "421000 9.6 0.09999999999985551\n",
      "421500 11.2 0.09999999999985551\n",
      "422000 10.9 0.09999999999985551\n",
      "422500 12.4 0.09999999999985551\n",
      "423000 10.4 0.09999999999985551\n",
      "423500 10.2 0.09999999999985551\n",
      "424000 9.3 0.09999999999985551\n",
      "424500 11.4 0.09999999999985551\n",
      "425000 8.6 0.09999999999985551\n",
      "425500 11.0 0.09999999999985551\n",
      "426000 11.4 0.09999999999985551\n",
      "426500 10.3 0.09999999999985551\n",
      "427000 9.8 0.09999999999985551\n",
      "427500 11.1 0.09999999999985551\n",
      "428000 10.6 0.09999999999985551\n",
      "428500 12.2 0.09999999999985551\n",
      "429000 10.2 0.09999999999985551\n",
      "429500 9.5 0.09999999999985551\n",
      "430000 10.1 0.09999999999985551\n",
      "430500 13.9 0.09999999999985551\n",
      "431000 6.8 0.09999999999985551\n",
      "431500 11.0 0.09999999999985551\n",
      "432000 11.3 0.09999999999985551\n",
      "432500 10.1 0.09999999999985551\n",
      "433000 11.5 0.09999999999985551\n",
      "433500 10.1 0.09999999999985551\n",
      "434000 12.0 0.09999999999985551\n",
      "434500 9.8 0.09999999999985551\n",
      "435000 10.2 0.09999999999985551\n",
      "435500 10.1 0.09999999999985551\n",
      "436000 9.3 0.09999999999985551\n",
      "436500 11.3 0.09999999999985551\n",
      "437000 9.4 0.09999999999985551\n",
      "437500 10.4 0.09999999999985551\n",
      "438000 9.7 0.09999999999985551\n",
      "438500 11.2 0.09999999999985551\n",
      "439000 11.3 0.09999999999985551\n",
      "439500 8.5 0.09999999999985551\n",
      "440000 12.2 0.09999999999985551\n",
      "440500 11.3 0.09999999999985551\n",
      "441000 9.0 0.09999999999985551\n",
      "441500 11.6 0.09999999999985551\n",
      "442000 11.5 0.09999999999985551\n",
      "442500 9.2 0.09999999999985551\n",
      "443000 11.2 0.09999999999985551\n",
      "443500 8.3 0.09999999999985551\n",
      "444000 10.9 0.09999999999985551\n",
      "444500 10.8 0.09999999999985551\n",
      "445000 10.0 0.09999999999985551\n",
      "445500 10.2 0.09999999999985551\n",
      "446000 12.5 0.09999999999985551\n",
      "446500 11.3 0.09999999999985551\n",
      "447000 11.9 0.09999999999985551\n",
      "447500 9.3 0.09999999999985551\n",
      "448000 10.9 0.09999999999985551\n",
      "448500 10.4 0.09999999999985551\n",
      "449000 10.7 0.09999999999985551\n",
      "449500 11.4 0.09999999999985551\n",
      "450000 10.4 0.09999999999985551\n",
      "Saved Model\n",
      "450500 11.3 0.09999999999985551\n",
      "451000 10.3 0.09999999999985551\n",
      "451500 11.1 0.09999999999985551\n",
      "452000 13.0 0.09999999999985551\n",
      "452500 11.7 0.09999999999985551\n",
      "453000 11.6 0.09999999999985551\n",
      "453500 11.1 0.09999999999985551\n",
      "454000 11.2 0.09999999999985551\n",
      "454500 11.5 0.09999999999985551\n",
      "455000 9.0 0.09999999999985551\n",
      "455500 10.8 0.09999999999985551\n",
      "456000 10.7 0.09999999999985551\n",
      "456500 11.8 0.09999999999985551\n",
      "457000 9.6 0.09999999999985551\n",
      "457500 12.9 0.09999999999985551\n",
      "458000 10.1 0.09999999999985551\n",
      "458500 11.4 0.09999999999985551\n",
      "459000 8.4 0.09999999999985551\n",
      "459500 11.6 0.09999999999985551\n",
      "460000 8.9 0.09999999999985551\n",
      "460500 13.1 0.09999999999985551\n",
      "461000 11.0 0.09999999999985551\n",
      "461500 8.2 0.09999999999985551\n",
      "462000 9.1 0.09999999999985551\n",
      "462500 11.1 0.09999999999985551\n",
      "463000 11.7 0.09999999999985551\n",
      "463500 8.7 0.09999999999985551\n",
      "464000 10.4 0.09999999999985551\n",
      "464500 9.8 0.09999999999985551\n",
      "465000 8.3 0.09999999999985551\n",
      "465500 12.0 0.09999999999985551\n",
      "466000 9.6 0.09999999999985551\n",
      "466500 8.4 0.09999999999985551\n",
      "467000 9.8 0.09999999999985551\n",
      "467500 10.3 0.09999999999985551\n",
      "468000 12.1 0.09999999999985551\n",
      "468500 13.1 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469000 10.7 0.09999999999985551\n",
      "469500 11.4 0.09999999999985551\n",
      "470000 10.7 0.09999999999985551\n",
      "470500 10.0 0.09999999999985551\n",
      "471000 11.4 0.09999999999985551\n",
      "471500 11.2 0.09999999999985551\n",
      "472000 8.9 0.09999999999985551\n",
      "472500 9.6 0.09999999999985551\n",
      "473000 10.4 0.09999999999985551\n",
      "473500 10.4 0.09999999999985551\n",
      "474000 10.1 0.09999999999985551\n",
      "474500 10.4 0.09999999999985551\n",
      "475000 9.3 0.09999999999985551\n",
      "475500 9.8 0.09999999999985551\n",
      "476000 10.5 0.09999999999985551\n",
      "476500 10.0 0.09999999999985551\n",
      "477000 11.3 0.09999999999985551\n",
      "477500 10.2 0.09999999999985551\n",
      "478000 9.8 0.09999999999985551\n",
      "478500 9.9 0.09999999999985551\n",
      "479000 10.5 0.09999999999985551\n",
      "479500 9.5 0.09999999999985551\n",
      "480000 10.5 0.09999999999985551\n",
      "480500 14.1 0.09999999999985551\n",
      "481000 9.1 0.09999999999985551\n",
      "481500 10.6 0.09999999999985551\n",
      "482000 10.7 0.09999999999985551\n",
      "482500 10.4 0.09999999999985551\n",
      "483000 12.5 0.09999999999985551\n",
      "483500 8.0 0.09999999999985551\n",
      "484000 11.4 0.09999999999985551\n",
      "484500 14.0 0.09999999999985551\n",
      "485000 10.2 0.09999999999985551\n",
      "485500 11.0 0.09999999999985551\n",
      "486000 10.1 0.09999999999985551\n",
      "486500 9.7 0.09999999999985551\n",
      "487000 12.1 0.09999999999985551\n",
      "487500 12.1 0.09999999999985551\n",
      "488000 11.6 0.09999999999985551\n",
      "488500 11.2 0.09999999999985551\n",
      "489000 10.0 0.09999999999985551\n",
      "489500 11.5 0.09999999999985551\n",
      "490000 9.4 0.09999999999985551\n",
      "490500 11.4 0.09999999999985551\n",
      "491000 11.9 0.09999999999985551\n",
      "491500 11.6 0.09999999999985551\n",
      "492000 9.8 0.09999999999985551\n",
      "492500 9.5 0.09999999999985551\n",
      "493000 13.5 0.09999999999985551\n",
      "493500 13.1 0.09999999999985551\n",
      "494000 10.3 0.09999999999985551\n",
      "494500 10.1 0.09999999999985551\n",
      "495000 11.4 0.09999999999985551\n",
      "495500 12.3 0.09999999999985551\n",
      "496000 11.9 0.09999999999985551\n",
      "496500 7.4 0.09999999999985551\n",
      "497000 10.4 0.09999999999985551\n",
      "497500 13.2 0.09999999999985551\n",
      "498000 11.4 0.09999999999985551\n",
      "498500 9.9 0.09999999999985551\n",
      "499000 11.9 0.09999999999985551\n",
      "499500 9.3 0.09999999999985551\n",
      "500000 10.5 0.09999999999985551\n",
      "Percent of succesful episodes: 8.2428%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i+1000)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i+1000)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8c480e5780>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANEElEQVR4nO3df+hd9X3H8edridbWbtVoFjIjS0ZFkYHRfXGKZXRqNmuL9o8iShllCP2n23QtVN3+KIX90cJo6x+jELRdGM4ftbpKKHZZahmDkRp/rNVEm2hjTVATO52dg21p3/vjnrBvwzfxfHPv/X7vyef5gMv3nnPuzfmcnLxyzj33fN/vVBWSTn6/stwDkLQ0DLvUCMMuNcKwS40w7FIjDLvUiLHCnuSaJM8n2Zvk9kkNStLk5US/Z0+yAvgRsAnYDzwO3FRVuyY3PEmTsnKM914K7K2qFwGS3AdcDxwz7GeffXatX79+jFVKOp59+/bx+uuvZ6Fl44T9HODledP7gd893hvWr1/Pzp07x1ilpOOZm5s75rKpX6BL8skkO5PsPHTo0LRXJ+kYxgn7AeDcedPrunm/pKo2V9VcVc2tXr16jNVJGsc4YX8cOC/JhiSnAjcCj0xmWJIm7YQ/s1fV4SR/AnwHWAF8raqendjIJE3UOBfoqKpvA9+e0FgkTZF30EmNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSI8b6FddZkCxYW08zbJp9g4f2r2Epuyh7ZJcaYdilRrxj2JN8LcnBJM/Mm7cqybYke7qfZ053mJLG1efI/rfANUfNux3YXlXnAdu7aUkz7B3DXlX/DPz7UbOvB7Z0z7cAH53wuCRN2Il+Zl9TVa90z18F1kxoPJKmZOwLdDX67uCY3x/YEUaaDSca9teSrAXofh481gvtCCPNhhMN+yPAJ7rnnwC+NZnhSJqWPl+93Qv8K3B+kv1Jbga+AGxKsge4upuWNMPe8XbZqrrpGIuumvBYJE2Rd9BJjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9SIwZeS1vAMrdzzycIju9QIwy41wrBLjTDsUiMMu9SIPmWpzk3yWJJdSZ5Ncks3364w0oD0ObIfBj5TVRcClwGfSnIhdoWRBqVPR5hXqurJ7vnPgN3AOdgVRhqURX1mT7IeuBjYQc+uMDaJkGZD77AneS/wTeDWqnpr/rLjdYWxSYQ0G3qFPckpjIJ+T1U91M3u3RVG0vLrczU+wN3A7qr60rxFdoWRBqTPL8JcAfwR8MMkT3fz/oJRF5gHug4xLwE3TGeIkiahT0eYf+HYv6hkVxhpILyDTmqEYZcaYdilRhh2qRGGXWqEYZcaYcFJHdeC90CPyYKTy8Mju9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41ok8NutOSfD/Jv3UdYT7fzd+QZEeSvUnuT3Lq9Icr6UT1ObL/N3BlVV0EbASuSXIZ8EXgy1X1fuAN4ObpDVPSuPp0hKmq+s9u8pTuUcCVwIPdfDvCSDOub934FV1l2YPANuAF4M2qOty9ZD+jllALvdeOMNIM6BX2qvp5VW0E1gGXAhf0XYEdYaTZsKir8VX1JvAYcDlwRpIjvw+/Djgw4bFJmqA+V+NXJzmje/5uYBOjTq6PAR/rXmZHGGnG9alUsxbYkmQFo/8cHqiqrUl2Afcl+SvgKUYtoiTNqD4dYX7AqE3z0fNfZPT5XdIAeAed1AjDLjXCsEuNsJT0SWXyhZ8zsMLPlr4+No/sUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiN6h70rJ/1Ukq3dtB1hpAFZzJH9FkaFJo+wI4w0IH2bRKwDPgzc1U0HO8JIg9L3yP4V4LPAL7rps7AjjDQoferGfwQ4WFVPnMgK7AgjzYY+ZamuAK5Lci1wGvBrwJ10HWG6o7sdYaQZ16eL6x1Vta6q1gM3At+tqo9jRxhpUMb5nv024NNJ9jL6DL8sHWFqio/p/KHTlCk8hsW/gWNbVHXZqvoe8L3uuR1hpAHxDjqpEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEb0q1STZB/wM+DlwuKrmkqwC7gfWA/uAG6rqjekMU9K4FnNk//2q2lhVc9307cD2qjoP2N5NS5pRi6pBd5TrgQ92z7cwqk1325jjWbSpFgScwh8+9ZqTE3YyFVxsXd8jewH/mOSJJJ/s5q2pqle6568CaxZ6ox1hpNnQ98j+gao6kOTXgW1Jnpu/sKoqyYIHraraDGwGmJubG9qBTTpp9DqyV9WB7udB4GFGJaRfS7IWoPt5cFqDlDS+Pr3eTk/yq0eeA38APAM8wqgTDNgRRpp5fU7j1wAPj7o0sxL4+6p6NMnjwANJbgZeAm6Y3jAljesdw951frlogfk/Ba6axqAkTZ530EmNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjVinFLSmjGWfdbx9DqyJzkjyYNJnkuyO8nlSVYl2ZZkT/fzzGkPVtKJ63safyfwaFVdwKhE1W7sCCMNSp/qsu8Dfg+4G6Cq/qeq3mTUEWZL97ItwEenNUhJ4+tzZN8AHAK+nuSpJHd1JaXtCCMNSJ+wrwQuAb5aVRcDb3PUKXtVFcdoY1ZVm6tqrqrmVq9ePe54JZ2gPmHfD+yvqh3d9IOMwm9HGGlA3jHsVfUq8HKS87tZVwG7sCOMNCh9v2f/U+CeJKcCLwJ/zOg/CjvCSAPRK+xV9TQwt8AiO8JIA+HtslIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKCk0tsmkUhFywoMCaLWJ48PLJLjTDsUiMMu9QIwy41ok8p6fOTPD3v8VaSW20SIQ1Lnxp0z1fVxqraCPwO8F/Aw9gkQhqUxZ7GXwW8UFUvYZMIaVAWG/YbgXu7572aREiaDb3D3lWWvQ74xtHLjtckwo4w0mxYzJH9Q8CTVfVaN92rSYQdYaTZsJiw38T/n8KDTSKkQenbn/10YBPw0LzZXwA2JdkDXN1NS5pRfZtEvA2cddS8n2KTCGkwvINOaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdasTgS0mPfuFO0+Lf7snDI7vUCMMuNcKwS40w7FIjDLvUCMMuNcKwS43oW5bqz5M8m+SZJPcmOS3JhiQ7kuxNcn9XfVbSjOrT/ukc4M+Auar6bWAFo/rxXwS+XFXvB94Abp7mQCWNp+9p/Erg3UlWAu8BXgGuBB7sltsRRppxfXq9HQD+GvgJo5D/B/AE8GZVHe5eth84Z1qDlDS+PqfxZzLq67YB+A3gdOCaviuwI4w0G/qcxl8N/LiqDlXV/zKqHX8FcEZ3Wg+wDjiw0JvtCCPNhj5h/wlwWZL3JAmjWvG7gMeAj3WvsSOMNOP6fGbfwehC3JPAD7v3bAZuAz6dZC+jBhJ3T3GcksbUtyPM54DPHTX7ReDSiY9I0lR4B53UCMMuNcKwS40w7FIjspQFG5McAt4GXl+ylU7f2bg9s+pk2hbotz2/WVUL3tCypGEHSLKzquaWdKVT5PbMrpNpW2D87fE0XmqEYZcasRxh37wM65wmt2d2nUzbAmNuz5J/Zpe0PDyNlxqxpGFPck2S57u6dbcv5brHleTcJI8l2dXV47ulm78qybYke7qfZy73WBcjyYokTyXZ2k0PtrZgkjOSPJjkuSS7k1w+5P0z6dqPSxb2JCuAvwE+BFwI3JTkwqVa/wQcBj5TVRcClwGf6sZ/O7C9qs4DtnfTQ3ILsHve9JBrC94JPFpVFwAXMdquQe6fqdR+rKoleQCXA9+ZN30HcMdSrX8K2/MtYBPwPLC2m7cWeH65x7aIbVjHKABXAluBMLppY+VC+2yWH8D7gB/TXYeaN3+Q+4dRmbeXgVWMfjt1K/CH4+yfpTyNPzL4IwZbty7JeuBiYAewpqpe6Ra9CqxZpmGdiK8AnwV+0U2fxXBrC24ADgFf7z6W3JXkdAa6f2oKtR+9QLdISd4LfBO4taremr+sRv/dDuLrjSQfAQ5W1RPLPZYJWQlcAny1qi5mdFv2L52yD2z/jFX7cSFLGfYDwLnzpo9Zt25WJTmFUdDvqaqHutmvJVnbLV8LHFyu8S3SFcB1SfYB9zE6lb+TnrUFZ9B+YH+NKivBqLrSJQx3/4xV+3EhSxn2x4HzuquJpzK62PDIEq5/LF39vbuB3VX1pXmLHmFUgw8GVIuvqu6oqnVVtZ7RvvhuVX2cgdYWrKpXgZeTnN/NOlIrcZD7h2nUflziiw7XAj8CXgD+crkvgixy7B9gdAr4A+Dp7nEto8+524E9wD8Bq5Z7rCewbR8EtnbPfwv4PrAX+AbwruUe3yK2YyOws9tH/wCcOeT9A3weeA54Bvg74F3j7B/voJMa4QU6qRGGXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRvwfL6wEjkiT2eAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4221741eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4221741710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220d309e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220d309e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220d309e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220d309e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c717f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c717f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c717f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c717f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4220c71ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4220c71908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 -0.8 1\n",
      "1000 -0.1 1\n",
      "1500 0.7 1\n",
      "2000 0.1 1\n",
      "2500 0.0 1\n",
      "3000 -0.6 1\n",
      "3500 0.5 1\n",
      "4000 -0.7 1\n",
      "4500 -0.4 1\n",
      "5000 0.9 1\n",
      "5500 1.8 1\n",
      "6000 -0.1 1\n",
      "6500 -0.9 1\n",
      "7000 -0.8 1\n",
      "7500 0.5 1\n",
      "8000 0.2 1\n",
      "8500 0.8 1\n",
      "9000 0.8 1\n",
      "9500 0.2 1\n",
      "10000 -1.3 1\n",
      "10500 -0.5 0.9549999999999828\n",
      "11000 1.7 0.9099999999999655\n",
      "11500 0.2 0.8649999999999483\n",
      "12000 0.8 0.819999999999931\n",
      "12500 0.2 0.7749999999999138\n",
      "13000 0.2 0.7299999999998965\n",
      "13500 1.2 0.6849999999998793\n",
      "14000 0.5 0.639999999999862\n",
      "14500 0.2 0.5949999999998448\n",
      "15000 -0.4 0.5499999999998275\n",
      "15500 0.6 0.5049999999998103\n",
      "16000 -0.3 0.4599999999998177\n",
      "16500 -0.1 0.41499999999982823\n",
      "17000 -0.7 0.36999999999983874\n",
      "17500 0.0 0.32499999999984924\n",
      "18000 -0.1 0.27999999999985975\n",
      "18500 0.4 0.23499999999986562\n",
      "19000 -0.2 0.18999999999986225\n",
      "19500 0.4 0.14499999999985888\n",
      "20000 0.3 0.09999999999985551\n",
      "20500 -0.5 0.09999999999985551\n",
      "21000 0.1 0.09999999999985551\n",
      "21500 0.1 0.09999999999985551\n",
      "22000 0.2 0.09999999999985551\n",
      "22500 0.3 0.09999999999985551\n",
      "23000 0.2 0.09999999999985551\n",
      "23500 -0.3 0.09999999999985551\n",
      "24000 0.2 0.09999999999985551\n",
      "24500 -0.1 0.09999999999985551\n",
      "25000 0.3 0.09999999999985551\n",
      "25500 0.4 0.09999999999985551\n",
      "26000 -0.4 0.09999999999985551\n",
      "26500 0.4 0.09999999999985551\n",
      "27000 0.3 0.09999999999985551\n",
      "27500 -0.1 0.09999999999985551\n",
      "28000 0.7 0.09999999999985551\n",
      "28500 0.4 0.09999999999985551\n",
      "29000 0.2 0.09999999999985551\n",
      "29500 0.6 0.09999999999985551\n",
      "30000 0.4 0.09999999999985551\n",
      "30500 0.9 0.09999999999985551\n",
      "31000 0.4 0.09999999999985551\n",
      "31500 0.2 0.09999999999985551\n",
      "32000 -0.3 0.09999999999985551\n",
      "32500 0.5 0.09999999999985551\n",
      "33000 0.0 0.09999999999985551\n",
      "33500 -0.2 0.09999999999985551\n",
      "34000 0.1 0.09999999999985551\n",
      "34500 0.2 0.09999999999985551\n",
      "35000 0.0 0.09999999999985551\n",
      "35500 1.0 0.09999999999985551\n",
      "36000 -0.3 0.09999999999985551\n",
      "36500 0.8 0.09999999999985551\n",
      "37000 0.7 0.09999999999985551\n",
      "37500 0.4 0.09999999999985551\n",
      "38000 0.7 0.09999999999985551\n",
      "38500 0.7 0.09999999999985551\n",
      "39000 0.9 0.09999999999985551\n",
      "39500 1.2 0.09999999999985551\n",
      "40000 0.9 0.09999999999985551\n",
      "40500 0.8 0.09999999999985551\n",
      "41000 0.1 0.09999999999985551\n",
      "41500 0.7 0.09999999999985551\n",
      "42000 -0.1 0.09999999999985551\n",
      "42500 0.5 0.09999999999985551\n",
      "43000 0.8 0.09999999999985551\n",
      "43500 0.3 0.09999999999985551\n",
      "44000 0.5 0.09999999999985551\n",
      "44500 1.1 0.09999999999985551\n",
      "45000 0.3 0.09999999999985551\n",
      "45500 0.2 0.09999999999985551\n",
      "46000 0.0 0.09999999999985551\n",
      "46500 0.6 0.09999999999985551\n",
      "47000 0.5 0.09999999999985551\n",
      "47500 1.4 0.09999999999985551\n",
      "48000 0.7 0.09999999999985551\n",
      "48500 0.4 0.09999999999985551\n",
      "49000 1.8 0.09999999999985551\n",
      "49500 0.8 0.09999999999985551\n",
      "50000 0.9 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.4 0.09999999999985551\n",
      "51000 0.9 0.09999999999985551\n",
      "51500 0.7 0.09999999999985551\n",
      "52000 1.5 0.09999999999985551\n",
      "52500 1.4 0.09999999999985551\n",
      "53000 2.0 0.09999999999985551\n",
      "53500 1.1 0.09999999999985551\n",
      "54000 1.5 0.09999999999985551\n",
      "54500 1.7 0.09999999999985551\n",
      "55000 -0.3 0.09999999999985551\n",
      "55500 0.6 0.09999999999985551\n",
      "56000 0.5 0.09999999999985551\n",
      "56500 0.1 0.09999999999985551\n",
      "57000 1.5 0.09999999999985551\n",
      "57500 1.9 0.09999999999985551\n",
      "58000 0.6 0.09999999999985551\n",
      "58500 0.2 0.09999999999985551\n",
      "59000 0.1 0.09999999999985551\n",
      "59500 1.4 0.09999999999985551\n",
      "60000 0.1 0.09999999999985551\n",
      "60500 0.9 0.09999999999985551\n",
      "61000 2.9 0.09999999999985551\n",
      "61500 1.7 0.09999999999985551\n",
      "62000 1.4 0.09999999999985551\n",
      "62500 1.0 0.09999999999985551\n",
      "63000 1.8 0.09999999999985551\n",
      "63500 1.7 0.09999999999985551\n",
      "64000 1.0 0.09999999999985551\n",
      "64500 1.0 0.09999999999985551\n",
      "65000 0.7 0.09999999999985551\n",
      "65500 2.8 0.09999999999985551\n",
      "66000 1.5 0.09999999999985551\n",
      "66500 2.7 0.09999999999985551\n",
      "67000 2.2 0.09999999999985551\n",
      "67500 1.6 0.09999999999985551\n",
      "68000 1.1 0.09999999999985551\n",
      "68500 2.2 0.09999999999985551\n",
      "69000 3.0 0.09999999999985551\n",
      "69500 1.8 0.09999999999985551\n",
      "70000 3.3 0.09999999999985551\n",
      "70500 2.7 0.09999999999985551\n",
      "71000 2.6 0.09999999999985551\n",
      "71500 2.0 0.09999999999985551\n",
      "72000 1.4 0.09999999999985551\n",
      "72500 2.0 0.09999999999985551\n",
      "73000 1.9 0.09999999999985551\n",
      "73500 2.6 0.09999999999985551\n",
      "74000 2.3 0.09999999999985551\n",
      "74500 3.9 0.09999999999985551\n",
      "75000 2.7 0.09999999999985551\n",
      "75500 3.6 0.09999999999985551\n",
      "76000 4.7 0.09999999999985551\n",
      "76500 2.0 0.09999999999985551\n",
      "77000 2.2 0.09999999999985551\n",
      "77500 4.0 0.09999999999985551\n",
      "78000 1.1 0.09999999999985551\n",
      "78500 3.9 0.09999999999985551\n",
      "79000 3.7 0.09999999999985551\n",
      "79500 3.9 0.09999999999985551\n",
      "80000 3.4 0.09999999999985551\n",
      "80500 6.6 0.09999999999985551\n",
      "81000 4.6 0.09999999999985551\n",
      "81500 5.7 0.09999999999985551\n",
      "82000 5.5 0.09999999999985551\n",
      "82500 3.9 0.09999999999985551\n",
      "83000 4.9 0.09999999999985551\n",
      "83500 3.3 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84000 4.3 0.09999999999985551\n",
      "84500 7.3 0.09999999999985551\n",
      "85000 4.5 0.09999999999985551\n",
      "85500 4.1 0.09999999999985551\n",
      "86000 5.2 0.09999999999985551\n",
      "86500 3.3 0.09999999999985551\n",
      "87000 3.7 0.09999999999985551\n",
      "87500 6.7 0.09999999999985551\n",
      "88000 7.3 0.09999999999985551\n",
      "88500 5.4 0.09999999999985551\n",
      "89000 7.0 0.09999999999985551\n",
      "89500 6.9 0.09999999999985551\n",
      "90000 6.2 0.09999999999985551\n",
      "90500 4.3 0.09999999999985551\n",
      "91000 6.1 0.09999999999985551\n",
      "91500 3.6 0.09999999999985551\n",
      "92000 5.9 0.09999999999985551\n",
      "92500 4.9 0.09999999999985551\n",
      "93000 5.5 0.09999999999985551\n",
      "93500 7.1 0.09999999999985551\n",
      "94000 4.8 0.09999999999985551\n",
      "94500 6.5 0.09999999999985551\n",
      "95000 8.0 0.09999999999985551\n",
      "95500 5.7 0.09999999999985551\n",
      "96000 8.5 0.09999999999985551\n",
      "96500 8.0 0.09999999999985551\n",
      "97000 6.2 0.09999999999985551\n",
      "97500 8.6 0.09999999999985551\n",
      "98000 9.4 0.09999999999985551\n",
      "98500 9.3 0.09999999999985551\n",
      "99000 5.9 0.09999999999985551\n",
      "99500 6.4 0.09999999999985551\n",
      "100000 7.8 0.09999999999985551\n",
      "Saved Model\n",
      "100500 6.1 0.09999999999985551\n",
      "101000 10.6 0.09999999999985551\n",
      "101500 5.2 0.09999999999985551\n",
      "102000 8.4 0.09999999999985551\n",
      "102500 6.1 0.09999999999985551\n",
      "103000 8.6 0.09999999999985551\n",
      "103500 8.5 0.09999999999985551\n",
      "104000 6.8 0.09999999999985551\n",
      "104500 8.0 0.09999999999985551\n",
      "105000 8.0 0.09999999999985551\n",
      "105500 6.0 0.09999999999985551\n",
      "106000 7.7 0.09999999999985551\n",
      "106500 6.6 0.09999999999985551\n",
      "107000 6.6 0.09999999999985551\n",
      "107500 6.0 0.09999999999985551\n",
      "108000 10.0 0.09999999999985551\n",
      "108500 11.7 0.09999999999985551\n",
      "109000 7.9 0.09999999999985551\n",
      "109500 8.8 0.09999999999985551\n",
      "110000 6.3 0.09999999999985551\n",
      "110500 7.1 0.09999999999985551\n",
      "111000 8.5 0.09999999999985551\n",
      "111500 6.7 0.09999999999985551\n",
      "112000 7.3 0.09999999999985551\n",
      "112500 8.2 0.09999999999985551\n",
      "113000 8.0 0.09999999999985551\n",
      "113500 5.9 0.09999999999985551\n",
      "114000 9.1 0.09999999999985551\n",
      "114500 8.8 0.09999999999985551\n",
      "115000 9.5 0.09999999999985551\n",
      "115500 3.3 0.09999999999985551\n",
      "116000 8.2 0.09999999999985551\n",
      "116500 8.9 0.09999999999985551\n",
      "117000 7.2 0.09999999999985551\n",
      "117500 7.9 0.09999999999985551\n",
      "118000 10.3 0.09999999999985551\n",
      "118500 8.5 0.09999999999985551\n",
      "119000 7.4 0.09999999999985551\n",
      "119500 5.2 0.09999999999985551\n",
      "120000 8.9 0.09999999999985551\n",
      "120500 5.9 0.09999999999985551\n",
      "121000 8.1 0.09999999999985551\n",
      "121500 10.0 0.09999999999985551\n",
      "122000 8.1 0.09999999999985551\n",
      "122500 9.0 0.09999999999985551\n",
      "123000 6.9 0.09999999999985551\n",
      "123500 7.7 0.09999999999985551\n",
      "124000 6.3 0.09999999999985551\n",
      "124500 9.6 0.09999999999985551\n",
      "125000 5.5 0.09999999999985551\n",
      "125500 6.2 0.09999999999985551\n",
      "126000 10.4 0.09999999999985551\n",
      "126500 8.3 0.09999999999985551\n",
      "127000 8.0 0.09999999999985551\n",
      "127500 9.0 0.09999999999985551\n",
      "128000 8.0 0.09999999999985551\n",
      "128500 6.3 0.09999999999985551\n",
      "129000 9.4 0.09999999999985551\n",
      "129500 6.4 0.09999999999985551\n",
      "130000 9.3 0.09999999999985551\n",
      "130500 11.0 0.09999999999985551\n",
      "131000 8.9 0.09999999999985551\n",
      "131500 10.2 0.09999999999985551\n",
      "132000 12.1 0.09999999999985551\n",
      "132500 8.9 0.09999999999985551\n",
      "133000 8.9 0.09999999999985551\n",
      "133500 4.9 0.09999999999985551\n",
      "134000 9.4 0.09999999999985551\n",
      "134500 8.9 0.09999999999985551\n",
      "135000 9.3 0.09999999999985551\n",
      "135500 9.0 0.09999999999985551\n",
      "136000 7.8 0.09999999999985551\n",
      "136500 8.5 0.09999999999985551\n",
      "137000 8.7 0.09999999999985551\n",
      "137500 7.2 0.09999999999985551\n",
      "138000 9.3 0.09999999999985551\n",
      "138500 9.3 0.09999999999985551\n",
      "139000 8.3 0.09999999999985551\n",
      "139500 9.6 0.09999999999985551\n",
      "140000 7.4 0.09999999999985551\n",
      "140500 8.0 0.09999999999985551\n",
      "141000 7.8 0.09999999999985551\n",
      "141500 8.0 0.09999999999985551\n",
      "142000 11.9 0.09999999999985551\n",
      "142500 9.4 0.09999999999985551\n",
      "143000 11.1 0.09999999999985551\n",
      "143500 11.0 0.09999999999985551\n",
      "144000 11.1 0.09999999999985551\n",
      "144500 9.8 0.09999999999985551\n",
      "145000 10.0 0.09999999999985551\n",
      "145500 11.4 0.09999999999985551\n",
      "146000 6.3 0.09999999999985551\n",
      "146500 8.8 0.09999999999985551\n",
      "147000 8.7 0.09999999999985551\n",
      "147500 10.8 0.09999999999985551\n",
      "148000 9.3 0.09999999999985551\n",
      "148500 10.7 0.09999999999985551\n",
      "149000 6.0 0.09999999999985551\n",
      "149500 8.3 0.09999999999985551\n",
      "150000 8.0 0.09999999999985551\n",
      "Saved Model\n",
      "150500 7.9 0.09999999999985551\n",
      "151000 12.6 0.09999999999985551\n",
      "151500 10.1 0.09999999999985551\n",
      "152000 10.3 0.09999999999985551\n",
      "152500 11.4 0.09999999999985551\n",
      "153000 7.6 0.09999999999985551\n",
      "153500 8.8 0.09999999999985551\n",
      "154000 9.8 0.09999999999985551\n",
      "154500 11.8 0.09999999999985551\n",
      "155000 14.6 0.09999999999985551\n",
      "155500 10.5 0.09999999999985551\n",
      "156000 6.8 0.09999999999985551\n",
      "156500 11.3 0.09999999999985551\n",
      "157000 10.1 0.09999999999985551\n",
      "157500 9.1 0.09999999999985551\n",
      "158000 10.9 0.09999999999985551\n",
      "158500 9.0 0.09999999999985551\n",
      "159000 5.7 0.09999999999985551\n",
      "159500 8.7 0.09999999999985551\n",
      "160000 11.6 0.09999999999985551\n",
      "160500 8.6 0.09999999999985551\n",
      "161000 10.1 0.09999999999985551\n",
      "161500 11.7 0.09999999999985551\n",
      "162000 9.4 0.09999999999985551\n",
      "162500 5.3 0.09999999999985551\n",
      "163000 10.3 0.09999999999985551\n",
      "163500 9.2 0.09999999999985551\n",
      "164000 10.0 0.09999999999985551\n",
      "164500 11.3 0.09999999999985551\n",
      "165000 10.5 0.09999999999985551\n",
      "165500 8.9 0.09999999999985551\n",
      "166000 10.7 0.09999999999985551\n",
      "166500 11.1 0.09999999999985551\n",
      "167000 9.6 0.09999999999985551\n",
      "167500 12.9 0.09999999999985551\n",
      "168000 10.4 0.09999999999985551\n",
      "168500 10.6 0.09999999999985551\n",
      "169000 10.4 0.09999999999985551\n",
      "169500 13.1 0.09999999999985551\n",
      "170000 9.3 0.09999999999985551\n",
      "170500 10.1 0.09999999999985551\n",
      "171000 9.2 0.09999999999985551\n",
      "171500 9.6 0.09999999999985551\n",
      "172000 9.5 0.09999999999985551\n",
      "172500 10.3 0.09999999999985551\n",
      "173000 7.9 0.09999999999985551\n",
      "173500 8.9 0.09999999999985551\n",
      "174000 10.3 0.09999999999985551\n",
      "174500 9.9 0.09999999999985551\n",
      "175000 11.8 0.09999999999985551\n",
      "175500 9.1 0.09999999999985551\n",
      "176000 8.9 0.09999999999985551\n",
      "176500 11.0 0.09999999999985551\n",
      "177000 12.5 0.09999999999985551\n",
      "177500 12.9 0.09999999999985551\n",
      "178000 8.7 0.09999999999985551\n",
      "178500 10.3 0.09999999999985551\n",
      "179000 6.2 0.09999999999985551\n",
      "179500 9.9 0.09999999999985551\n",
      "180000 11.6 0.09999999999985551\n",
      "180500 9.7 0.09999999999985551\n",
      "181000 8.9 0.09999999999985551\n",
      "181500 10.0 0.09999999999985551\n",
      "182000 11.7 0.09999999999985551\n",
      "182500 11.5 0.09999999999985551\n",
      "183000 10.2 0.09999999999985551\n",
      "183500 10.2 0.09999999999985551\n",
      "184000 9.9 0.09999999999985551\n",
      "184500 11.7 0.09999999999985551\n",
      "185000 12.7 0.09999999999985551\n",
      "185500 8.6 0.09999999999985551\n",
      "186000 7.3 0.09999999999985551\n",
      "186500 8.2 0.09999999999985551\n",
      "187000 7.1 0.09999999999985551\n",
      "187500 8.8 0.09999999999985551\n",
      "188000 7.6 0.09999999999985551\n",
      "188500 10.2 0.09999999999985551\n",
      "189000 11.1 0.09999999999985551\n",
      "189500 11.1 0.09999999999985551\n",
      "190000 11.2 0.09999999999985551\n",
      "190500 7.8 0.09999999999985551\n",
      "191000 11.2 0.09999999999985551\n",
      "191500 8.3 0.09999999999985551\n",
      "192000 9.8 0.09999999999985551\n",
      "192500 9.6 0.09999999999985551\n",
      "193000 11.7 0.09999999999985551\n",
      "193500 10.4 0.09999999999985551\n",
      "194000 8.5 0.09999999999985551\n",
      "194500 9.0 0.09999999999985551\n",
      "195000 11.3 0.09999999999985551\n",
      "195500 10.4 0.09999999999985551\n",
      "196000 9.4 0.09999999999985551\n",
      "196500 6.9 0.09999999999985551\n",
      "197000 10.7 0.09999999999985551\n",
      "197500 10.7 0.09999999999985551\n",
      "198000 12.1 0.09999999999985551\n",
      "198500 10.2 0.09999999999985551\n",
      "199000 10.9 0.09999999999985551\n",
      "199500 13.3 0.09999999999985551\n",
      "200000 11.4 0.09999999999985551\n",
      "Saved Model\n",
      "200500 11.6 0.09999999999985551\n",
      "201000 11.3 0.09999999999985551\n",
      "201500 8.5 0.09999999999985551\n",
      "202000 11.9 0.09999999999985551\n",
      "202500 9.3 0.09999999999985551\n",
      "203000 10.3 0.09999999999985551\n",
      "203500 12.1 0.09999999999985551\n",
      "204000 11.4 0.09999999999985551\n",
      "204500 11.3 0.09999999999985551\n",
      "205000 11.6 0.09999999999985551\n",
      "205500 9.8 0.09999999999985551\n",
      "206000 13.6 0.09999999999985551\n",
      "206500 10.4 0.09999999999985551\n",
      "207000 11.0 0.09999999999985551\n",
      "207500 10.6 0.09999999999985551\n",
      "208000 9.8 0.09999999999985551\n",
      "208500 11.7 0.09999999999985551\n",
      "209000 11.3 0.09999999999985551\n",
      "209500 11.9 0.09999999999985551\n",
      "210000 11.6 0.09999999999985551\n",
      "210500 8.5 0.09999999999985551\n",
      "211000 14.3 0.09999999999985551\n",
      "211500 8.7 0.09999999999985551\n",
      "212000 10.1 0.09999999999985551\n",
      "212500 8.9 0.09999999999985551\n",
      "213000 13.5 0.09999999999985551\n",
      "213500 12.7 0.09999999999985551\n",
      "214000 11.8 0.09999999999985551\n",
      "214500 12.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215000 10.5 0.09999999999985551\n",
      "215500 11.2 0.09999999999985551\n",
      "216000 8.6 0.09999999999985551\n",
      "216500 9.6 0.09999999999985551\n",
      "217000 9.7 0.09999999999985551\n",
      "217500 14.4 0.09999999999985551\n",
      "218000 11.8 0.09999999999985551\n",
      "218500 9.0 0.09999999999985551\n",
      "219000 13.1 0.09999999999985551\n",
      "219500 10.4 0.09999999999985551\n",
      "220000 10.4 0.09999999999985551\n",
      "220500 10.9 0.09999999999985551\n",
      "221000 7.2 0.09999999999985551\n",
      "221500 11.0 0.09999999999985551\n",
      "222000 12.6 0.09999999999985551\n",
      "222500 10.5 0.09999999999985551\n",
      "223000 11.8 0.09999999999985551\n",
      "223500 14.2 0.09999999999985551\n",
      "224000 11.2 0.09999999999985551\n",
      "224500 11.1 0.09999999999985551\n",
      "225000 12.3 0.09999999999985551\n",
      "225500 14.1 0.09999999999985551\n",
      "226000 9.4 0.09999999999985551\n",
      "226500 12.6 0.09999999999985551\n",
      "227000 16.7 0.09999999999985551\n",
      "227500 11.6 0.09999999999985551\n",
      "228000 12.6 0.09999999999985551\n",
      "228500 12.1 0.09999999999985551\n",
      "229000 11.5 0.09999999999985551\n",
      "229500 8.9 0.09999999999985551\n",
      "230000 8.5 0.09999999999985551\n",
      "230500 11.7 0.09999999999985551\n",
      "231000 10.3 0.09999999999985551\n",
      "231500 11.7 0.09999999999985551\n",
      "232000 12.9 0.09999999999985551\n",
      "232500 12.0 0.09999999999985551\n",
      "233000 14.2 0.09999999999985551\n",
      "233500 8.4 0.09999999999985551\n",
      "234000 9.9 0.09999999999985551\n",
      "234500 11.6 0.09999999999985551\n",
      "235000 10.9 0.09999999999985551\n",
      "235500 12.7 0.09999999999985551\n",
      "236000 11.3 0.09999999999985551\n",
      "236500 9.6 0.09999999999985551\n",
      "237000 13.2 0.09999999999985551\n",
      "237500 12.4 0.09999999999985551\n",
      "238000 10.6 0.09999999999985551\n",
      "238500 11.6 0.09999999999985551\n",
      "239000 8.8 0.09999999999985551\n",
      "239500 9.0 0.09999999999985551\n",
      "240000 13.5 0.09999999999985551\n",
      "240500 14.3 0.09999999999985551\n",
      "241000 13.0 0.09999999999985551\n",
      "241500 8.8 0.09999999999985551\n",
      "242000 13.1 0.09999999999985551\n",
      "242500 12.6 0.09999999999985551\n",
      "243000 13.9 0.09999999999985551\n",
      "243500 11.7 0.09999999999985551\n",
      "244000 13.0 0.09999999999985551\n",
      "244500 12.8 0.09999999999985551\n",
      "245000 9.9 0.09999999999985551\n",
      "245500 9.8 0.09999999999985551\n",
      "246000 14.0 0.09999999999985551\n",
      "246500 13.2 0.09999999999985551\n",
      "247000 10.2 0.09999999999985551\n",
      "247500 9.5 0.09999999999985551\n",
      "248000 9.7 0.09999999999985551\n",
      "248500 9.0 0.09999999999985551\n",
      "249000 14.7 0.09999999999985551\n",
      "249500 7.7 0.09999999999985551\n",
      "250000 8.9 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 10.3 0.09999999999985551\n",
      "251000 13.1 0.09999999999985551\n",
      "251500 9.6 0.09999999999985551\n",
      "252000 8.8 0.09999999999985551\n",
      "252500 12.8 0.09999999999985551\n",
      "253000 11.8 0.09999999999985551\n",
      "253500 10.8 0.09999999999985551\n",
      "254000 12.5 0.09999999999985551\n",
      "254500 10.4 0.09999999999985551\n",
      "255000 9.4 0.09999999999985551\n",
      "255500 10.4 0.09999999999985551\n",
      "256000 11.7 0.09999999999985551\n",
      "256500 10.9 0.09999999999985551\n",
      "257000 13.2 0.09999999999985551\n",
      "257500 9.8 0.09999999999985551\n",
      "258000 9.7 0.09999999999985551\n",
      "258500 9.1 0.09999999999985551\n",
      "259000 13.6 0.09999999999985551\n",
      "259500 10.3 0.09999999999985551\n",
      "260000 12.4 0.09999999999985551\n",
      "260500 9.6 0.09999999999985551\n",
      "261000 9.4 0.09999999999985551\n",
      "261500 11.5 0.09999999999985551\n",
      "262000 9.4 0.09999999999985551\n",
      "262500 12.4 0.09999999999985551\n",
      "263000 10.3 0.09999999999985551\n",
      "263500 8.0 0.09999999999985551\n",
      "264000 9.8 0.09999999999985551\n",
      "264500 15.5 0.09999999999985551\n",
      "265000 8.8 0.09999999999985551\n",
      "265500 8.0 0.09999999999985551\n",
      "266000 10.7 0.09999999999985551\n",
      "266500 9.0 0.09999999999985551\n",
      "267000 9.4 0.09999999999985551\n",
      "267500 13.7 0.09999999999985551\n",
      "268000 12.7 0.09999999999985551\n",
      "268500 10.4 0.09999999999985551\n",
      "269000 12.3 0.09999999999985551\n",
      "269500 9.6 0.09999999999985551\n",
      "270000 12.0 0.09999999999985551\n",
      "270500 9.8 0.09999999999985551\n",
      "271000 13.3 0.09999999999985551\n",
      "271500 9.3 0.09999999999985551\n",
      "272000 13.7 0.09999999999985551\n",
      "272500 10.3 0.09999999999985551\n",
      "273000 14.5 0.09999999999985551\n",
      "273500 9.6 0.09999999999985551\n",
      "274000 8.1 0.09999999999985551\n",
      "274500 11.7 0.09999999999985551\n",
      "275000 13.9 0.09999999999985551\n",
      "275500 10.5 0.09999999999985551\n",
      "276000 11.5 0.09999999999985551\n",
      "276500 13.5 0.09999999999985551\n",
      "277000 8.7 0.09999999999985551\n",
      "277500 8.6 0.09999999999985551\n",
      "278000 10.5 0.09999999999985551\n",
      "278500 11.1 0.09999999999985551\n",
      "279000 10.9 0.09999999999985551\n",
      "279500 10.1 0.09999999999985551\n",
      "280000 9.6 0.09999999999985551\n",
      "280500 11.8 0.09999999999985551\n",
      "281000 12.3 0.09999999999985551\n",
      "281500 8.7 0.09999999999985551\n",
      "282000 9.9 0.09999999999985551\n",
      "282500 11.9 0.09999999999985551\n",
      "283000 10.8 0.09999999999985551\n",
      "283500 10.9 0.09999999999985551\n",
      "284000 11.0 0.09999999999985551\n",
      "284500 13.1 0.09999999999985551\n",
      "285000 6.3 0.09999999999985551\n",
      "285500 11.1 0.09999999999985551\n",
      "286000 10.9 0.09999999999985551\n",
      "286500 10.7 0.09999999999985551\n",
      "287000 8.3 0.09999999999985551\n",
      "287500 15.4 0.09999999999985551\n",
      "288000 11.1 0.09999999999985551\n",
      "288500 8.1 0.09999999999985551\n",
      "289000 12.7 0.09999999999985551\n",
      "289500 12.2 0.09999999999985551\n",
      "290000 11.7 0.09999999999985551\n",
      "290500 10.5 0.09999999999985551\n",
      "291000 10.6 0.09999999999985551\n",
      "291500 10.5 0.09999999999985551\n",
      "292000 10.6 0.09999999999985551\n",
      "292500 10.1 0.09999999999985551\n",
      "293000 12.3 0.09999999999985551\n",
      "293500 11.6 0.09999999999985551\n",
      "294000 10.0 0.09999999999985551\n",
      "294500 11.1 0.09999999999985551\n",
      "295000 12.8 0.09999999999985551\n",
      "295500 9.4 0.09999999999985551\n",
      "296000 7.4 0.09999999999985551\n",
      "296500 9.4 0.09999999999985551\n",
      "297000 9.8 0.09999999999985551\n",
      "297500 10.0 0.09999999999985551\n",
      "298000 12.6 0.09999999999985551\n",
      "298500 13.8 0.09999999999985551\n",
      "299000 11.0 0.09999999999985551\n",
      "299500 12.7 0.09999999999985551\n",
      "300000 10.6 0.09999999999985551\n",
      "Saved Model\n",
      "300500 12.6 0.09999999999985551\n",
      "301000 12.5 0.09999999999985551\n",
      "301500 10.4 0.09999999999985551\n",
      "302000 6.8 0.09999999999985551\n",
      "302500 10.4 0.09999999999985551\n",
      "303000 11.0 0.09999999999985551\n",
      "303500 12.9 0.09999999999985551\n",
      "304000 11.3 0.09999999999985551\n",
      "304500 9.5 0.09999999999985551\n",
      "305000 12.2 0.09999999999985551\n",
      "305500 9.4 0.09999999999985551\n",
      "306000 11.9 0.09999999999985551\n",
      "306500 11.4 0.09999999999985551\n",
      "307000 8.4 0.09999999999985551\n",
      "307500 12.3 0.09999999999985551\n",
      "308000 14.4 0.09999999999985551\n",
      "308500 11.2 0.09999999999985551\n",
      "309000 9.9 0.09999999999985551\n",
      "309500 12.5 0.09999999999985551\n",
      "310000 10.1 0.09999999999985551\n",
      "310500 13.0 0.09999999999985551\n",
      "311000 13.9 0.09999999999985551\n",
      "311500 10.8 0.09999999999985551\n",
      "312000 12.8 0.09999999999985551\n",
      "312500 13.2 0.09999999999985551\n",
      "313000 11.4 0.09999999999985551\n",
      "313500 10.6 0.09999999999985551\n",
      "314000 10.9 0.09999999999985551\n",
      "314500 9.5 0.09999999999985551\n",
      "315000 7.4 0.09999999999985551\n",
      "315500 6.5 0.09999999999985551\n",
      "316000 9.3 0.09999999999985551\n",
      "316500 9.6 0.09999999999985551\n",
      "317000 12.8 0.09999999999985551\n",
      "317500 11.2 0.09999999999985551\n",
      "318000 7.7 0.09999999999985551\n",
      "318500 10.5 0.09999999999985551\n",
      "319000 9.0 0.09999999999985551\n",
      "319500 13.5 0.09999999999985551\n",
      "320000 12.1 0.09999999999985551\n",
      "320500 9.6 0.09999999999985551\n",
      "321000 10.0 0.09999999999985551\n",
      "321500 9.0 0.09999999999985551\n",
      "322000 10.9 0.09999999999985551\n",
      "322500 12.2 0.09999999999985551\n",
      "323000 13.3 0.09999999999985551\n",
      "323500 12.3 0.09999999999985551\n",
      "324000 12.0 0.09999999999985551\n",
      "324500 11.1 0.09999999999985551\n",
      "325000 10.9 0.09999999999985551\n",
      "325500 11.3 0.09999999999985551\n",
      "326000 15.0 0.09999999999985551\n",
      "326500 11.1 0.09999999999985551\n",
      "327000 13.1 0.09999999999985551\n",
      "327500 11.1 0.09999999999985551\n",
      "328000 12.2 0.09999999999985551\n",
      "328500 10.1 0.09999999999985551\n",
      "329000 10.1 0.09999999999985551\n",
      "329500 12.8 0.09999999999985551\n",
      "330000 8.3 0.09999999999985551\n",
      "330500 10.8 0.09999999999985551\n",
      "331000 10.0 0.09999999999985551\n",
      "331500 10.3 0.09999999999985551\n",
      "332000 15.9 0.09999999999985551\n",
      "332500 13.5 0.09999999999985551\n",
      "333000 8.7 0.09999999999985551\n",
      "333500 11.6 0.09999999999985551\n",
      "334000 11.9 0.09999999999985551\n",
      "334500 10.0 0.09999999999985551\n",
      "335000 9.7 0.09999999999985551\n",
      "335500 10.3 0.09999999999985551\n",
      "336000 13.1 0.09999999999985551\n",
      "336500 10.1 0.09999999999985551\n",
      "337000 12.9 0.09999999999985551\n",
      "337500 10.2 0.09999999999985551\n",
      "338000 12.2 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338500 12.5 0.09999999999985551\n",
      "339000 11.1 0.09999999999985551\n",
      "339500 8.3 0.09999999999985551\n",
      "340000 8.3 0.09999999999985551\n",
      "340500 11.5 0.09999999999985551\n",
      "341000 11.5 0.09999999999985551\n",
      "341500 11.5 0.09999999999985551\n",
      "342000 13.4 0.09999999999985551\n",
      "342500 9.2 0.09999999999985551\n",
      "343000 14.3 0.09999999999985551\n",
      "343500 8.7 0.09999999999985551\n",
      "344000 11.2 0.09999999999985551\n",
      "344500 13.1 0.09999999999985551\n",
      "345000 10.9 0.09999999999985551\n",
      "345500 10.5 0.09999999999985551\n",
      "346000 10.1 0.09999999999985551\n",
      "346500 14.2 0.09999999999985551\n",
      "347000 12.3 0.09999999999985551\n",
      "347500 8.8 0.09999999999985551\n",
      "348000 12.1 0.09999999999985551\n",
      "348500 10.2 0.09999999999985551\n",
      "349000 8.5 0.09999999999985551\n",
      "349500 9.4 0.09999999999985551\n",
      "350000 10.9 0.09999999999985551\n",
      "Saved Model\n",
      "350500 11.4 0.09999999999985551\n",
      "351000 11.9 0.09999999999985551\n",
      "351500 15.2 0.09999999999985551\n",
      "352000 8.8 0.09999999999985551\n",
      "352500 14.4 0.09999999999985551\n",
      "353000 15.5 0.09999999999985551\n",
      "353500 9.3 0.09999999999985551\n",
      "354000 10.0 0.09999999999985551\n",
      "354500 11.9 0.09999999999985551\n",
      "355000 14.1 0.09999999999985551\n",
      "355500 12.5 0.09999999999985551\n",
      "356000 10.8 0.09999999999985551\n",
      "356500 13.5 0.09999999999985551\n",
      "357000 8.2 0.09999999999985551\n",
      "357500 10.2 0.09999999999985551\n",
      "358000 11.6 0.09999999999985551\n",
      "358500 12.0 0.09999999999985551\n",
      "359000 11.5 0.09999999999985551\n",
      "359500 12.0 0.09999999999985551\n",
      "360000 10.5 0.09999999999985551\n",
      "360500 8.9 0.09999999999985551\n",
      "361000 10.0 0.09999999999985551\n",
      "361500 14.2 0.09999999999985551\n",
      "362000 9.3 0.09999999999985551\n",
      "362500 12.7 0.09999999999985551\n",
      "363000 12.4 0.09999999999985551\n",
      "363500 7.6 0.09999999999985551\n",
      "364000 10.9 0.09999999999985551\n",
      "364500 9.4 0.09999999999985551\n",
      "365000 11.5 0.09999999999985551\n",
      "365500 10.2 0.09999999999985551\n",
      "366000 10.3 0.09999999999985551\n",
      "366500 11.5 0.09999999999985551\n",
      "367000 12.4 0.09999999999985551\n",
      "367500 9.7 0.09999999999985551\n",
      "368000 10.6 0.09999999999985551\n",
      "368500 8.3 0.09999999999985551\n",
      "369000 11.4 0.09999999999985551\n",
      "369500 10.4 0.09999999999985551\n",
      "370000 12.8 0.09999999999985551\n",
      "370500 9.5 0.09999999999985551\n",
      "371000 13.5 0.09999999999985551\n",
      "371500 9.2 0.09999999999985551\n",
      "372000 13.0 0.09999999999985551\n",
      "372500 12.4 0.09999999999985551\n",
      "373000 8.7 0.09999999999985551\n",
      "373500 9.8 0.09999999999985551\n",
      "374000 12.0 0.09999999999985551\n",
      "374500 8.2 0.09999999999985551\n",
      "375000 11.6 0.09999999999985551\n",
      "375500 12.4 0.09999999999985551\n",
      "376000 8.4 0.09999999999985551\n",
      "376500 11.4 0.09999999999985551\n",
      "377000 11.4 0.09999999999985551\n",
      "377500 8.6 0.09999999999985551\n",
      "378000 11.8 0.09999999999985551\n",
      "378500 11.2 0.09999999999985551\n",
      "379000 9.2 0.09999999999985551\n",
      "379500 11.6 0.09999999999985551\n",
      "380000 12.0 0.09999999999985551\n",
      "380500 12.5 0.09999999999985551\n",
      "381000 10.8 0.09999999999985551\n",
      "381500 11.6 0.09999999999985551\n",
      "382000 11.2 0.09999999999985551\n",
      "382500 12.2 0.09999999999985551\n",
      "383000 11.6 0.09999999999985551\n",
      "383500 11.7 0.09999999999985551\n",
      "384000 10.3 0.09999999999985551\n",
      "384500 11.6 0.09999999999985551\n",
      "385000 12.0 0.09999999999985551\n",
      "385500 12.6 0.09999999999985551\n",
      "386000 10.2 0.09999999999985551\n",
      "386500 9.7 0.09999999999985551\n",
      "387000 13.5 0.09999999999985551\n",
      "387500 11.3 0.09999999999985551\n",
      "388000 13.4 0.09999999999985551\n",
      "388500 10.7 0.09999999999985551\n",
      "389000 12.9 0.09999999999985551\n",
      "389500 11.9 0.09999999999985551\n",
      "390000 14.5 0.09999999999985551\n",
      "390500 11.9 0.09999999999985551\n",
      "391000 11.6 0.09999999999985551\n",
      "391500 12.6 0.09999999999985551\n",
      "392000 12.0 0.09999999999985551\n",
      "392500 10.3 0.09999999999985551\n",
      "393000 11.0 0.09999999999985551\n",
      "393500 11.9 0.09999999999985551\n",
      "394000 14.4 0.09999999999985551\n",
      "394500 13.2 0.09999999999985551\n",
      "395000 10.1 0.09999999999985551\n",
      "395500 7.9 0.09999999999985551\n",
      "396000 11.5 0.09999999999985551\n",
      "396500 13.0 0.09999999999985551\n",
      "397000 10.9 0.09999999999985551\n",
      "397500 12.4 0.09999999999985551\n",
      "398000 12.1 0.09999999999985551\n",
      "398500 11.2 0.09999999999985551\n",
      "399000 11.7 0.09999999999985551\n",
      "399500 11.5 0.09999999999985551\n",
      "400000 13.0 0.09999999999985551\n",
      "Saved Model\n",
      "400500 11.5 0.09999999999985551\n",
      "401000 11.5 0.09999999999985551\n",
      "401500 13.8 0.09999999999985551\n",
      "402000 11.4 0.09999999999985551\n",
      "402500 8.7 0.09999999999985551\n",
      "403000 10.4 0.09999999999985551\n",
      "403500 15.3 0.09999999999985551\n",
      "404000 9.8 0.09999999999985551\n",
      "404500 12.5 0.09999999999985551\n",
      "405000 11.8 0.09999999999985551\n",
      "405500 13.7 0.09999999999985551\n",
      "406000 12.5 0.09999999999985551\n",
      "406500 10.2 0.09999999999985551\n",
      "407000 13.9 0.09999999999985551\n",
      "407500 9.2 0.09999999999985551\n",
      "408000 12.5 0.09999999999985551\n",
      "408500 13.6 0.09999999999985551\n",
      "409000 10.0 0.09999999999985551\n",
      "409500 10.4 0.09999999999985551\n",
      "410000 13.5 0.09999999999985551\n",
      "410500 14.3 0.09999999999985551\n",
      "411000 10.6 0.09999999999985551\n",
      "411500 10.2 0.09999999999985551\n",
      "412000 13.0 0.09999999999985551\n",
      "412500 13.0 0.09999999999985551\n",
      "413000 11.5 0.09999999999985551\n",
      "413500 10.3 0.09999999999985551\n",
      "414000 13.3 0.09999999999985551\n",
      "414500 9.3 0.09999999999985551\n",
      "415000 11.7 0.09999999999985551\n",
      "415500 11.8 0.09999999999985551\n",
      "416000 15.3 0.09999999999985551\n",
      "416500 13.6 0.09999999999985551\n",
      "417000 11.3 0.09999999999985551\n",
      "417500 12.1 0.09999999999985551\n",
      "418000 11.9 0.09999999999985551\n",
      "418500 13.8 0.09999999999985551\n",
      "419000 15.6 0.09999999999985551\n",
      "419500 7.7 0.09999999999985551\n",
      "420000 12.0 0.09999999999985551\n",
      "420500 9.4 0.09999999999985551\n",
      "421000 10.1 0.09999999999985551\n",
      "421500 13.9 0.09999999999985551\n",
      "422000 9.9 0.09999999999985551\n",
      "422500 11.2 0.09999999999985551\n",
      "423000 13.2 0.09999999999985551\n",
      "423500 7.9 0.09999999999985551\n",
      "424000 13.6 0.09999999999985551\n",
      "424500 10.9 0.09999999999985551\n",
      "425000 12.2 0.09999999999985551\n",
      "425500 15.1 0.09999999999985551\n",
      "426000 12.4 0.09999999999985551\n",
      "426500 9.2 0.09999999999985551\n",
      "427000 11.2 0.09999999999985551\n",
      "427500 13.4 0.09999999999985551\n",
      "428000 11.5 0.09999999999985551\n",
      "428500 12.3 0.09999999999985551\n",
      "429000 10.6 0.09999999999985551\n",
      "429500 13.9 0.09999999999985551\n",
      "430000 13.9 0.09999999999985551\n",
      "430500 12.1 0.09999999999985551\n",
      "431000 10.8 0.09999999999985551\n",
      "431500 10.4 0.09999999999985551\n",
      "432000 13.4 0.09999999999985551\n",
      "432500 13.0 0.09999999999985551\n",
      "433000 10.1 0.09999999999985551\n",
      "433500 10.5 0.09999999999985551\n",
      "434000 14.6 0.09999999999985551\n",
      "434500 10.9 0.09999999999985551\n",
      "435000 11.9 0.09999999999985551\n",
      "435500 14.2 0.09999999999985551\n",
      "436000 14.3 0.09999999999985551\n",
      "436500 11.8 0.09999999999985551\n",
      "437000 7.6 0.09999999999985551\n",
      "437500 11.2 0.09999999999985551\n",
      "438000 13.7 0.09999999999985551\n",
      "438500 10.3 0.09999999999985551\n",
      "439000 10.5 0.09999999999985551\n",
      "439500 10.6 0.09999999999985551\n",
      "440000 10.6 0.09999999999985551\n",
      "440500 12.1 0.09999999999985551\n",
      "441000 10.2 0.09999999999985551\n",
      "441500 12.6 0.09999999999985551\n",
      "442000 12.5 0.09999999999985551\n",
      "442500 8.8 0.09999999999985551\n",
      "443000 12.4 0.09999999999985551\n",
      "443500 10.4 0.09999999999985551\n",
      "444000 10.4 0.09999999999985551\n",
      "444500 11.7 0.09999999999985551\n",
      "445000 12.7 0.09999999999985551\n",
      "445500 12.5 0.09999999999985551\n",
      "446000 12.0 0.09999999999985551\n",
      "446500 10.8 0.09999999999985551\n",
      "447000 11.7 0.09999999999985551\n",
      "447500 11.5 0.09999999999985551\n",
      "448000 8.4 0.09999999999985551\n",
      "448500 11.2 0.09999999999985551\n",
      "449000 11.7 0.09999999999985551\n",
      "449500 13.8 0.09999999999985551\n",
      "450000 13.5 0.09999999999985551\n",
      "Saved Model\n",
      "450500 9.9 0.09999999999985551\n",
      "451000 13.8 0.09999999999985551\n",
      "451500 8.7 0.09999999999985551\n",
      "452000 13.5 0.09999999999985551\n",
      "452500 13.1 0.09999999999985551\n",
      "453000 12.0 0.09999999999985551\n",
      "453500 15.1 0.09999999999985551\n",
      "454000 9.8 0.09999999999985551\n",
      "454500 14.2 0.09999999999985551\n",
      "455000 10.5 0.09999999999985551\n",
      "455500 14.4 0.09999999999985551\n",
      "456000 11.5 0.09999999999985551\n",
      "456500 10.7 0.09999999999985551\n",
      "457000 9.2 0.09999999999985551\n",
      "457500 10.9 0.09999999999985551\n",
      "458000 12.7 0.09999999999985551\n",
      "458500 10.7 0.09999999999985551\n",
      "459000 11.5 0.09999999999985551\n",
      "459500 12.5 0.09999999999985551\n",
      "460000 10.5 0.09999999999985551\n",
      "460500 12.4 0.09999999999985551\n",
      "461000 10.1 0.09999999999985551\n",
      "461500 10.9 0.09999999999985551\n",
      "462000 15.6 0.09999999999985551\n",
      "462500 10.1 0.09999999999985551\n",
      "463000 12.2 0.09999999999985551\n",
      "463500 14.6 0.09999999999985551\n",
      "464000 12.7 0.09999999999985551\n",
      "464500 11.7 0.09999999999985551\n",
      "465000 10.1 0.09999999999985551\n",
      "465500 13.9 0.09999999999985551\n",
      "466000 14.5 0.09999999999985551\n",
      "466500 15.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467000 14.6 0.09999999999985551\n",
      "467500 13.3 0.09999999999985551\n",
      "468000 13.2 0.09999999999985551\n",
      "468500 11.4 0.09999999999985551\n",
      "469000 11.8 0.09999999999985551\n",
      "469500 10.0 0.09999999999985551\n",
      "470000 9.7 0.09999999999985551\n",
      "470500 14.2 0.09999999999985551\n",
      "471000 11.9 0.09999999999985551\n",
      "471500 11.8 0.09999999999985551\n",
      "472000 12.4 0.09999999999985551\n",
      "472500 9.4 0.09999999999985551\n",
      "473000 14.0 0.09999999999985551\n",
      "473500 12.1 0.09999999999985551\n",
      "474000 11.0 0.09999999999985551\n",
      "474500 11.5 0.09999999999985551\n",
      "475000 10.4 0.09999999999985551\n",
      "475500 11.5 0.09999999999985551\n",
      "476000 13.3 0.09999999999985551\n",
      "476500 10.9 0.09999999999985551\n",
      "477000 12.9 0.09999999999985551\n",
      "477500 10.7 0.09999999999985551\n",
      "478000 12.2 0.09999999999985551\n",
      "478500 11.0 0.09999999999985551\n",
      "479000 11.0 0.09999999999985551\n",
      "479500 8.7 0.09999999999985551\n",
      "480000 12.3 0.09999999999985551\n",
      "480500 11.0 0.09999999999985551\n",
      "481000 12.1 0.09999999999985551\n",
      "481500 9.1 0.09999999999985551\n",
      "482000 10.8 0.09999999999985551\n",
      "482500 9.0 0.09999999999985551\n",
      "483000 11.4 0.09999999999985551\n",
      "483500 12.8 0.09999999999985551\n",
      "484000 10.2 0.09999999999985551\n",
      "484500 12.9 0.09999999999985551\n",
      "485000 12.5 0.09999999999985551\n",
      "485500 14.5 0.09999999999985551\n",
      "486000 14.3 0.09999999999985551\n",
      "486500 11.4 0.09999999999985551\n",
      "487000 11.9 0.09999999999985551\n",
      "487500 11.7 0.09999999999985551\n",
      "488000 10.6 0.09999999999985551\n",
      "488500 12.4 0.09999999999985551\n",
      "489000 13.9 0.09999999999985551\n",
      "489500 14.0 0.09999999999985551\n",
      "490000 11.9 0.09999999999985551\n",
      "490500 7.9 0.09999999999985551\n",
      "491000 13.1 0.09999999999985551\n",
      "491500 11.6 0.09999999999985551\n",
      "492000 13.3 0.09999999999985551\n",
      "492500 10.4 0.09999999999985551\n",
      "493000 13.8 0.09999999999985551\n",
      "493500 11.2 0.09999999999985551\n",
      "494000 11.7 0.09999999999985551\n",
      "494500 11.8 0.09999999999985551\n",
      "495000 10.2 0.09999999999985551\n",
      "495500 12.2 0.09999999999985551\n",
      "496000 12.9 0.09999999999985551\n",
      "496500 12.9 0.09999999999985551\n",
      "497000 10.7 0.09999999999985551\n",
      "497500 13.1 0.09999999999985551\n",
      "498000 10.7 0.09999999999985551\n",
      "498500 13.4 0.09999999999985551\n",
      "499000 12.9 0.09999999999985551\n",
      "499500 9.4 0.09999999999985551\n",
      "500000 14.1 0.09999999999985551\n",
      "Percent of succesful episodes: 9.0415%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i+1000)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i+1000)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4220e92320>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b6576550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b65762b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b65762b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b65762b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b65762b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b6576da0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5b63780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5b63780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5b63780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5b63780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa7780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa76a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa76a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa76a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fd8b5aa76a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fd8b5aa7860>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 0.6 1\n",
      "1000 0.5 1\n",
      "1500 0.0 1\n",
      "2000 1.5 1\n",
      "2500 -0.7 1\n",
      "3000 -0.2 1\n",
      "3500 1.4 1\n",
      "4000 -1.0 1\n",
      "4500 0.3 1\n",
      "5000 0.3 1\n",
      "5500 -0.8 1\n",
      "6000 0.5 1\n",
      "6500 -1.3 1\n",
      "7000 -0.6 1\n",
      "7500 -0.7 1\n",
      "8000 1.3 1\n",
      "8500 -1.2 1\n",
      "9000 0.7 1\n",
      "9500 -0.8 1\n",
      "10000 0.7 1\n",
      "10500 -0.6 0.9549999999999828\n",
      "11000 -0.9 0.9099999999999655\n",
      "11500 0.0 0.8649999999999483\n",
      "12000 -0.4 0.819999999999931\n",
      "12500 0.1 0.7749999999999138\n",
      "13000 1.1 0.7299999999998965\n",
      "13500 0.6 0.6849999999998793\n",
      "14000 0.2 0.639999999999862\n",
      "14500 0.3 0.5949999999998448\n",
      "15000 -0.1 0.5499999999998275\n",
      "15500 -1.0 0.5049999999998103\n",
      "16000 0.8 0.4599999999998177\n",
      "16500 0.4 0.41499999999982823\n",
      "17000 0.0 0.36999999999983874\n",
      "17500 0.4 0.32499999999984924\n",
      "18000 -1.1 0.27999999999985975\n",
      "18500 0.5 0.23499999999986562\n",
      "19000 0.1 0.18999999999986225\n",
      "19500 0.4 0.14499999999985888\n",
      "20000 0.0 0.09999999999985551\n",
      "20500 0.0 0.09999999999985551\n",
      "21000 0.2 0.09999999999985551\n",
      "21500 0.9 0.09999999999985551\n",
      "22000 0.1 0.09999999999985551\n",
      "22500 -0.1 0.09999999999985551\n",
      "23000 0.5 0.09999999999985551\n",
      "23500 0.1 0.09999999999985551\n",
      "24000 0.4 0.09999999999985551\n",
      "24500 0.3 0.09999999999985551\n",
      "25000 -0.1 0.09999999999985551\n",
      "25500 -0.1 0.09999999999985551\n",
      "26000 0.5 0.09999999999985551\n",
      "26500 0.6 0.09999999999985551\n",
      "27000 -0.5 0.09999999999985551\n",
      "27500 1.0 0.09999999999985551\n",
      "28000 1.1 0.09999999999985551\n",
      "28500 0.4 0.09999999999985551\n",
      "29000 0.1 0.09999999999985551\n",
      "29500 0.1 0.09999999999985551\n",
      "30000 0.7 0.09999999999985551\n",
      "30500 0.2 0.09999999999985551\n",
      "31000 0.0 0.09999999999985551\n",
      "31500 0.2 0.09999999999985551\n",
      "32000 0.9 0.09999999999985551\n",
      "32500 0.9 0.09999999999985551\n",
      "33000 0.9 0.09999999999985551\n",
      "33500 0.4 0.09999999999985551\n",
      "34000 0.6 0.09999999999985551\n",
      "34500 0.4 0.09999999999985551\n",
      "35000 0.0 0.09999999999985551\n",
      "35500 0.4 0.09999999999985551\n",
      "36000 0.1 0.09999999999985551\n",
      "36500 1.1 0.09999999999985551\n",
      "37000 1.0 0.09999999999985551\n",
      "37500 -0.5 0.09999999999985551\n",
      "38000 0.4 0.09999999999985551\n",
      "38500 1.0 0.09999999999985551\n",
      "39000 0.1 0.09999999999985551\n",
      "39500 0.2 0.09999999999985551\n",
      "40000 0.4 0.09999999999985551\n",
      "40500 0.7 0.09999999999985551\n",
      "41000 1.7 0.09999999999985551\n",
      "41500 1.5 0.09999999999985551\n",
      "42000 0.6 0.09999999999985551\n",
      "42500 1.1 0.09999999999985551\n",
      "43000 0.6 0.09999999999985551\n",
      "43500 0.1 0.09999999999985551\n",
      "44000 0.7 0.09999999999985551\n",
      "44500 0.2 0.09999999999985551\n",
      "45000 1.2 0.09999999999985551\n",
      "45500 0.8 0.09999999999985551\n",
      "46000 0.7 0.09999999999985551\n",
      "46500 0.7 0.09999999999985551\n",
      "47000 1.9 0.09999999999985551\n",
      "47500 0.4 0.09999999999985551\n",
      "48000 2.4 0.09999999999985551\n",
      "48500 1.5 0.09999999999985551\n",
      "49000 0.5 0.09999999999985551\n",
      "49500 1.1 0.09999999999985551\n",
      "50000 2.3 0.09999999999985551\n",
      "Saved Model\n",
      "50500 1.7 0.09999999999985551\n",
      "51000 1.0 0.09999999999985551\n",
      "51500 2.8 0.09999999999985551\n",
      "52000 0.5 0.09999999999985551\n",
      "52500 1.1 0.09999999999985551\n",
      "53000 0.5 0.09999999999985551\n",
      "53500 0.6 0.09999999999985551\n",
      "54000 0.3 0.09999999999985551\n",
      "54500 1.6 0.09999999999985551\n",
      "55000 1.6 0.09999999999985551\n",
      "55500 1.0 0.09999999999985551\n",
      "56000 1.8 0.09999999999985551\n",
      "56500 2.9 0.09999999999985551\n",
      "57000 1.4 0.09999999999985551\n",
      "57500 0.5 0.09999999999985551\n",
      "58000 2.9 0.09999999999985551\n",
      "58500 1.5 0.09999999999985551\n",
      "59000 0.6 0.09999999999985551\n",
      "59500 1.4 0.09999999999985551\n",
      "60000 2.2 0.09999999999985551\n",
      "60500 2.7 0.09999999999985551\n",
      "61000 2.4 0.09999999999985551\n",
      "61500 3.2 0.09999999999985551\n",
      "62000 2.5 0.09999999999985551\n",
      "62500 2.4 0.09999999999985551\n",
      "63000 2.5 0.09999999999985551\n",
      "63500 2.4 0.09999999999985551\n",
      "64000 2.6 0.09999999999985551\n",
      "64500 1.0 0.09999999999985551\n",
      "65000 2.4 0.09999999999985551\n",
      "65500 1.6 0.09999999999985551\n",
      "66000 2.4 0.09999999999985551\n",
      "66500 4.9 0.09999999999985551\n",
      "67000 4.8 0.09999999999985551\n",
      "67500 2.0 0.09999999999985551\n",
      "68000 2.9 0.09999999999985551\n",
      "68500 3.9 0.09999999999985551\n",
      "69000 4.9 0.09999999999985551\n",
      "69500 6.7 0.09999999999985551\n",
      "70000 4.5 0.09999999999985551\n",
      "70500 1.7 0.09999999999985551\n",
      "71000 2.6 0.09999999999985551\n",
      "71500 1.6 0.09999999999985551\n",
      "72000 2.7 0.09999999999985551\n",
      "72500 1.6 0.09999999999985551\n",
      "73000 5.4 0.09999999999985551\n",
      "73500 5.1 0.09999999999985551\n",
      "74000 6.0 0.09999999999985551\n",
      "74500 5.9 0.09999999999985551\n",
      "75000 3.6 0.09999999999985551\n",
      "75500 2.2 0.09999999999985551\n",
      "76000 6.0 0.09999999999985551\n",
      "76500 6.3 0.09999999999985551\n",
      "77000 5.0 0.09999999999985551\n",
      "77500 5.1 0.09999999999985551\n",
      "78000 4.9 0.09999999999985551\n",
      "78500 6.8 0.09999999999985551\n",
      "79000 4.3 0.09999999999985551\n",
      "79500 6.8 0.09999999999985551\n",
      "80000 5.6 0.09999999999985551\n",
      "80500 6.7 0.09999999999985551\n",
      "81000 4.6 0.09999999999985551\n",
      "81500 2.2 0.09999999999985551\n",
      "82000 9.2 0.09999999999985551\n",
      "82500 6.3 0.09999999999985551\n",
      "83000 7.3 0.09999999999985551\n",
      "83500 7.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84000 5.4 0.09999999999985551\n",
      "84500 6.0 0.09999999999985551\n",
      "85000 7.0 0.09999999999985551\n",
      "85500 6.2 0.09999999999985551\n",
      "86000 9.2 0.09999999999985551\n",
      "86500 8.0 0.09999999999985551\n",
      "87000 7.9 0.09999999999985551\n",
      "87500 7.5 0.09999999999985551\n",
      "88000 9.0 0.09999999999985551\n",
      "88500 6.5 0.09999999999985551\n",
      "89000 9.9 0.09999999999985551\n",
      "89500 5.7 0.09999999999985551\n",
      "90000 7.1 0.09999999999985551\n",
      "90500 8.3 0.09999999999985551\n",
      "91000 9.7 0.09999999999985551\n",
      "91500 6.0 0.09999999999985551\n",
      "92000 6.4 0.09999999999985551\n",
      "92500 7.8 0.09999999999985551\n",
      "93000 9.7 0.09999999999985551\n",
      "93500 3.4 0.09999999999985551\n",
      "94000 8.2 0.09999999999985551\n",
      "94500 8.4 0.09999999999985551\n",
      "95000 6.5 0.09999999999985551\n",
      "95500 6.0 0.09999999999985551\n",
      "96000 6.2 0.09999999999985551\n",
      "96500 6.0 0.09999999999985551\n",
      "97000 7.1 0.09999999999985551\n",
      "97500 7.5 0.09999999999985551\n",
      "98000 6.9 0.09999999999985551\n",
      "98500 9.7 0.09999999999985551\n",
      "99000 4.6 0.09999999999985551\n",
      "99500 10.8 0.09999999999985551\n",
      "100000 5.1 0.09999999999985551\n",
      "Saved Model\n",
      "100500 9.6 0.09999999999985551\n",
      "101000 6.9 0.09999999999985551\n",
      "101500 10.0 0.09999999999985551\n",
      "102000 9.3 0.09999999999985551\n",
      "102500 11.5 0.09999999999985551\n",
      "103000 8.6 0.09999999999985551\n",
      "103500 8.2 0.09999999999985551\n",
      "104000 7.9 0.09999999999985551\n",
      "104500 8.9 0.09999999999985551\n",
      "105000 9.8 0.09999999999985551\n",
      "105500 9.5 0.09999999999985551\n",
      "106000 7.2 0.09999999999985551\n",
      "106500 9.2 0.09999999999985551\n",
      "107000 7.4 0.09999999999985551\n",
      "107500 9.4 0.09999999999985551\n",
      "108000 7.8 0.09999999999985551\n",
      "108500 6.9 0.09999999999985551\n",
      "109000 9.1 0.09999999999985551\n",
      "109500 9.9 0.09999999999985551\n",
      "110000 8.6 0.09999999999985551\n",
      "110500 11.3 0.09999999999985551\n",
      "111000 11.7 0.09999999999985551\n",
      "111500 11.2 0.09999999999985551\n",
      "112000 11.5 0.09999999999985551\n",
      "112500 7.6 0.09999999999985551\n",
      "113000 8.6 0.09999999999985551\n",
      "113500 13.1 0.09999999999985551\n",
      "114000 9.3 0.09999999999985551\n",
      "114500 7.8 0.09999999999985551\n",
      "115000 6.1 0.09999999999985551\n",
      "115500 8.0 0.09999999999985551\n",
      "116000 8.8 0.09999999999985551\n",
      "116500 10.6 0.09999999999985551\n",
      "117000 11.1 0.09999999999985551\n",
      "117500 11.3 0.09999999999985551\n",
      "118000 6.3 0.09999999999985551\n",
      "118500 9.1 0.09999999999985551\n",
      "119000 7.9 0.09999999999985551\n",
      "119500 12.4 0.09999999999985551\n",
      "120000 9.6 0.09999999999985551\n",
      "120500 6.0 0.09999999999985551\n",
      "121000 10.9 0.09999999999985551\n",
      "121500 11.5 0.09999999999985551\n",
      "122000 10.4 0.09999999999985551\n",
      "122500 10.2 0.09999999999985551\n",
      "123000 9.3 0.09999999999985551\n",
      "123500 9.2 0.09999999999985551\n",
      "124000 8.4 0.09999999999985551\n",
      "124500 8.8 0.09999999999985551\n",
      "125000 10.2 0.09999999999985551\n",
      "125500 10.5 0.09999999999985551\n",
      "126000 8.9 0.09999999999985551\n",
      "126500 11.7 0.09999999999985551\n",
      "127000 11.7 0.09999999999985551\n",
      "127500 11.6 0.09999999999985551\n",
      "128000 12.4 0.09999999999985551\n",
      "128500 7.9 0.09999999999985551\n",
      "129000 10.0 0.09999999999985551\n",
      "129500 7.1 0.09999999999985551\n",
      "130000 9.3 0.09999999999985551\n",
      "130500 9.2 0.09999999999985551\n",
      "131000 11.1 0.09999999999985551\n",
      "131500 8.8 0.09999999999985551\n",
      "132000 10.3 0.09999999999985551\n",
      "132500 9.4 0.09999999999985551\n",
      "133000 12.7 0.09999999999985551\n",
      "133500 12.7 0.09999999999985551\n",
      "134000 8.7 0.09999999999985551\n",
      "134500 11.9 0.09999999999985551\n",
      "135000 9.8 0.09999999999985551\n",
      "135500 7.6 0.09999999999985551\n",
      "136000 12.5 0.09999999999985551\n",
      "136500 10.2 0.09999999999985551\n",
      "137000 9.3 0.09999999999985551\n",
      "137500 7.3 0.09999999999985551\n",
      "138000 11.4 0.09999999999985551\n",
      "138500 10.2 0.09999999999985551\n",
      "139000 10.5 0.09999999999985551\n",
      "139500 10.6 0.09999999999985551\n",
      "140000 9.0 0.09999999999985551\n",
      "140500 9.3 0.09999999999985551\n",
      "141000 12.7 0.09999999999985551\n",
      "141500 11.0 0.09999999999985551\n",
      "142000 12.3 0.09999999999985551\n",
      "142500 12.1 0.09999999999985551\n",
      "143000 8.0 0.09999999999985551\n",
      "143500 10.1 0.09999999999985551\n",
      "144000 12.0 0.09999999999985551\n",
      "144500 9.5 0.09999999999985551\n",
      "145000 8.9 0.09999999999985551\n",
      "145500 12.6 0.09999999999985551\n",
      "146000 9.9 0.09999999999985551\n",
      "146500 12.8 0.09999999999985551\n",
      "147000 11.8 0.09999999999985551\n",
      "147500 13.0 0.09999999999985551\n",
      "148000 8.3 0.09999999999985551\n",
      "148500 8.9 0.09999999999985551\n",
      "149000 14.4 0.09999999999985551\n",
      "149500 10.7 0.09999999999985551\n",
      "150000 10.5 0.09999999999985551\n",
      "Saved Model\n",
      "150500 8.6 0.09999999999985551\n",
      "151000 11.8 0.09999999999985551\n",
      "151500 6.8 0.09999999999985551\n",
      "152000 7.8 0.09999999999985551\n",
      "152500 10.7 0.09999999999985551\n",
      "153000 8.2 0.09999999999985551\n",
      "153500 9.3 0.09999999999985551\n",
      "154000 10.3 0.09999999999985551\n",
      "154500 12.5 0.09999999999985551\n",
      "155000 10.4 0.09999999999985551\n",
      "155500 9.5 0.09999999999985551\n",
      "156000 7.0 0.09999999999985551\n",
      "156500 9.7 0.09999999999985551\n",
      "157000 11.2 0.09999999999985551\n",
      "157500 9.8 0.09999999999985551\n",
      "158000 7.4 0.09999999999985551\n",
      "158500 12.4 0.09999999999985551\n",
      "159000 12.4 0.09999999999985551\n",
      "159500 7.4 0.09999999999985551\n",
      "160000 9.9 0.09999999999985551\n",
      "160500 12.1 0.09999999999985551\n",
      "161000 12.2 0.09999999999985551\n",
      "161500 10.1 0.09999999999985551\n",
      "162000 9.5 0.09999999999985551\n",
      "162500 14.4 0.09999999999985551\n",
      "163000 12.2 0.09999999999985551\n",
      "163500 10.8 0.09999999999985551\n",
      "164000 10.2 0.09999999999985551\n",
      "164500 13.7 0.09999999999985551\n",
      "165000 10.1 0.09999999999985551\n",
      "165500 11.1 0.09999999999985551\n",
      "166000 11.8 0.09999999999985551\n",
      "166500 9.3 0.09999999999985551\n",
      "167000 11.2 0.09999999999985551\n",
      "167500 10.7 0.09999999999985551\n",
      "168000 10.5 0.09999999999985551\n",
      "168500 11.6 0.09999999999985551\n",
      "169000 11.0 0.09999999999985551\n",
      "169500 13.1 0.09999999999985551\n",
      "170000 10.0 0.09999999999985551\n",
      "170500 10.3 0.09999999999985551\n",
      "171000 9.5 0.09999999999985551\n",
      "171500 10.1 0.09999999999985551\n",
      "172000 11.3 0.09999999999985551\n",
      "172500 9.4 0.09999999999985551\n",
      "173000 11.9 0.09999999999985551\n",
      "173500 13.4 0.09999999999985551\n",
      "174000 9.7 0.09999999999985551\n",
      "174500 6.6 0.09999999999985551\n",
      "175000 8.9 0.09999999999985551\n",
      "175500 8.1 0.09999999999985551\n",
      "176000 11.3 0.09999999999985551\n",
      "176500 9.4 0.09999999999985551\n",
      "177000 13.2 0.09999999999985551\n",
      "177500 12.9 0.09999999999985551\n",
      "178000 11.1 0.09999999999985551\n",
      "178500 9.7 0.09999999999985551\n",
      "179000 11.6 0.09999999999985551\n",
      "179500 12.8 0.09999999999985551\n",
      "180000 13.4 0.09999999999985551\n",
      "180500 9.9 0.09999999999985551\n",
      "181000 8.1 0.09999999999985551\n",
      "181500 11.9 0.09999999999985551\n",
      "182000 11.3 0.09999999999985551\n",
      "182500 10.6 0.09999999999985551\n",
      "183000 10.3 0.09999999999985551\n",
      "183500 8.1 0.09999999999985551\n",
      "184000 10.0 0.09999999999985551\n",
      "184500 10.3 0.09999999999985551\n",
      "185000 11.9 0.09999999999985551\n",
      "185500 8.6 0.09999999999985551\n",
      "186000 9.5 0.09999999999985551\n",
      "186500 11.5 0.09999999999985551\n",
      "187000 11.0 0.09999999999985551\n",
      "187500 5.7 0.09999999999985551\n",
      "188000 9.2 0.09999999999985551\n",
      "188500 13.6 0.09999999999985551\n",
      "189000 10.7 0.09999999999985551\n",
      "189500 8.2 0.09999999999985551\n",
      "190000 10.1 0.09999999999985551\n",
      "190500 12.3 0.09999999999985551\n",
      "191000 13.0 0.09999999999985551\n",
      "191500 8.8 0.09999999999985551\n",
      "192000 12.9 0.09999999999985551\n",
      "192500 12.7 0.09999999999985551\n",
      "193000 12.8 0.09999999999985551\n",
      "193500 12.2 0.09999999999985551\n",
      "194000 12.1 0.09999999999985551\n",
      "194500 7.9 0.09999999999985551\n",
      "195000 11.5 0.09999999999985551\n",
      "195500 12.4 0.09999999999985551\n",
      "196000 9.3 0.09999999999985551\n",
      "196500 8.7 0.09999999999985551\n",
      "197000 8.8 0.09999999999985551\n",
      "197500 7.5 0.09999999999985551\n",
      "198000 10.9 0.09999999999985551\n",
      "198500 11.9 0.09999999999985551\n",
      "199000 8.3 0.09999999999985551\n",
      "199500 12.6 0.09999999999985551\n",
      "200000 10.1 0.09999999999985551\n",
      "Saved Model\n",
      "200500 10.2 0.09999999999985551\n",
      "201000 9.2 0.09999999999985551\n",
      "201500 11.4 0.09999999999985551\n",
      "202000 14.4 0.09999999999985551\n",
      "202500 11.7 0.09999999999985551\n",
      "203000 12.9 0.09999999999985551\n",
      "203500 11.5 0.09999999999985551\n",
      "204000 7.8 0.09999999999985551\n",
      "204500 9.5 0.09999999999985551\n",
      "205000 11.4 0.09999999999985551\n",
      "205500 8.5 0.09999999999985551\n",
      "206000 11.4 0.09999999999985551\n",
      "206500 9.8 0.09999999999985551\n",
      "207000 9.6 0.09999999999985551\n",
      "207500 11.0 0.09999999999985551\n",
      "208000 11.8 0.09999999999985551\n",
      "208500 9.8 0.09999999999985551\n",
      "209000 7.5 0.09999999999985551\n",
      "209500 12.8 0.09999999999985551\n",
      "210000 12.7 0.09999999999985551\n",
      "210500 12.3 0.09999999999985551\n",
      "211000 12.7 0.09999999999985551\n",
      "211500 8.8 0.09999999999985551\n",
      "212000 14.5 0.09999999999985551\n",
      "212500 10.8 0.09999999999985551\n",
      "213000 16.7 0.09999999999985551\n",
      "213500 11.7 0.09999999999985551\n",
      "214000 9.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214500 8.7 0.09999999999985551\n",
      "215000 8.2 0.09999999999985551\n",
      "215500 10.4 0.09999999999985551\n",
      "216000 13.3 0.09999999999985551\n",
      "216500 11.7 0.09999999999985551\n",
      "217000 9.5 0.09999999999985551\n",
      "217500 12.8 0.09999999999985551\n",
      "218000 10.7 0.09999999999985551\n",
      "218500 8.2 0.09999999999985551\n",
      "219000 8.2 0.09999999999985551\n",
      "219500 10.0 0.09999999999985551\n",
      "220000 9.2 0.09999999999985551\n",
      "220500 14.0 0.09999999999985551\n",
      "221000 9.9 0.09999999999985551\n",
      "221500 10.8 0.09999999999985551\n",
      "222000 12.3 0.09999999999985551\n",
      "222500 7.8 0.09999999999985551\n",
      "223000 7.3 0.09999999999985551\n",
      "223500 10.0 0.09999999999985551\n",
      "224000 12.0 0.09999999999985551\n",
      "224500 10.5 0.09999999999985551\n",
      "225000 9.6 0.09999999999985551\n",
      "225500 12.7 0.09999999999985551\n",
      "226000 11.8 0.09999999999985551\n",
      "226500 12.7 0.09999999999985551\n",
      "227000 11.5 0.09999999999985551\n",
      "227500 16.5 0.09999999999985551\n",
      "228000 8.6 0.09999999999985551\n",
      "228500 9.7 0.09999999999985551\n",
      "229000 10.0 0.09999999999985551\n",
      "229500 10.1 0.09999999999985551\n",
      "230000 12.2 0.09999999999985551\n",
      "230500 11.5 0.09999999999985551\n",
      "231000 13.2 0.09999999999985551\n",
      "231500 9.9 0.09999999999985551\n",
      "232000 13.9 0.09999999999985551\n",
      "232500 10.3 0.09999999999985551\n",
      "233000 10.6 0.09999999999985551\n",
      "233500 11.6 0.09999999999985551\n",
      "234000 11.4 0.09999999999985551\n",
      "234500 10.5 0.09999999999985551\n",
      "235000 11.0 0.09999999999985551\n",
      "235500 9.4 0.09999999999985551\n",
      "236000 11.1 0.09999999999985551\n",
      "236500 12.2 0.09999999999985551\n",
      "237000 9.1 0.09999999999985551\n",
      "237500 9.1 0.09999999999985551\n",
      "238000 10.6 0.09999999999985551\n",
      "238500 13.3 0.09999999999985551\n",
      "239000 11.7 0.09999999999985551\n",
      "239500 12.0 0.09999999999985551\n",
      "240000 11.9 0.09999999999985551\n",
      "240500 11.7 0.09999999999985551\n",
      "241000 8.1 0.09999999999985551\n",
      "241500 10.4 0.09999999999985551\n",
      "242000 9.1 0.09999999999985551\n",
      "242500 13.1 0.09999999999985551\n",
      "243000 11.8 0.09999999999985551\n",
      "243500 13.4 0.09999999999985551\n",
      "244000 13.5 0.09999999999985551\n",
      "244500 11.4 0.09999999999985551\n",
      "245000 9.2 0.09999999999985551\n",
      "245500 11.2 0.09999999999985551\n",
      "246000 10.5 0.09999999999985551\n",
      "246500 9.5 0.09999999999985551\n",
      "247000 11.4 0.09999999999985551\n",
      "247500 11.0 0.09999999999985551\n",
      "248000 9.1 0.09999999999985551\n",
      "248500 10.8 0.09999999999985551\n",
      "249000 14.3 0.09999999999985551\n",
      "249500 13.3 0.09999999999985551\n",
      "250000 9.5 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 10.8 0.09999999999985551\n",
      "251000 14.1 0.09999999999985551\n",
      "251500 12.5 0.09999999999985551\n",
      "252000 12.2 0.09999999999985551\n",
      "252500 13.1 0.09999999999985551\n",
      "253000 9.2 0.09999999999985551\n",
      "253500 11.6 0.09999999999985551\n",
      "254000 10.4 0.09999999999985551\n",
      "254500 11.7 0.09999999999985551\n",
      "255000 13.8 0.09999999999985551\n",
      "255500 9.7 0.09999999999985551\n",
      "256000 9.7 0.09999999999985551\n",
      "256500 12.1 0.09999999999985551\n",
      "257000 10.9 0.09999999999985551\n",
      "257500 11.0 0.09999999999985551\n",
      "258000 12.3 0.09999999999985551\n",
      "258500 11.9 0.09999999999985551\n",
      "259000 10.5 0.09999999999985551\n",
      "259500 13.1 0.09999999999985551\n",
      "260000 12.7 0.09999999999985551\n",
      "260500 7.0 0.09999999999985551\n",
      "261000 11.0 0.09999999999985551\n",
      "261500 8.4 0.09999999999985551\n",
      "262000 9.2 0.09999999999985551\n",
      "262500 10.6 0.09999999999985551\n",
      "263000 10.6 0.09999999999985551\n",
      "263500 14.2 0.09999999999985551\n",
      "264000 14.5 0.09999999999985551\n",
      "264500 12.1 0.09999999999985551\n",
      "265000 13.2 0.09999999999985551\n",
      "265500 11.3 0.09999999999985551\n",
      "266000 9.2 0.09999999999985551\n",
      "266500 12.0 0.09999999999985551\n",
      "267000 12.9 0.09999999999985551\n",
      "267500 11.5 0.09999999999985551\n",
      "268000 12.4 0.09999999999985551\n",
      "268500 13.4 0.09999999999985551\n",
      "269000 11.0 0.09999999999985551\n",
      "269500 10.6 0.09999999999985551\n",
      "270000 11.1 0.09999999999985551\n",
      "270500 11.0 0.09999999999985551\n",
      "271000 13.8 0.09999999999985551\n",
      "271500 11.9 0.09999999999985551\n",
      "272000 10.6 0.09999999999985551\n",
      "272500 12.1 0.09999999999985551\n",
      "273000 12.9 0.09999999999985551\n",
      "273500 11.5 0.09999999999985551\n",
      "274000 13.2 0.09999999999985551\n",
      "274500 9.4 0.09999999999985551\n",
      "275000 9.2 0.09999999999985551\n",
      "275500 12.9 0.09999999999985551\n",
      "276000 11.6 0.09999999999985551\n",
      "276500 13.8 0.09999999999985551\n",
      "277000 11.3 0.09999999999985551\n",
      "277500 13.4 0.09999999999985551\n",
      "278000 12.0 0.09999999999985551\n",
      "278500 9.7 0.09999999999985551\n",
      "279000 11.6 0.09999999999985551\n",
      "279500 9.8 0.09999999999985551\n",
      "280000 10.4 0.09999999999985551\n",
      "280500 10.9 0.09999999999985551\n",
      "281000 9.1 0.09999999999985551\n",
      "281500 11.7 0.09999999999985551\n",
      "282000 14.2 0.09999999999985551\n",
      "282500 8.1 0.09999999999985551\n",
      "283000 10.6 0.09999999999985551\n",
      "283500 12.2 0.09999999999985551\n",
      "284000 10.7 0.09999999999985551\n",
      "284500 12.3 0.09999999999985551\n",
      "285000 7.7 0.09999999999985551\n",
      "285500 11.3 0.09999999999985551\n",
      "286000 9.4 0.09999999999985551\n",
      "286500 13.1 0.09999999999985551\n",
      "287000 10.9 0.09999999999985551\n",
      "287500 10.0 0.09999999999985551\n",
      "288000 12.1 0.09999999999985551\n",
      "288500 11.3 0.09999999999985551\n",
      "289000 10.4 0.09999999999985551\n",
      "289500 12.8 0.09999999999985551\n",
      "290000 10.1 0.09999999999985551\n",
      "290500 10.0 0.09999999999985551\n",
      "291000 12.2 0.09999999999985551\n",
      "291500 14.0 0.09999999999985551\n",
      "292000 13.0 0.09999999999985551\n",
      "292500 12.3 0.09999999999985551\n",
      "293000 10.3 0.09999999999985551\n",
      "293500 11.0 0.09999999999985551\n",
      "294000 10.5 0.09999999999985551\n",
      "294500 7.7 0.09999999999985551\n",
      "295000 13.1 0.09999999999985551\n",
      "295500 14.1 0.09999999999985551\n",
      "296000 10.9 0.09999999999985551\n",
      "296500 11.2 0.09999999999985551\n",
      "297000 11.0 0.09999999999985551\n",
      "297500 11.6 0.09999999999985551\n",
      "298000 10.6 0.09999999999985551\n",
      "298500 10.4 0.09999999999985551\n",
      "299000 12.8 0.09999999999985551\n",
      "299500 12.7 0.09999999999985551\n",
      "300000 12.9 0.09999999999985551\n",
      "Saved Model\n",
      "300500 10.6 0.09999999999985551\n",
      "301000 11.0 0.09999999999985551\n",
      "301500 7.9 0.09999999999985551\n",
      "302000 12.8 0.09999999999985551\n",
      "302500 10.7 0.09999999999985551\n",
      "303000 12.4 0.09999999999985551\n",
      "303500 11.8 0.09999999999985551\n",
      "304000 11.0 0.09999999999985551\n",
      "304500 14.9 0.09999999999985551\n",
      "305000 12.6 0.09999999999985551\n",
      "305500 12.2 0.09999999999985551\n",
      "306000 12.4 0.09999999999985551\n",
      "306500 11.2 0.09999999999985551\n",
      "307000 11.1 0.09999999999985551\n",
      "307500 9.2 0.09999999999985551\n",
      "308000 9.9 0.09999999999985551\n",
      "308500 12.0 0.09999999999985551\n",
      "309000 12.6 0.09999999999985551\n",
      "309500 9.1 0.09999999999985551\n",
      "310000 8.7 0.09999999999985551\n",
      "310500 7.4 0.09999999999985551\n",
      "311000 8.0 0.09999999999985551\n",
      "311500 11.4 0.09999999999985551\n",
      "312000 11.9 0.09999999999985551\n",
      "312500 9.8 0.09999999999985551\n",
      "313000 11.5 0.09999999999985551\n",
      "313500 11.7 0.09999999999985551\n",
      "314000 9.7 0.09999999999985551\n",
      "314500 11.4 0.09999999999985551\n",
      "315000 12.1 0.09999999999985551\n",
      "315500 10.6 0.09999999999985551\n",
      "316000 9.5 0.09999999999985551\n",
      "316500 13.2 0.09999999999985551\n",
      "317000 11.7 0.09999999999985551\n",
      "317500 9.5 0.09999999999985551\n",
      "318000 12.5 0.09999999999985551\n",
      "318500 14.2 0.09999999999985551\n",
      "319000 13.5 0.09999999999985551\n",
      "319500 12.5 0.09999999999985551\n",
      "320000 8.5 0.09999999999985551\n",
      "320500 11.9 0.09999999999985551\n",
      "321000 12.4 0.09999999999985551\n",
      "321500 11.4 0.09999999999985551\n",
      "322000 9.1 0.09999999999985551\n",
      "322500 10.1 0.09999999999985551\n",
      "323000 13.5 0.09999999999985551\n",
      "323500 12.3 0.09999999999985551\n",
      "324000 8.1 0.09999999999985551\n",
      "324500 12.5 0.09999999999985551\n",
      "325000 10.3 0.09999999999985551\n",
      "325500 12.6 0.09999999999985551\n",
      "326000 8.8 0.09999999999985551\n",
      "326500 13.1 0.09999999999985551\n",
      "327000 10.0 0.09999999999985551\n",
      "327500 9.5 0.09999999999985551\n",
      "328000 10.1 0.09999999999985551\n",
      "328500 11.7 0.09999999999985551\n",
      "329000 13.7 0.09999999999985551\n",
      "329500 9.3 0.09999999999985551\n",
      "330000 12.1 0.09999999999985551\n",
      "330500 12.0 0.09999999999985551\n",
      "331000 10.2 0.09999999999985551\n",
      "331500 12.2 0.09999999999985551\n",
      "332000 13.1 0.09999999999985551\n",
      "332500 11.6 0.09999999999985551\n",
      "333000 12.8 0.09999999999985551\n",
      "333500 12.4 0.09999999999985551\n",
      "334000 9.0 0.09999999999985551\n",
      "334500 12.6 0.09999999999985551\n",
      "335000 17.0 0.09999999999985551\n",
      "335500 14.1 0.09999999999985551\n",
      "336000 12.5 0.09999999999985551\n",
      "336500 8.5 0.09999999999985551\n",
      "337000 11.9 0.09999999999985551\n",
      "337500 11.3 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338000 9.9 0.09999999999985551\n",
      "338500 13.2 0.09999999999985551\n",
      "339000 7.9 0.09999999999985551\n",
      "339500 12.7 0.09999999999985551\n",
      "340000 10.6 0.09999999999985551\n",
      "340500 14.0 0.09999999999985551\n",
      "341000 9.2 0.09999999999985551\n",
      "341500 13.9 0.09999999999985551\n",
      "342000 14.7 0.09999999999985551\n",
      "342500 12.1 0.09999999999985551\n",
      "343000 13.1 0.09999999999985551\n",
      "343500 9.6 0.09999999999985551\n",
      "344000 10.8 0.09999999999985551\n",
      "344500 8.1 0.09999999999985551\n",
      "345000 10.1 0.09999999999985551\n",
      "345500 12.6 0.09999999999985551\n",
      "346000 11.5 0.09999999999985551\n",
      "346500 11.2 0.09999999999985551\n",
      "347000 15.2 0.09999999999985551\n",
      "347500 12.0 0.09999999999985551\n",
      "348000 13.4 0.09999999999985551\n",
      "348500 13.0 0.09999999999985551\n",
      "349000 15.6 0.09999999999985551\n",
      "349500 11.2 0.09999999999985551\n",
      "350000 12.4 0.09999999999985551\n",
      "Saved Model\n",
      "350500 11.7 0.09999999999985551\n",
      "351000 10.3 0.09999999999985551\n",
      "351500 11.3 0.09999999999985551\n",
      "352000 8.1 0.09999999999985551\n",
      "352500 9.0 0.09999999999985551\n",
      "353000 12.6 0.09999999999985551\n",
      "353500 11.9 0.09999999999985551\n",
      "354000 12.4 0.09999999999985551\n",
      "354500 11.2 0.09999999999985551\n",
      "355000 11.2 0.09999999999985551\n",
      "355500 14.2 0.09999999999985551\n",
      "356000 13.4 0.09999999999985551\n",
      "356500 13.3 0.09999999999985551\n",
      "357000 13.3 0.09999999999985551\n",
      "357500 12.5 0.09999999999985551\n",
      "358000 12.6 0.09999999999985551\n",
      "358500 11.0 0.09999999999985551\n",
      "359000 11.0 0.09999999999985551\n",
      "359500 12.3 0.09999999999985551\n",
      "360000 12.6 0.09999999999985551\n",
      "360500 11.0 0.09999999999985551\n",
      "361000 11.3 0.09999999999985551\n",
      "361500 11.0 0.09999999999985551\n",
      "362000 12.8 0.09999999999985551\n",
      "362500 10.1 0.09999999999985551\n",
      "363000 11.2 0.09999999999985551\n",
      "363500 14.1 0.09999999999985551\n",
      "364000 9.9 0.09999999999985551\n",
      "364500 12.1 0.09999999999985551\n",
      "365000 12.3 0.09999999999985551\n",
      "365500 13.7 0.09999999999985551\n",
      "366000 10.6 0.09999999999985551\n",
      "366500 10.6 0.09999999999985551\n",
      "367000 11.9 0.09999999999985551\n",
      "367500 13.0 0.09999999999985551\n",
      "368000 13.5 0.09999999999985551\n",
      "368500 12.5 0.09999999999985551\n",
      "369000 12.9 0.09999999999985551\n",
      "369500 13.3 0.09999999999985551\n",
      "370000 9.4 0.09999999999985551\n",
      "370500 15.0 0.09999999999985551\n",
      "371000 8.1 0.09999999999985551\n",
      "371500 11.3 0.09999999999985551\n",
      "372000 10.4 0.09999999999985551\n",
      "372500 18.5 0.09999999999985551\n",
      "373000 13.2 0.09999999999985551\n",
      "373500 10.2 0.09999999999985551\n",
      "374000 7.7 0.09999999999985551\n",
      "374500 8.8 0.09999999999985551\n",
      "375000 10.1 0.09999999999985551\n",
      "375500 12.3 0.09999999999985551\n",
      "376000 10.0 0.09999999999985551\n",
      "376500 7.2 0.09999999999985551\n",
      "377000 14.6 0.09999999999985551\n",
      "377500 11.1 0.09999999999985551\n",
      "378000 9.3 0.09999999999985551\n",
      "378500 12.3 0.09999999999985551\n",
      "379000 9.5 0.09999999999985551\n",
      "379500 7.1 0.09999999999985551\n",
      "380000 13.5 0.09999999999985551\n",
      "380500 8.6 0.09999999999985551\n",
      "381000 10.5 0.09999999999985551\n",
      "381500 12.7 0.09999999999985551\n",
      "382000 13.0 0.09999999999985551\n",
      "382500 9.3 0.09999999999985551\n",
      "383000 11.2 0.09999999999985551\n",
      "383500 10.0 0.09999999999985551\n",
      "384000 8.7 0.09999999999985551\n",
      "384500 16.0 0.09999999999985551\n",
      "385000 15.5 0.09999999999985551\n",
      "385500 12.7 0.09999999999985551\n",
      "386000 13.1 0.09999999999985551\n",
      "386500 9.9 0.09999999999985551\n",
      "387000 11.3 0.09999999999985551\n",
      "387500 13.6 0.09999999999985551\n",
      "388000 10.0 0.09999999999985551\n",
      "388500 14.7 0.09999999999985551\n",
      "389000 8.9 0.09999999999985551\n",
      "389500 10.0 0.09999999999985551\n",
      "390000 9.7 0.09999999999985551\n",
      "390500 8.6 0.09999999999985551\n",
      "391000 10.5 0.09999999999985551\n",
      "391500 11.6 0.09999999999985551\n",
      "392000 9.9 0.09999999999985551\n",
      "392500 8.2 0.09999999999985551\n",
      "393000 15.6 0.09999999999985551\n",
      "393500 10.8 0.09999999999985551\n",
      "394000 12.2 0.09999999999985551\n",
      "394500 12.9 0.09999999999985551\n",
      "395000 11.7 0.09999999999985551\n",
      "395500 11.1 0.09999999999985551\n",
      "396000 11.7 0.09999999999985551\n",
      "396500 10.7 0.09999999999985551\n",
      "397000 10.7 0.09999999999985551\n",
      "397500 12.7 0.09999999999985551\n",
      "398000 9.8 0.09999999999985551\n",
      "398500 9.8 0.09999999999985551\n",
      "399000 10.6 0.09999999999985551\n",
      "399500 13.8 0.09999999999985551\n",
      "400000 10.9 0.09999999999985551\n",
      "Saved Model\n",
      "400500 9.9 0.09999999999985551\n",
      "401000 13.0 0.09999999999985551\n",
      "401500 10.3 0.09999999999985551\n",
      "402000 10.2 0.09999999999985551\n",
      "402500 12.7 0.09999999999985551\n",
      "403000 8.8 0.09999999999985551\n",
      "403500 10.2 0.09999999999985551\n",
      "404000 15.0 0.09999999999985551\n",
      "404500 7.9 0.09999999999985551\n",
      "405000 9.2 0.09999999999985551\n",
      "405500 14.0 0.09999999999985551\n",
      "406000 7.3 0.09999999999985551\n",
      "406500 9.3 0.09999999999985551\n",
      "407000 8.7 0.09999999999985551\n",
      "407500 11.2 0.09999999999985551\n",
      "408000 14.3 0.09999999999985551\n",
      "408500 12.3 0.09999999999985551\n",
      "409000 10.9 0.09999999999985551\n",
      "409500 12.6 0.09999999999985551\n",
      "410000 9.8 0.09999999999985551\n",
      "410500 9.3 0.09999999999985551\n",
      "411000 10.7 0.09999999999985551\n",
      "411500 12.3 0.09999999999985551\n",
      "412000 8.3 0.09999999999985551\n",
      "412500 12.3 0.09999999999985551\n",
      "413000 12.9 0.09999999999985551\n",
      "413500 10.5 0.09999999999985551\n",
      "414000 12.4 0.09999999999985551\n",
      "414500 11.6 0.09999999999985551\n",
      "415000 12.1 0.09999999999985551\n",
      "415500 11.8 0.09999999999985551\n",
      "416000 12.6 0.09999999999985551\n",
      "416500 14.5 0.09999999999985551\n",
      "417000 12.9 0.09999999999985551\n",
      "417500 12.9 0.09999999999985551\n",
      "418000 9.7 0.09999999999985551\n",
      "418500 10.4 0.09999999999985551\n",
      "419000 11.7 0.09999999999985551\n",
      "419500 12.6 0.09999999999985551\n",
      "420000 12.8 0.09999999999985551\n",
      "420500 14.8 0.09999999999985551\n",
      "421000 15.1 0.09999999999985551\n",
      "421500 11.7 0.09999999999985551\n",
      "422000 14.2 0.09999999999985551\n",
      "422500 11.8 0.09999999999985551\n",
      "423000 12.8 0.09999999999985551\n",
      "423500 13.0 0.09999999999985551\n",
      "424000 11.6 0.09999999999985551\n",
      "424500 10.8 0.09999999999985551\n",
      "425000 12.8 0.09999999999985551\n",
      "425500 10.1 0.09999999999985551\n",
      "426000 9.4 0.09999999999985551\n",
      "426500 12.5 0.09999999999985551\n",
      "427000 13.7 0.09999999999985551\n",
      "427500 11.8 0.09999999999985551\n",
      "428000 13.9 0.09999999999985551\n",
      "428500 12.4 0.09999999999985551\n",
      "429000 12.9 0.09999999999985551\n",
      "429500 11.7 0.09999999999985551\n",
      "430000 9.4 0.09999999999985551\n",
      "430500 12.8 0.09999999999985551\n",
      "431000 12.1 0.09999999999985551\n",
      "431500 12.2 0.09999999999985551\n",
      "432000 13.9 0.09999999999985551\n",
      "432500 12.6 0.09999999999985551\n",
      "433000 13.6 0.09999999999985551\n",
      "433500 10.9 0.09999999999985551\n",
      "434000 14.1 0.09999999999985551\n",
      "434500 13.2 0.09999999999985551\n",
      "435000 10.5 0.09999999999985551\n",
      "435500 11.6 0.09999999999985551\n",
      "436000 10.5 0.09999999999985551\n",
      "436500 12.6 0.09999999999985551\n",
      "437000 12.0 0.09999999999985551\n",
      "437500 12.7 0.09999999999985551\n",
      "438000 9.8 0.09999999999985551\n",
      "438500 10.4 0.09999999999985551\n",
      "439000 11.0 0.09999999999985551\n",
      "439500 13.0 0.09999999999985551\n",
      "440000 12.3 0.09999999999985551\n",
      "440500 9.1 0.09999999999985551\n",
      "441000 12.3 0.09999999999985551\n",
      "441500 11.7 0.09999999999985551\n",
      "442000 14.9 0.09999999999985551\n",
      "442500 12.5 0.09999999999985551\n",
      "443000 12.4 0.09999999999985551\n",
      "443500 10.9 0.09999999999985551\n",
      "444000 14.4 0.09999999999985551\n",
      "444500 11.5 0.09999999999985551\n",
      "445000 11.0 0.09999999999985551\n",
      "445500 12.1 0.09999999999985551\n",
      "446000 13.1 0.09999999999985551\n",
      "446500 8.5 0.09999999999985551\n",
      "447000 14.0 0.09999999999985551\n",
      "447500 7.6 0.09999999999985551\n",
      "448000 11.7 0.09999999999985551\n",
      "448500 12.7 0.09999999999985551\n",
      "449000 13.0 0.09999999999985551\n",
      "449500 12.7 0.09999999999985551\n",
      "450000 10.6 0.09999999999985551\n",
      "Saved Model\n",
      "450500 11.6 0.09999999999985551\n",
      "451000 16.1 0.09999999999985551\n",
      "451500 13.6 0.09999999999985551\n",
      "452000 12.6 0.09999999999985551\n",
      "452500 12.2 0.09999999999985551\n",
      "453000 11.0 0.09999999999985551\n",
      "453500 11.5 0.09999999999985551\n",
      "454000 10.0 0.09999999999985551\n",
      "454500 9.5 0.09999999999985551\n",
      "455000 12.9 0.09999999999985551\n",
      "455500 9.6 0.09999999999985551\n",
      "456000 9.9 0.09999999999985551\n",
      "456500 10.8 0.09999999999985551\n",
      "457000 13.2 0.09999999999985551\n",
      "457500 11.0 0.09999999999985551\n",
      "458000 10.9 0.09999999999985551\n",
      "458500 13.1 0.09999999999985551\n",
      "459000 11.3 0.09999999999985551\n",
      "459500 11.7 0.09999999999985551\n",
      "460000 12.8 0.09999999999985551\n",
      "460500 10.9 0.09999999999985551\n",
      "461000 12.3 0.09999999999985551\n",
      "461500 12.6 0.09999999999985551\n",
      "462000 16.1 0.09999999999985551\n",
      "462500 10.4 0.09999999999985551\n",
      "463000 15.4 0.09999999999985551\n",
      "463500 10.3 0.09999999999985551\n",
      "464000 13.1 0.09999999999985551\n",
      "464500 13.2 0.09999999999985551\n",
      "465000 13.5 0.09999999999985551\n",
      "465500 12.3 0.09999999999985551\n",
      "466000 10.9 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "466500 10.4 0.09999999999985551\n",
      "467000 9.7 0.09999999999985551\n",
      "467500 10.9 0.09999999999985551\n",
      "468000 8.2 0.09999999999985551\n",
      "468500 12.6 0.09999999999985551\n",
      "469000 14.1 0.09999999999985551\n",
      "469500 11.3 0.09999999999985551\n",
      "470000 12.4 0.09999999999985551\n",
      "470500 10.6 0.09999999999985551\n",
      "471000 12.8 0.09999999999985551\n",
      "471500 12.8 0.09999999999985551\n",
      "472000 10.7 0.09999999999985551\n",
      "472500 12.9 0.09999999999985551\n",
      "473000 12.3 0.09999999999985551\n",
      "473500 10.0 0.09999999999985551\n",
      "474000 15.8 0.09999999999985551\n",
      "474500 12.6 0.09999999999985551\n",
      "475000 11.3 0.09999999999985551\n",
      "475500 12.5 0.09999999999985551\n",
      "476000 15.1 0.09999999999985551\n",
      "476500 12.6 0.09999999999985551\n",
      "477000 12.5 0.09999999999985551\n",
      "477500 11.2 0.09999999999985551\n",
      "478000 13.0 0.09999999999985551\n",
      "478500 13.7 0.09999999999985551\n",
      "479000 12.6 0.09999999999985551\n",
      "479500 9.4 0.09999999999985551\n",
      "480000 7.6 0.09999999999985551\n",
      "480500 6.0 0.09999999999985551\n",
      "481000 10.0 0.09999999999985551\n",
      "481500 14.3 0.09999999999985551\n",
      "482000 15.4 0.09999999999985551\n",
      "482500 13.5 0.09999999999985551\n",
      "483000 13.3 0.09999999999985551\n",
      "483500 12.2 0.09999999999985551\n",
      "484000 15.0 0.09999999999985551\n",
      "484500 12.6 0.09999999999985551\n",
      "485000 14.2 0.09999999999985551\n",
      "485500 15.0 0.09999999999985551\n",
      "486000 11.5 0.09999999999985551\n",
      "486500 11.1 0.09999999999985551\n",
      "487000 11.6 0.09999999999985551\n",
      "487500 11.8 0.09999999999985551\n",
      "488000 18.5 0.09999999999985551\n",
      "488500 11.6 0.09999999999985551\n",
      "489000 9.8 0.09999999999985551\n",
      "489500 13.1 0.09999999999985551\n",
      "490000 10.6 0.09999999999985551\n",
      "490500 10.4 0.09999999999985551\n",
      "491000 11.4 0.09999999999985551\n",
      "491500 14.6 0.09999999999985551\n",
      "492000 13.2 0.09999999999985551\n",
      "492500 10.0 0.09999999999985551\n",
      "493000 10.7 0.09999999999985551\n",
      "493500 12.1 0.09999999999985551\n",
      "494000 13.8 0.09999999999985551\n",
      "494500 9.8 0.09999999999985551\n",
      "495000 10.9 0.09999999999985551\n",
      "495500 10.0 0.09999999999985551\n",
      "496000 14.2 0.09999999999985551\n",
      "496500 9.7 0.09999999999985551\n",
      "497000 11.6 0.09999999999985551\n",
      "497500 9.9 0.09999999999985551\n",
      "498000 14.4 0.09999999999985551\n",
      "498500 13.7 0.09999999999985551\n",
      "499000 9.9 0.09999999999985551\n",
      "499500 12.8 0.09999999999985551\n",
      "500000 10.8 0.09999999999985551\n",
      "Percent of succesful episodes: 9.4523%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd9405707f0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

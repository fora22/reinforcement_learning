{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f41736897b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f41736897b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f41736897b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f41736897b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173689588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4173689198>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172c6b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172c6b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172c6b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172c6b710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173baf358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173baf358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173baf358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4173baf358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f4172bb0b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb0fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb0fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb06d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb06d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb06d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4172bb06d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 0.7 1\n",
      "1000 -0.7 1\n",
      "1500 1.5 1\n",
      "2000 1.1 1\n",
      "2500 0.4 1\n",
      "3000 -0.2 1\n",
      "3500 -0.5 1\n",
      "4000 1.3 1\n",
      "4500 1.2 1\n",
      "5000 2.2 1\n",
      "5500 1.2 1\n",
      "6000 0.4 1\n",
      "6500 0.3 1\n",
      "7000 1.6 1\n",
      "7500 0.6 1\n",
      "8000 1.3 1\n",
      "8500 1.4 1\n",
      "9000 0.2 1\n",
      "9500 -0.1 1\n",
      "10000 -0.1 1\n",
      "10500 0.3 0.9549999999999828\n",
      "11000 -0.1 0.9099999999999655\n",
      "11500 0.6 0.8649999999999483\n",
      "12000 0.9 0.819999999999931\n",
      "12500 1.3 0.7749999999999138\n",
      "13000 1.3 0.7299999999998965\n",
      "13500 0.7 0.6849999999998793\n",
      "14000 0.7 0.639999999999862\n",
      "14500 0.1 0.5949999999998448\n",
      "15000 0.9 0.5499999999998275\n",
      "15500 0.1 0.5049999999998103\n",
      "16000 0.2 0.4599999999998177\n",
      "16500 1.0 0.41499999999982823\n",
      "17000 0.9 0.36999999999983874\n",
      "17500 0.1 0.32499999999984924\n",
      "18000 1.1 0.27999999999985975\n",
      "18500 0.8 0.23499999999986562\n",
      "19000 1.1 0.18999999999986225\n",
      "19500 -0.1 0.14499999999985888\n",
      "20000 0.5 0.09999999999985551\n",
      "20500 0.0 0.09999999999985551\n",
      "21000 0.8 0.09999999999985551\n",
      "21500 -0.2 0.09999999999985551\n",
      "22000 0.8 0.09999999999985551\n",
      "22500 0.9 0.09999999999985551\n",
      "23000 0.9 0.09999999999985551\n",
      "23500 0.7 0.09999999999985551\n",
      "24000 0.9 0.09999999999985551\n",
      "24500 0.6 0.09999999999985551\n",
      "25000 0.3 0.09999999999985551\n",
      "25500 0.6 0.09999999999985551\n",
      "26000 0.3 0.09999999999985551\n",
      "26500 0.5 0.09999999999985551\n",
      "27000 0.2 0.09999999999985551\n",
      "27500 1.4 0.09999999999985551\n",
      "28000 1.0 0.09999999999985551\n",
      "28500 1.0 0.09999999999985551\n",
      "29000 0.8 0.09999999999985551\n",
      "29500 0.9 0.09999999999985551\n",
      "30000 1.2 0.09999999999985551\n",
      "30500 1.6 0.09999999999985551\n",
      "31000 0.4 0.09999999999985551\n",
      "31500 1.3 0.09999999999985551\n",
      "32000 1.3 0.09999999999985551\n",
      "32500 1.7 0.09999999999985551\n",
      "33000 0.9 0.09999999999985551\n",
      "33500 1.2 0.09999999999985551\n",
      "34000 1.1 0.09999999999985551\n",
      "34500 0.5 0.09999999999985551\n",
      "35000 0.5 0.09999999999985551\n",
      "35500 0.7 0.09999999999985551\n",
      "36000 0.6 0.09999999999985551\n",
      "36500 1.2 0.09999999999985551\n",
      "37000 0.6 0.09999999999985551\n",
      "37500 1.8 0.09999999999985551\n",
      "38000 1.3 0.09999999999985551\n",
      "38500 1.0 0.09999999999985551\n",
      "39000 0.7 0.09999999999985551\n",
      "39500 0.6 0.09999999999985551\n",
      "40000 0.7 0.09999999999985551\n",
      "40500 1.2 0.09999999999985551\n",
      "41000 1.4 0.09999999999985551\n",
      "41500 0.9 0.09999999999985551\n",
      "42000 1.7 0.09999999999985551\n",
      "42500 0.9 0.09999999999985551\n",
      "43000 1.0 0.09999999999985551\n",
      "43500 1.6 0.09999999999985551\n",
      "44000 1.2 0.09999999999985551\n",
      "44500 1.9 0.09999999999985551\n",
      "45000 1.3 0.09999999999985551\n",
      "45500 0.7 0.09999999999985551\n",
      "46000 2.0 0.09999999999985551\n",
      "46500 1.1 0.09999999999985551\n",
      "47000 1.8 0.09999999999985551\n",
      "47500 2.2 0.09999999999985551\n",
      "48000 1.7 0.09999999999985551\n",
      "48500 1.1 0.09999999999985551\n",
      "49000 1.6 0.09999999999985551\n",
      "49500 2.4 0.09999999999985551\n",
      "50000 1.7 0.09999999999985551\n",
      "Saved Model\n",
      "50500 1.4 0.09999999999985551\n",
      "51000 1.0 0.09999999999985551\n",
      "51500 2.7 0.09999999999985551\n",
      "52000 2.3 0.09999999999985551\n",
      "52500 1.3 0.09999999999985551\n",
      "53000 1.7 0.09999999999985551\n",
      "53500 1.8 0.09999999999985551\n",
      "54000 2.7 0.09999999999985551\n",
      "54500 2.5 0.09999999999985551\n",
      "55000 2.5 0.09999999999985551\n",
      "55500 2.8 0.09999999999985551\n",
      "56000 3.0 0.09999999999985551\n",
      "56500 2.7 0.09999999999985551\n",
      "57000 3.9 0.09999999999985551\n",
      "57500 1.7 0.09999999999985551\n",
      "58000 2.6 0.09999999999985551\n",
      "58500 2.9 0.09999999999985551\n",
      "59000 4.1 0.09999999999985551\n",
      "59500 2.6 0.09999999999985551\n",
      "60000 2.3 0.09999999999985551\n",
      "60500 2.9 0.09999999999985551\n",
      "61000 3.6 0.09999999999985551\n",
      "61500 4.5 0.09999999999985551\n",
      "62000 1.8 0.09999999999985551\n",
      "62500 4.0 0.09999999999985551\n",
      "63000 5.7 0.09999999999985551\n",
      "63500 4.9 0.09999999999985551\n",
      "64000 4.7 0.09999999999985551\n",
      "64500 3.4 0.09999999999985551\n",
      "65000 3.3 0.09999999999985551\n",
      "65500 3.2 0.09999999999985551\n",
      "66000 4.9 0.09999999999985551\n",
      "66500 3.8 0.09999999999985551\n",
      "67000 4.6 0.09999999999985551\n",
      "67500 5.0 0.09999999999985551\n",
      "68000 3.2 0.09999999999985551\n",
      "68500 6.0 0.09999999999985551\n",
      "69000 5.6 0.09999999999985551\n",
      "69500 4.4 0.09999999999985551\n",
      "70000 4.2 0.09999999999985551\n",
      "70500 6.1 0.09999999999985551\n",
      "71000 4.7 0.09999999999985551\n",
      "71500 6.6 0.09999999999985551\n",
      "72000 7.6 0.09999999999985551\n",
      "72500 9.8 0.09999999999985551\n",
      "73000 7.5 0.09999999999985551\n",
      "73500 5.6 0.09999999999985551\n",
      "74000 7.3 0.09999999999985551\n",
      "74500 6.5 0.09999999999985551\n",
      "75000 6.2 0.09999999999985551\n",
      "75500 5.6 0.09999999999985551\n",
      "76000 2.9 0.09999999999985551\n",
      "76500 8.9 0.09999999999985551\n",
      "77000 8.9 0.09999999999985551\n",
      "77500 10.0 0.09999999999985551\n",
      "78000 6.7 0.09999999999985551\n",
      "78500 9.3 0.09999999999985551\n",
      "79000 13.9 0.09999999999985551\n",
      "79500 7.9 0.09999999999985551\n",
      "80000 10.2 0.09999999999985551\n",
      "80500 7.5 0.09999999999985551\n",
      "81000 8.6 0.09999999999985551\n",
      "81500 12.1 0.09999999999985551\n",
      "82000 7.2 0.09999999999985551\n",
      "82500 13.6 0.09999999999985551\n",
      "83000 13.3 0.09999999999985551\n",
      "83500 8.2 0.09999999999985551\n",
      "84000 10.0 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84500 8.2 0.09999999999985551\n",
      "85000 9.3 0.09999999999985551\n",
      "85500 8.3 0.09999999999985551\n",
      "86000 11.3 0.09999999999985551\n",
      "86500 11.0 0.09999999999985551\n",
      "87000 8.6 0.09999999999985551\n",
      "87500 11.1 0.09999999999985551\n",
      "88000 9.7 0.09999999999985551\n",
      "88500 10.0 0.09999999999985551\n",
      "89000 9.4 0.09999999999985551\n",
      "89500 11.5 0.09999999999985551\n",
      "90000 9.3 0.09999999999985551\n",
      "90500 10.9 0.09999999999985551\n",
      "91000 12.2 0.09999999999985551\n",
      "91500 8.7 0.09999999999985551\n",
      "92000 9.2 0.09999999999985551\n",
      "92500 6.2 0.09999999999985551\n",
      "93000 7.5 0.09999999999985551\n",
      "93500 9.6 0.09999999999985551\n",
      "94000 7.9 0.09999999999985551\n",
      "94500 9.1 0.09999999999985551\n",
      "95000 10.9 0.09999999999985551\n",
      "95500 11.2 0.09999999999985551\n",
      "96000 6.8 0.09999999999985551\n",
      "96500 8.4 0.09999999999985551\n",
      "97000 8.8 0.09999999999985551\n",
      "97500 10.9 0.09999999999985551\n",
      "98000 7.5 0.09999999999985551\n",
      "98500 11.6 0.09999999999985551\n",
      "99000 10.4 0.09999999999985551\n",
      "99500 9.0 0.09999999999985551\n",
      "100000 10.9 0.09999999999985551\n",
      "Saved Model\n",
      "100500 11.5 0.09999999999985551\n",
      "101000 11.7 0.09999999999985551\n",
      "101500 7.6 0.09999999999985551\n",
      "102000 8.1 0.09999999999985551\n",
      "102500 12.8 0.09999999999985551\n",
      "103000 8.3 0.09999999999985551\n",
      "103500 10.5 0.09999999999985551\n",
      "104000 8.3 0.09999999999985551\n",
      "104500 7.6 0.09999999999985551\n",
      "105000 13.0 0.09999999999985551\n",
      "105500 11.5 0.09999999999985551\n",
      "106000 10.2 0.09999999999985551\n",
      "106500 10.5 0.09999999999985551\n",
      "107000 11.3 0.09999999999985551\n",
      "107500 6.6 0.09999999999985551\n",
      "108000 9.2 0.09999999999985551\n",
      "108500 10.9 0.09999999999985551\n",
      "109000 11.0 0.09999999999985551\n",
      "109500 12.5 0.09999999999985551\n",
      "110000 10.7 0.09999999999985551\n",
      "110500 10.0 0.09999999999985551\n",
      "111000 9.9 0.09999999999985551\n",
      "111500 11.9 0.09999999999985551\n",
      "112000 10.6 0.09999999999985551\n",
      "112500 11.5 0.09999999999985551\n",
      "113000 12.2 0.09999999999985551\n",
      "113500 10.9 0.09999999999985551\n",
      "114000 11.7 0.09999999999985551\n",
      "114500 11.3 0.09999999999985551\n",
      "115000 9.4 0.09999999999985551\n",
      "115500 10.9 0.09999999999985551\n",
      "116000 12.9 0.09999999999985551\n",
      "116500 12.3 0.09999999999985551\n",
      "117000 11.3 0.09999999999985551\n",
      "117500 8.2 0.09999999999985551\n",
      "118000 10.5 0.09999999999985551\n",
      "118500 6.6 0.09999999999985551\n",
      "119000 8.6 0.09999999999985551\n",
      "119500 11.3 0.09999999999985551\n",
      "120000 11.9 0.09999999999985551\n",
      "120500 12.2 0.09999999999985551\n",
      "121000 12.0 0.09999999999985551\n",
      "121500 10.7 0.09999999999985551\n",
      "122000 11.7 0.09999999999985551\n",
      "122500 12.6 0.09999999999985551\n",
      "123000 11.5 0.09999999999985551\n",
      "123500 11.9 0.09999999999985551\n",
      "124000 10.1 0.09999999999985551\n",
      "124500 8.2 0.09999999999985551\n",
      "125000 8.8 0.09999999999985551\n",
      "125500 12.5 0.09999999999985551\n",
      "126000 12.8 0.09999999999985551\n",
      "126500 11.1 0.09999999999985551\n",
      "127000 12.1 0.09999999999985551\n",
      "127500 15.0 0.09999999999985551\n",
      "128000 9.0 0.09999999999985551\n",
      "128500 11.6 0.09999999999985551\n",
      "129000 10.0 0.09999999999985551\n",
      "129500 12.7 0.09999999999985551\n",
      "130000 13.4 0.09999999999985551\n",
      "130500 9.9 0.09999999999985551\n",
      "131000 7.8 0.09999999999985551\n",
      "131500 12.9 0.09999999999985551\n",
      "132000 10.2 0.09999999999985551\n",
      "132500 11.6 0.09999999999985551\n",
      "133000 10.2 0.09999999999985551\n",
      "133500 10.7 0.09999999999985551\n",
      "134000 13.2 0.09999999999985551\n",
      "134500 11.5 0.09999999999985551\n",
      "135000 10.5 0.09999999999985551\n",
      "135500 9.8 0.09999999999985551\n",
      "136000 12.1 0.09999999999985551\n",
      "136500 10.4 0.09999999999985551\n",
      "137000 16.8 0.09999999999985551\n",
      "137500 11.8 0.09999999999985551\n",
      "138000 8.3 0.09999999999985551\n",
      "138500 7.2 0.09999999999985551\n",
      "139000 9.9 0.09999999999985551\n",
      "139500 13.3 0.09999999999985551\n",
      "140000 13.0 0.09999999999985551\n",
      "140500 13.3 0.09999999999985551\n",
      "141000 9.9 0.09999999999985551\n",
      "141500 10.5 0.09999999999985551\n",
      "142000 7.5 0.09999999999985551\n",
      "142500 11.6 0.09999999999985551\n",
      "143000 10.9 0.09999999999985551\n",
      "143500 11.4 0.09999999999985551\n",
      "144000 7.9 0.09999999999985551\n",
      "144500 12.5 0.09999999999985551\n",
      "145000 12.0 0.09999999999985551\n",
      "145500 8.1 0.09999999999985551\n",
      "146000 10.4 0.09999999999985551\n",
      "146500 13.2 0.09999999999985551\n",
      "147000 12.6 0.09999999999985551\n",
      "147500 10.0 0.09999999999985551\n",
      "148000 10.9 0.09999999999985551\n",
      "148500 9.2 0.09999999999985551\n",
      "149000 15.5 0.09999999999985551\n",
      "149500 9.7 0.09999999999985551\n",
      "150000 12.3 0.09999999999985551\n",
      "Saved Model\n",
      "150500 13.7 0.09999999999985551\n",
      "151000 11.1 0.09999999999985551\n",
      "151500 12.0 0.09999999999985551\n",
      "152000 10.1 0.09999999999985551\n",
      "152500 12.5 0.09999999999985551\n",
      "153000 9.2 0.09999999999985551\n",
      "153500 11.8 0.09999999999985551\n",
      "154000 9.1 0.09999999999985551\n",
      "154500 12.3 0.09999999999985551\n",
      "155000 10.4 0.09999999999985551\n",
      "155500 14.6 0.09999999999985551\n",
      "156000 11.1 0.09999999999985551\n",
      "156500 7.5 0.09999999999985551\n",
      "157000 9.3 0.09999999999985551\n",
      "157500 12.5 0.09999999999985551\n",
      "158000 10.5 0.09999999999985551\n",
      "158500 10.3 0.09999999999985551\n",
      "159000 10.2 0.09999999999985551\n",
      "159500 10.4 0.09999999999985551\n",
      "160000 13.5 0.09999999999985551\n",
      "160500 10.8 0.09999999999985551\n",
      "161000 11.3 0.09999999999985551\n",
      "161500 8.7 0.09999999999985551\n",
      "162000 12.2 0.09999999999985551\n",
      "162500 9.4 0.09999999999985551\n",
      "163000 13.1 0.09999999999985551\n",
      "163500 11.2 0.09999999999985551\n",
      "164000 8.2 0.09999999999985551\n",
      "164500 8.1 0.09999999999985551\n",
      "165000 11.7 0.09999999999985551\n",
      "165500 9.2 0.09999999999985551\n",
      "166000 12.5 0.09999999999985551\n",
      "166500 9.7 0.09999999999985551\n",
      "167000 8.5 0.09999999999985551\n",
      "167500 9.1 0.09999999999985551\n",
      "168000 11.8 0.09999999999985551\n",
      "168500 12.7 0.09999999999985551\n",
      "169000 7.9 0.09999999999985551\n",
      "169500 10.7 0.09999999999985551\n",
      "170000 10.4 0.09999999999985551\n",
      "170500 7.7 0.09999999999985551\n",
      "171000 8.0 0.09999999999985551\n",
      "171500 11.9 0.09999999999985551\n",
      "172000 11.1 0.09999999999985551\n",
      "172500 14.7 0.09999999999985551\n",
      "173000 15.2 0.09999999999985551\n",
      "173500 12.4 0.09999999999985551\n",
      "174000 10.5 0.09999999999985551\n",
      "174500 5.7 0.09999999999985551\n",
      "175000 12.1 0.09999999999985551\n",
      "175500 8.9 0.09999999999985551\n",
      "176000 10.5 0.09999999999985551\n",
      "176500 11.2 0.09999999999985551\n",
      "177000 13.7 0.09999999999985551\n",
      "177500 11.7 0.09999999999985551\n",
      "178000 13.3 0.09999999999985551\n",
      "178500 12.3 0.09999999999985551\n",
      "179000 10.9 0.09999999999985551\n",
      "179500 8.9 0.09999999999985551\n",
      "180000 10.7 0.09999999999985551\n",
      "180500 12.4 0.09999999999985551\n",
      "181000 15.9 0.09999999999985551\n",
      "181500 9.6 0.09999999999985551\n",
      "182000 11.4 0.09999999999985551\n",
      "182500 13.3 0.09999999999985551\n",
      "183000 11.1 0.09999999999985551\n",
      "183500 6.2 0.09999999999985551\n",
      "184000 10.0 0.09999999999985551\n",
      "184500 9.3 0.09999999999985551\n",
      "185000 11.7 0.09999999999985551\n",
      "185500 9.2 0.09999999999985551\n",
      "186000 10.5 0.09999999999985551\n",
      "186500 10.9 0.09999999999985551\n",
      "187000 11.2 0.09999999999985551\n",
      "187500 15.8 0.09999999999985551\n",
      "188000 12.1 0.09999999999985551\n",
      "188500 9.1 0.09999999999985551\n",
      "189000 13.8 0.09999999999985551\n",
      "189500 10.3 0.09999999999985551\n",
      "190000 10.5 0.09999999999985551\n",
      "190500 9.5 0.09999999999985551\n",
      "191000 10.1 0.09999999999985551\n",
      "191500 10.9 0.09999999999985551\n",
      "192000 10.2 0.09999999999985551\n",
      "192500 10.1 0.09999999999985551\n",
      "193000 11.2 0.09999999999985551\n",
      "193500 16.5 0.09999999999985551\n",
      "194000 12.6 0.09999999999985551\n",
      "194500 13.4 0.09999999999985551\n",
      "195000 9.6 0.09999999999985551\n",
      "195500 10.3 0.09999999999985551\n",
      "196000 11.9 0.09999999999985551\n",
      "196500 12.3 0.09999999999985551\n",
      "197000 11.9 0.09999999999985551\n",
      "197500 9.0 0.09999999999985551\n",
      "198000 8.7 0.09999999999985551\n",
      "198500 12.0 0.09999999999985551\n",
      "199000 8.3 0.09999999999985551\n",
      "199500 11.0 0.09999999999985551\n",
      "200000 12.9 0.09999999999985551\n",
      "Saved Model\n",
      "200500 12.9 0.09999999999985551\n",
      "201000 13.8 0.09999999999985551\n",
      "201500 9.7 0.09999999999985551\n",
      "202000 9.6 0.09999999999985551\n",
      "202500 13.4 0.09999999999985551\n",
      "203000 9.0 0.09999999999985551\n",
      "203500 12.3 0.09999999999985551\n",
      "204000 8.7 0.09999999999985551\n",
      "204500 13.4 0.09999999999985551\n",
      "205000 11.3 0.09999999999985551\n",
      "205500 11.0 0.09999999999985551\n",
      "206000 11.7 0.09999999999985551\n",
      "206500 11.5 0.09999999999985551\n",
      "207000 9.0 0.09999999999985551\n",
      "207500 13.1 0.09999999999985551\n",
      "208000 9.9 0.09999999999985551\n",
      "208500 9.9 0.09999999999985551\n",
      "209000 12.1 0.09999999999985551\n",
      "209500 10.9 0.09999999999985551\n",
      "210000 7.3 0.09999999999985551\n",
      "210500 12.2 0.09999999999985551\n",
      "211000 11.8 0.09999999999985551\n",
      "211500 9.2 0.09999999999985551\n",
      "212000 9.3 0.09999999999985551\n",
      "212500 9.6 0.09999999999985551\n",
      "213000 14.2 0.09999999999985551\n",
      "213500 10.0 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214000 13.6 0.09999999999985551\n",
      "214500 11.6 0.09999999999985551\n",
      "215000 12.5 0.09999999999985551\n",
      "215500 10.6 0.09999999999985551\n",
      "216000 12.5 0.09999999999985551\n",
      "216500 10.7 0.09999999999985551\n",
      "217000 13.6 0.09999999999985551\n",
      "217500 14.0 0.09999999999985551\n",
      "218000 9.1 0.09999999999985551\n",
      "218500 10.5 0.09999999999985551\n",
      "219000 11.2 0.09999999999985551\n",
      "219500 11.3 0.09999999999985551\n",
      "220000 15.2 0.09999999999985551\n",
      "220500 11.2 0.09999999999985551\n",
      "221000 12.3 0.09999999999985551\n",
      "221500 10.3 0.09999999999985551\n",
      "222000 8.9 0.09999999999985551\n",
      "222500 9.9 0.09999999999985551\n",
      "223000 11.3 0.09999999999985551\n",
      "223500 10.9 0.09999999999985551\n",
      "224000 11.5 0.09999999999985551\n",
      "224500 12.6 0.09999999999985551\n",
      "225000 8.2 0.09999999999985551\n",
      "225500 11.7 0.09999999999985551\n",
      "226000 11.6 0.09999999999985551\n",
      "226500 11.8 0.09999999999985551\n",
      "227000 7.5 0.09999999999985551\n",
      "227500 10.8 0.09999999999985551\n",
      "228000 11.6 0.09999999999985551\n",
      "228500 10.8 0.09999999999985551\n",
      "229000 8.3 0.09999999999985551\n",
      "229500 14.0 0.09999999999985551\n",
      "230000 8.9 0.09999999999985551\n",
      "230500 11.2 0.09999999999985551\n",
      "231000 12.0 0.09999999999985551\n",
      "231500 12.9 0.09999999999985551\n",
      "232000 11.0 0.09999999999985551\n",
      "232500 9.5 0.09999999999985551\n",
      "233000 10.3 0.09999999999985551\n",
      "233500 12.1 0.09999999999985551\n",
      "234000 8.3 0.09999999999985551\n",
      "234500 10.8 0.09999999999985551\n",
      "235000 10.4 0.09999999999985551\n",
      "235500 12.2 0.09999999999985551\n",
      "236000 13.5 0.09999999999985551\n",
      "236500 14.4 0.09999999999985551\n",
      "237000 11.8 0.09999999999985551\n",
      "237500 11.5 0.09999999999985551\n",
      "238000 11.5 0.09999999999985551\n",
      "238500 11.1 0.09999999999985551\n",
      "239000 11.2 0.09999999999985551\n",
      "239500 10.9 0.09999999999985551\n",
      "240000 10.7 0.09999999999985551\n",
      "240500 11.1 0.09999999999985551\n",
      "241000 14.6 0.09999999999985551\n",
      "241500 9.0 0.09999999999985551\n",
      "242000 12.6 0.09999999999985551\n",
      "242500 9.7 0.09999999999985551\n",
      "243000 10.0 0.09999999999985551\n",
      "243500 8.3 0.09999999999985551\n",
      "244000 12.4 0.09999999999985551\n",
      "244500 13.6 0.09999999999985551\n",
      "245000 12.6 0.09999999999985551\n",
      "245500 12.2 0.09999999999985551\n",
      "246000 8.1 0.09999999999985551\n",
      "246500 12.4 0.09999999999985551\n",
      "247000 9.2 0.09999999999985551\n",
      "247500 10.5 0.09999999999985551\n",
      "248000 12.9 0.09999999999985551\n",
      "248500 8.5 0.09999999999985551\n",
      "249000 11.2 0.09999999999985551\n",
      "249500 13.4 0.09999999999985551\n",
      "250000 12.3 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 12.2 0.09999999999985551\n",
      "251000 10.1 0.09999999999985551\n",
      "251500 10.9 0.09999999999985551\n",
      "252000 12.4 0.09999999999985551\n",
      "252500 12.0 0.09999999999985551\n",
      "253000 15.1 0.09999999999985551\n",
      "253500 13.0 0.09999999999985551\n",
      "254000 11.2 0.09999999999985551\n",
      "254500 10.6 0.09999999999985551\n",
      "255000 10.8 0.09999999999985551\n",
      "255500 14.6 0.09999999999985551\n",
      "256000 9.0 0.09999999999985551\n",
      "256500 13.0 0.09999999999985551\n",
      "257000 9.8 0.09999999999985551\n",
      "257500 9.2 0.09999999999985551\n",
      "258000 11.1 0.09999999999985551\n",
      "258500 12.2 0.09999999999985551\n",
      "259000 11.3 0.09999999999985551\n",
      "259500 10.7 0.09999999999985551\n",
      "260000 8.6 0.09999999999985551\n",
      "260500 11.2 0.09999999999985551\n",
      "261000 12.7 0.09999999999985551\n",
      "261500 10.0 0.09999999999985551\n",
      "262000 10.3 0.09999999999985551\n",
      "262500 8.3 0.09999999999985551\n",
      "263000 11.2 0.09999999999985551\n",
      "263500 10.8 0.09999999999985551\n",
      "264000 10.4 0.09999999999985551\n",
      "264500 13.3 0.09999999999985551\n",
      "265000 10.7 0.09999999999985551\n",
      "265500 12.9 0.09999999999985551\n",
      "266000 10.7 0.09999999999985551\n",
      "266500 12.5 0.09999999999985551\n",
      "267000 10.4 0.09999999999985551\n",
      "267500 12.8 0.09999999999985551\n",
      "268000 12.3 0.09999999999985551\n",
      "268500 11.6 0.09999999999985551\n",
      "269000 11.3 0.09999999999985551\n",
      "269500 10.5 0.09999999999985551\n",
      "270000 10.1 0.09999999999985551\n",
      "270500 12.6 0.09999999999985551\n",
      "271000 9.0 0.09999999999985551\n",
      "271500 12.4 0.09999999999985551\n",
      "272000 13.5 0.09999999999985551\n",
      "272500 14.8 0.09999999999985551\n",
      "273000 12.9 0.09999999999985551\n",
      "273500 9.4 0.09999999999985551\n",
      "274000 11.0 0.09999999999985551\n",
      "274500 10.2 0.09999999999985551\n",
      "275000 10.9 0.09999999999985551\n",
      "275500 11.0 0.09999999999985551\n",
      "276000 11.4 0.09999999999985551\n",
      "276500 10.8 0.09999999999985551\n",
      "277000 12.3 0.09999999999985551\n",
      "277500 14.9 0.09999999999985551\n",
      "278000 8.6 0.09999999999985551\n",
      "278500 10.0 0.09999999999985551\n",
      "279000 15.3 0.09999999999985551\n",
      "279500 9.9 0.09999999999985551\n",
      "280000 12.4 0.09999999999985551\n",
      "280500 12.7 0.09999999999985551\n",
      "281000 14.8 0.09999999999985551\n",
      "281500 11.2 0.09999999999985551\n",
      "282000 10.7 0.09999999999985551\n",
      "282500 13.8 0.09999999999985551\n",
      "283000 10.1 0.09999999999985551\n",
      "283500 14.0 0.09999999999985551\n",
      "284000 13.4 0.09999999999985551\n",
      "284500 9.8 0.09999999999985551\n",
      "285000 10.0 0.09999999999985551\n",
      "285500 8.5 0.09999999999985551\n",
      "286000 10.7 0.09999999999985551\n",
      "286500 8.8 0.09999999999985551\n",
      "287000 12.6 0.09999999999985551\n",
      "287500 12.4 0.09999999999985551\n",
      "288000 13.2 0.09999999999985551\n",
      "288500 9.2 0.09999999999985551\n",
      "289000 13.3 0.09999999999985551\n",
      "289500 8.3 0.09999999999985551\n",
      "290000 16.8 0.09999999999985551\n",
      "290500 12.7 0.09999999999985551\n",
      "291000 10.2 0.09999999999985551\n",
      "291500 12.9 0.09999999999985551\n",
      "292000 13.9 0.09999999999985551\n",
      "292500 11.9 0.09999999999985551\n",
      "293000 11.2 0.09999999999985551\n",
      "293500 12.1 0.09999999999985551\n",
      "294000 13.5 0.09999999999985551\n",
      "294500 12.0 0.09999999999985551\n",
      "295000 13.5 0.09999999999985551\n",
      "295500 11.5 0.09999999999985551\n",
      "296000 11.9 0.09999999999985551\n",
      "296500 11.6 0.09999999999985551\n",
      "297000 11.1 0.09999999999985551\n",
      "297500 11.9 0.09999999999985551\n",
      "298000 12.7 0.09999999999985551\n",
      "298500 13.6 0.09999999999985551\n",
      "299000 9.6 0.09999999999985551\n",
      "299500 10.4 0.09999999999985551\n",
      "300000 12.4 0.09999999999985551\n",
      "Saved Model\n",
      "300500 13.4 0.09999999999985551\n",
      "301000 12.2 0.09999999999985551\n",
      "301500 9.9 0.09999999999985551\n",
      "302000 14.0 0.09999999999985551\n",
      "302500 10.3 0.09999999999985551\n",
      "303000 12.5 0.09999999999985551\n",
      "303500 10.3 0.09999999999985551\n",
      "304000 9.7 0.09999999999985551\n",
      "304500 14.3 0.09999999999985551\n",
      "305000 11.3 0.09999999999985551\n",
      "305500 9.8 0.09999999999985551\n",
      "306000 7.6 0.09999999999985551\n",
      "306500 9.0 0.09999999999985551\n",
      "307000 7.8 0.09999999999985551\n",
      "307500 13.6 0.09999999999985551\n",
      "308000 10.7 0.09999999999985551\n",
      "308500 10.7 0.09999999999985551\n",
      "309000 14.2 0.09999999999985551\n",
      "309500 14.9 0.09999999999985551\n",
      "310000 12.1 0.09999999999985551\n",
      "310500 15.5 0.09999999999985551\n",
      "311000 13.5 0.09999999999985551\n",
      "311500 11.7 0.09999999999985551\n",
      "312000 12.2 0.09999999999985551\n",
      "312500 10.3 0.09999999999985551\n",
      "313000 10.7 0.09999999999985551\n",
      "313500 13.4 0.09999999999985551\n",
      "314000 14.2 0.09999999999985551\n",
      "314500 12.2 0.09999999999985551\n",
      "315000 10.9 0.09999999999985551\n",
      "315500 14.8 0.09999999999985551\n",
      "316000 9.5 0.09999999999985551\n",
      "316500 10.7 0.09999999999985551\n",
      "317000 13.7 0.09999999999985551\n",
      "317500 10.0 0.09999999999985551\n",
      "318000 12.3 0.09999999999985551\n",
      "318500 12.2 0.09999999999985551\n",
      "319000 14.4 0.09999999999985551\n",
      "319500 12.3 0.09999999999985551\n",
      "320000 10.8 0.09999999999985551\n",
      "320500 12.7 0.09999999999985551\n",
      "321000 10.8 0.09999999999985551\n",
      "321500 13.6 0.09999999999985551\n",
      "322000 12.8 0.09999999999985551\n",
      "322500 12.8 0.09999999999985551\n",
      "323000 12.8 0.09999999999985551\n",
      "323500 12.3 0.09999999999985551\n",
      "324000 12.4 0.09999999999985551\n",
      "324500 11.4 0.09999999999985551\n",
      "325000 9.7 0.09999999999985551\n",
      "325500 11.1 0.09999999999985551\n",
      "326000 12.1 0.09999999999985551\n",
      "326500 12.4 0.09999999999985551\n",
      "327000 13.5 0.09999999999985551\n",
      "327500 10.9 0.09999999999985551\n",
      "328000 11.2 0.09999999999985551\n",
      "328500 10.7 0.09999999999985551\n",
      "329000 14.1 0.09999999999985551\n",
      "329500 14.7 0.09999999999985551\n",
      "330000 10.3 0.09999999999985551\n",
      "330500 14.0 0.09999999999985551\n",
      "331000 13.2 0.09999999999985551\n",
      "331500 15.8 0.09999999999985551\n",
      "332000 12.9 0.09999999999985551\n",
      "332500 11.0 0.09999999999985551\n",
      "333000 8.4 0.09999999999985551\n",
      "333500 7.2 0.09999999999985551\n",
      "334000 11.2 0.09999999999985551\n",
      "334500 13.6 0.09999999999985551\n",
      "335000 9.6 0.09999999999985551\n",
      "335500 14.8 0.09999999999985551\n",
      "336000 15.1 0.09999999999985551\n",
      "336500 11.9 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337000 11.3 0.09999999999985551\n",
      "337500 12.6 0.09999999999985551\n",
      "338000 12.0 0.09999999999985551\n",
      "338500 12.3 0.09999999999985551\n",
      "339000 10.8 0.09999999999985551\n",
      "339500 9.8 0.09999999999985551\n",
      "340000 10.1 0.09999999999985551\n",
      "340500 12.6 0.09999999999985551\n",
      "341000 9.3 0.09999999999985551\n",
      "341500 15.2 0.09999999999985551\n",
      "342000 11.5 0.09999999999985551\n",
      "342500 12.6 0.09999999999985551\n",
      "343000 11.8 0.09999999999985551\n",
      "343500 10.5 0.09999999999985551\n",
      "344000 11.8 0.09999999999985551\n",
      "344500 13.2 0.09999999999985551\n",
      "345000 14.9 0.09999999999985551\n",
      "345500 13.1 0.09999999999985551\n",
      "346000 15.0 0.09999999999985551\n",
      "346500 11.2 0.09999999999985551\n",
      "347000 9.7 0.09999999999985551\n",
      "347500 12.2 0.09999999999985551\n",
      "348000 12.0 0.09999999999985551\n",
      "348500 14.6 0.09999999999985551\n",
      "349000 13.4 0.09999999999985551\n",
      "349500 10.6 0.09999999999985551\n",
      "350000 11.4 0.09999999999985551\n",
      "Saved Model\n",
      "350500 9.8 0.09999999999985551\n",
      "351000 12.4 0.09999999999985551\n",
      "351500 10.9 0.09999999999985551\n",
      "352000 11.1 0.09999999999985551\n",
      "352500 11.4 0.09999999999985551\n",
      "353000 8.4 0.09999999999985551\n",
      "353500 11.9 0.09999999999985551\n",
      "354000 8.1 0.09999999999985551\n",
      "354500 12.0 0.09999999999985551\n",
      "355000 9.9 0.09999999999985551\n",
      "355500 12.0 0.09999999999985551\n",
      "356000 9.6 0.09999999999985551\n",
      "356500 15.4 0.09999999999985551\n",
      "357000 11.7 0.09999999999985551\n",
      "357500 13.4 0.09999999999985551\n",
      "358000 12.6 0.09999999999985551\n",
      "358500 10.0 0.09999999999985551\n",
      "359000 14.0 0.09999999999985551\n",
      "359500 8.5 0.09999999999985551\n",
      "360000 12.5 0.09999999999985551\n",
      "360500 12.4 0.09999999999985551\n",
      "361000 15.5 0.09999999999985551\n",
      "361500 11.9 0.09999999999985551\n",
      "362000 10.6 0.09999999999985551\n",
      "362500 11.9 0.09999999999985551\n",
      "363000 9.1 0.09999999999985551\n",
      "363500 12.4 0.09999999999985551\n",
      "364000 12.8 0.09999999999985551\n",
      "364500 14.0 0.09999999999985551\n",
      "365000 12.1 0.09999999999985551\n",
      "365500 12.4 0.09999999999985551\n",
      "366000 12.1 0.09999999999985551\n",
      "366500 13.2 0.09999999999985551\n",
      "367000 11.7 0.09999999999985551\n",
      "367500 15.0 0.09999999999985551\n",
      "368000 11.3 0.09999999999985551\n",
      "368500 11.6 0.09999999999985551\n",
      "369000 11.4 0.09999999999985551\n",
      "369500 11.2 0.09999999999985551\n",
      "370000 13.1 0.09999999999985551\n",
      "370500 11.3 0.09999999999985551\n",
      "371000 13.8 0.09999999999985551\n",
      "371500 11.9 0.09999999999985551\n",
      "372000 9.2 0.09999999999985551\n",
      "372500 14.9 0.09999999999985551\n",
      "373000 11.4 0.09999999999985551\n",
      "373500 12.4 0.09999999999985551\n",
      "374000 12.4 0.09999999999985551\n",
      "374500 12.4 0.09999999999985551\n",
      "375000 16.2 0.09999999999985551\n",
      "375500 9.7 0.09999999999985551\n",
      "376000 11.8 0.09999999999985551\n",
      "376500 10.8 0.09999999999985551\n",
      "377000 8.6 0.09999999999985551\n",
      "377500 13.7 0.09999999999985551\n",
      "378000 11.6 0.09999999999985551\n",
      "378500 16.9 0.09999999999985551\n",
      "379000 11.9 0.09999999999985551\n",
      "379500 11.1 0.09999999999985551\n",
      "380000 12.6 0.09999999999985551\n",
      "380500 10.2 0.09999999999985551\n",
      "381000 16.6 0.09999999999985551\n",
      "381500 13.4 0.09999999999985551\n",
      "382000 12.0 0.09999999999985551\n",
      "382500 13.1 0.09999999999985551\n",
      "383000 12.5 0.09999999999985551\n",
      "383500 12.0 0.09999999999985551\n",
      "384000 8.7 0.09999999999985551\n",
      "384500 9.1 0.09999999999985551\n",
      "385000 10.6 0.09999999999985551\n",
      "385500 13.0 0.09999999999985551\n",
      "386000 13.0 0.09999999999985551\n",
      "386500 11.8 0.09999999999985551\n",
      "387000 12.7 0.09999999999985551\n",
      "387500 9.3 0.09999999999985551\n",
      "388000 10.6 0.09999999999985551\n",
      "388500 10.7 0.09999999999985551\n",
      "389000 13.9 0.09999999999985551\n",
      "389500 10.4 0.09999999999985551\n",
      "390000 14.8 0.09999999999985551\n",
      "390500 12.3 0.09999999999985551\n",
      "391000 11.8 0.09999999999985551\n",
      "391500 12.3 0.09999999999985551\n",
      "392000 13.8 0.09999999999985551\n",
      "392500 13.7 0.09999999999985551\n",
      "393000 12.2 0.09999999999985551\n",
      "393500 14.0 0.09999999999985551\n",
      "394000 10.6 0.09999999999985551\n",
      "394500 9.0 0.09999999999985551\n",
      "395000 7.9 0.09999999999985551\n",
      "395500 12.8 0.09999999999985551\n",
      "396000 12.0 0.09999999999985551\n",
      "396500 9.6 0.09999999999985551\n",
      "397000 11.0 0.09999999999985551\n",
      "397500 13.6 0.09999999999985551\n",
      "398000 12.8 0.09999999999985551\n",
      "398500 12.5 0.09999999999985551\n",
      "399000 12.9 0.09999999999985551\n",
      "399500 14.0 0.09999999999985551\n",
      "400000 13.1 0.09999999999985551\n",
      "Saved Model\n",
      "400500 12.8 0.09999999999985551\n",
      "401000 12.1 0.09999999999985551\n",
      "401500 12.0 0.09999999999985551\n",
      "402000 12.4 0.09999999999985551\n",
      "402500 13.7 0.09999999999985551\n",
      "403000 12.9 0.09999999999985551\n",
      "403500 14.3 0.09999999999985551\n",
      "404000 8.2 0.09999999999985551\n",
      "404500 11.0 0.09999999999985551\n",
      "405000 11.8 0.09999999999985551\n",
      "405500 14.3 0.09999999999985551\n",
      "406000 14.2 0.09999999999985551\n",
      "406500 11.0 0.09999999999985551\n",
      "407000 11.7 0.09999999999985551\n",
      "407500 13.9 0.09999999999985551\n",
      "408000 14.0 0.09999999999985551\n",
      "408500 11.4 0.09999999999985551\n",
      "409000 9.3 0.09999999999985551\n",
      "409500 10.8 0.09999999999985551\n",
      "410000 12.0 0.09999999999985551\n",
      "410500 13.0 0.09999999999985551\n",
      "411000 14.2 0.09999999999985551\n",
      "411500 11.2 0.09999999999985551\n",
      "412000 12.7 0.09999999999985551\n",
      "412500 13.1 0.09999999999985551\n",
      "413000 13.6 0.09999999999985551\n",
      "413500 10.6 0.09999999999985551\n",
      "414000 8.9 0.09999999999985551\n",
      "414500 11.7 0.09999999999985551\n",
      "415000 11.5 0.09999999999985551\n",
      "415500 11.3 0.09999999999985551\n",
      "416000 11.4 0.09999999999985551\n",
      "416500 14.3 0.09999999999985551\n",
      "417000 13.1 0.09999999999985551\n",
      "417500 15.4 0.09999999999985551\n",
      "418000 14.6 0.09999999999985551\n",
      "418500 11.2 0.09999999999985551\n",
      "419000 10.0 0.09999999999985551\n",
      "419500 8.9 0.09999999999985551\n",
      "420000 12.4 0.09999999999985551\n",
      "420500 10.9 0.09999999999985551\n",
      "421000 11.8 0.09999999999985551\n",
      "421500 13.5 0.09999999999985551\n",
      "422000 13.4 0.09999999999985551\n",
      "422500 11.9 0.09999999999985551\n",
      "423000 13.9 0.09999999999985551\n",
      "423500 12.3 0.09999999999985551\n",
      "424000 10.4 0.09999999999985551\n",
      "424500 15.2 0.09999999999985551\n",
      "425000 10.7 0.09999999999985551\n",
      "425500 9.3 0.09999999999985551\n",
      "426000 10.5 0.09999999999985551\n",
      "426500 13.7 0.09999999999985551\n",
      "427000 14.4 0.09999999999985551\n",
      "427500 13.4 0.09999999999985551\n",
      "428000 13.3 0.09999999999985551\n",
      "428500 12.4 0.09999999999985551\n",
      "429000 13.1 0.09999999999985551\n",
      "429500 7.8 0.09999999999985551\n",
      "430000 11.0 0.09999999999985551\n",
      "430500 11.2 0.09999999999985551\n",
      "431000 12.5 0.09999999999985551\n",
      "431500 10.0 0.09999999999985551\n",
      "432000 11.9 0.09999999999985551\n",
      "432500 15.3 0.09999999999985551\n",
      "433000 9.4 0.09999999999985551\n",
      "433500 13.0 0.09999999999985551\n",
      "434000 12.4 0.09999999999985551\n",
      "434500 10.6 0.09999999999985551\n",
      "435000 10.9 0.09999999999985551\n",
      "435500 13.9 0.09999999999985551\n",
      "436000 12.3 0.09999999999985551\n",
      "436500 13.8 0.09999999999985551\n",
      "437000 10.4 0.09999999999985551\n",
      "437500 12.3 0.09999999999985551\n",
      "438000 14.5 0.09999999999985551\n",
      "438500 11.6 0.09999999999985551\n",
      "439000 12.3 0.09999999999985551\n",
      "439500 10.5 0.09999999999985551\n",
      "440000 12.9 0.09999999999985551\n",
      "440500 8.5 0.09999999999985551\n",
      "441000 14.3 0.09999999999985551\n",
      "441500 13.3 0.09999999999985551\n",
      "442000 9.5 0.09999999999985551\n",
      "442500 13.6 0.09999999999985551\n",
      "443000 12.8 0.09999999999985551\n",
      "443500 9.0 0.09999999999985551\n",
      "444000 12.9 0.09999999999985551\n",
      "444500 12.4 0.09999999999985551\n",
      "445000 7.3 0.09999999999985551\n",
      "445500 12.9 0.09999999999985551\n",
      "446000 16.2 0.09999999999985551\n",
      "446500 12.2 0.09999999999985551\n",
      "447000 13.2 0.09999999999985551\n",
      "447500 13.4 0.09999999999985551\n",
      "448000 12.0 0.09999999999985551\n",
      "448500 12.0 0.09999999999985551\n",
      "449000 11.0 0.09999999999985551\n",
      "449500 12.6 0.09999999999985551\n",
      "450000 12.3 0.09999999999985551\n",
      "Saved Model\n",
      "450500 11.6 0.09999999999985551\n",
      "451000 12.6 0.09999999999985551\n",
      "451500 12.9 0.09999999999985551\n",
      "452000 15.7 0.09999999999985551\n",
      "452500 11.9 0.09999999999985551\n",
      "453000 12.1 0.09999999999985551\n",
      "453500 12.3 0.09999999999985551\n",
      "454000 15.0 0.09999999999985551\n",
      "454500 10.7 0.09999999999985551\n",
      "455000 12.3 0.09999999999985551\n",
      "455500 12.0 0.09999999999985551\n",
      "456000 12.8 0.09999999999985551\n",
      "456500 10.3 0.09999999999985551\n",
      "457000 11.1 0.09999999999985551\n",
      "457500 11.3 0.09999999999985551\n",
      "458000 12.4 0.09999999999985551\n",
      "458500 13.7 0.09999999999985551\n",
      "459000 13.2 0.09999999999985551\n",
      "459500 13.2 0.09999999999985551\n",
      "460000 10.8 0.09999999999985551\n",
      "460500 12.2 0.09999999999985551\n",
      "461000 9.0 0.09999999999985551\n",
      "461500 9.9 0.09999999999985551\n",
      "462000 12.8 0.09999999999985551\n",
      "462500 12.6 0.09999999999985551\n",
      "463000 13.2 0.09999999999985551\n",
      "463500 13.2 0.09999999999985551\n",
      "464000 13.3 0.09999999999985551\n",
      "464500 11.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465000 11.2 0.09999999999985551\n",
      "465500 12.6 0.09999999999985551\n",
      "466000 12.3 0.09999999999985551\n",
      "466500 9.9 0.09999999999985551\n",
      "467000 10.5 0.09999999999985551\n",
      "467500 15.5 0.09999999999985551\n",
      "468000 11.3 0.09999999999985551\n",
      "468500 14.2 0.09999999999985551\n",
      "469000 7.4 0.09999999999985551\n",
      "469500 11.3 0.09999999999985551\n",
      "470000 11.5 0.09999999999985551\n",
      "470500 10.1 0.09999999999985551\n",
      "471000 13.4 0.09999999999985551\n",
      "471500 10.4 0.09999999999985551\n",
      "472000 13.5 0.09999999999985551\n",
      "472500 12.8 0.09999999999985551\n",
      "473000 11.1 0.09999999999985551\n",
      "473500 10.0 0.09999999999985551\n",
      "474000 11.8 0.09999999999985551\n",
      "474500 13.3 0.09999999999985551\n",
      "475000 12.0 0.09999999999985551\n",
      "475500 14.8 0.09999999999985551\n",
      "476000 12.2 0.09999999999985551\n",
      "476500 16.2 0.09999999999985551\n",
      "477000 9.0 0.09999999999985551\n",
      "477500 11.9 0.09999999999985551\n",
      "478000 12.6 0.09999999999985551\n",
      "478500 10.3 0.09999999999985551\n",
      "479000 13.8 0.09999999999985551\n",
      "479500 13.0 0.09999999999985551\n",
      "480000 13.9 0.09999999999985551\n",
      "480500 9.2 0.09999999999985551\n",
      "481000 12.3 0.09999999999985551\n",
      "481500 11.8 0.09999999999985551\n",
      "482000 12.1 0.09999999999985551\n",
      "482500 11.5 0.09999999999985551\n",
      "483000 11.9 0.09999999999985551\n",
      "483500 13.5 0.09999999999985551\n",
      "484000 11.9 0.09999999999985551\n",
      "484500 12.4 0.09999999999985551\n",
      "485000 8.6 0.09999999999985551\n",
      "485500 13.0 0.09999999999985551\n",
      "486000 11.1 0.09999999999985551\n",
      "486500 12.4 0.09999999999985551\n",
      "487000 13.9 0.09999999999985551\n",
      "487500 12.3 0.09999999999985551\n",
      "488000 11.3 0.09999999999985551\n",
      "488500 12.6 0.09999999999985551\n",
      "489000 11.7 0.09999999999985551\n",
      "489500 11.6 0.09999999999985551\n",
      "490000 12.7 0.09999999999985551\n",
      "490500 8.0 0.09999999999985551\n",
      "491000 10.4 0.09999999999985551\n",
      "491500 11.5 0.09999999999985551\n",
      "492000 12.9 0.09999999999985551\n",
      "492500 16.0 0.09999999999985551\n",
      "493000 14.7 0.09999999999985551\n",
      "493500 13.2 0.09999999999985551\n",
      "494000 13.7 0.09999999999985551\n",
      "494500 11.4 0.09999999999985551\n",
      "495000 15.2 0.09999999999985551\n",
      "495500 11.0 0.09999999999985551\n",
      "496000 11.3 0.09999999999985551\n",
      "496500 13.5 0.09999999999985551\n",
      "497000 12.1 0.09999999999985551\n",
      "497500 14.6 0.09999999999985551\n",
      "498000 11.9 0.09999999999985551\n",
      "498500 9.8 0.09999999999985551\n",
      "499000 12.3 0.09999999999985551\n",
      "499500 13.7 0.09999999999985551\n",
      "500000 13.2 0.09999999999985551\n",
      "Percent of succesful episodes: 10.0506%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4173b1dcc0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "%matplotlib inline\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld_gaussian import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./DQN_gaussian\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E7B8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E7B8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E3C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40E3C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40EEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40EEB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40EEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C40EEB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C40EA58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C65F898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C65F898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C65F898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C65F898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4D30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4D30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4D30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4D30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4DA0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4DA0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4DA0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4DA0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000002403C4A4438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000002403C742668>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 0.7 1\n",
      "1000 -1.4 1\n",
      "1500 -0.4 1\n",
      "2000 0.1 1\n",
      "2500 -0.1 1\n",
      "3000 0.5 1\n",
      "3500 0.6 1\n",
      "4000 -1.0 1\n",
      "4500 -0.1 1\n",
      "5000 -0.3 1\n",
      "5500 0.8 1\n",
      "6000 -1.1 1\n",
      "6500 -0.7 1\n",
      "7000 -0.3 1\n",
      "7500 -0.1 1\n",
      "8000 -0.1 1\n",
      "8500 -0.3 1\n",
      "9000 -1.0 1\n",
      "9500 -0.1 1\n",
      "10000 0.3 1\n",
      "10500 0.0 0.9549999999999828\n",
      "11000 0.4 0.9099999999999655\n",
      "11500 0.1 0.8649999999999483\n",
      "12000 0.7 0.819999999999931\n",
      "12500 0.6 0.7749999999999138\n",
      "13000 -0.5 0.7299999999998965\n",
      "13500 -0.3 0.6849999999998793\n",
      "14000 -0.2 0.639999999999862\n",
      "14500 -0.6 0.5949999999998448\n",
      "15000 0.5 0.5499999999998275\n",
      "15500 0.7 0.5049999999998103\n",
      "16000 -0.3 0.4599999999998177\n",
      "16500 0.3 0.41499999999982823\n",
      "17000 -0.1 0.36999999999983874\n",
      "17500 0.9 0.32499999999984924\n",
      "18000 0.5 0.27999999999985975\n",
      "18500 -0.1 0.23499999999986562\n",
      "19000 0.2 0.18999999999986225\n",
      "19500 0.0 0.14499999999985888\n",
      "20000 0.4 0.09999999999985551\n",
      "20500 0.1 0.09999999999985551\n",
      "21000 0.6 0.09999999999985551\n",
      "21500 0.0 0.09999999999985551\n",
      "22000 0.5 0.09999999999985551\n",
      "22500 0.4 0.09999999999985551\n",
      "23000 0.5 0.09999999999985551\n",
      "23500 0.0 0.09999999999985551\n",
      "24000 0.3 0.09999999999985551\n",
      "24500 -0.6 0.09999999999985551\n",
      "25000 -0.2 0.09999999999985551\n",
      "25500 -0.1 0.09999999999985551\n",
      "26000 0.6 0.09999999999985551\n",
      "26500 0.2 0.09999999999985551\n",
      "27000 -0.4 0.09999999999985551\n",
      "27500 0.2 0.09999999999985551\n",
      "28000 0.7 0.09999999999985551\n",
      "28500 -0.5 0.09999999999985551\n",
      "29000 0.3 0.09999999999985551\n",
      "29500 -0.3 0.09999999999985551\n",
      "30000 0.1 0.09999999999985551\n",
      "30500 0.3 0.09999999999985551\n",
      "31000 0.1 0.09999999999985551\n",
      "31500 0.0 0.09999999999985551\n",
      "32000 -0.4 0.09999999999985551\n",
      "32500 0.2 0.09999999999985551\n",
      "33000 0.3 0.09999999999985551\n",
      "33500 0.5 0.09999999999985551\n",
      "34000 0.1 0.09999999999985551\n",
      "34500 0.5 0.09999999999985551\n",
      "35000 0.3 0.09999999999985551\n",
      "35500 0.3 0.09999999999985551\n",
      "36000 0.3 0.09999999999985551\n",
      "36500 0.1 0.09999999999985551\n",
      "37000 0.1 0.09999999999985551\n",
      "37500 0.5 0.09999999999985551\n",
      "38000 0.5 0.09999999999985551\n",
      "38500 0.7 0.09999999999985551\n",
      "39000 -0.1 0.09999999999985551\n",
      "39500 0.3 0.09999999999985551\n",
      "40000 1.0 0.09999999999985551\n",
      "40500 0.1 0.09999999999985551\n",
      "41000 0.6 0.09999999999985551\n",
      "41500 -0.7 0.09999999999985551\n",
      "42000 -0.1 0.09999999999985551\n",
      "42500 -0.1 0.09999999999985551\n",
      "43000 0.7 0.09999999999985551\n",
      "43500 0.5 0.09999999999985551\n",
      "44000 0.0 0.09999999999985551\n",
      "44500 0.2 0.09999999999985551\n",
      "45000 0.8 0.09999999999985551\n",
      "45500 0.4 0.09999999999985551\n",
      "46000 0.9 0.09999999999985551\n",
      "46500 0.2 0.09999999999985551\n",
      "47000 0.2 0.09999999999985551\n",
      "47500 0.3 0.09999999999985551\n",
      "48000 0.5 0.09999999999985551\n",
      "48500 0.8 0.09999999999985551\n",
      "49000 -0.1 0.09999999999985551\n",
      "49500 1.0 0.09999999999985551\n",
      "50000 -0.4 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.9 0.09999999999985551\n",
      "51000 0.2 0.09999999999985551\n",
      "51500 0.2 0.09999999999985551\n",
      "52000 0.3 0.09999999999985551\n",
      "52500 0.4 0.09999999999985551\n",
      "53000 -0.4 0.09999999999985551\n",
      "53500 0.6 0.09999999999985551\n",
      "54000 0.1 0.09999999999985551\n",
      "54500 0.3 0.09999999999985551\n",
      "55000 0.9 0.09999999999985551\n",
      "55500 1.1 0.09999999999985551\n",
      "56000 0.9 0.09999999999985551\n",
      "56500 0.5 0.09999999999985551\n",
      "57000 0.7 0.09999999999985551\n",
      "57500 1.1 0.09999999999985551\n",
      "58000 0.7 0.09999999999985551\n",
      "58500 1.0 0.09999999999985551\n",
      "59000 0.5 0.09999999999985551\n",
      "59500 1.5 0.09999999999985551\n",
      "60000 0.6 0.09999999999985551\n",
      "60500 0.9 0.09999999999985551\n",
      "61000 1.0 0.09999999999985551\n",
      "61500 0.5 0.09999999999985551\n",
      "62000 0.6 0.09999999999985551\n",
      "62500 1.1 0.09999999999985551\n",
      "63000 0.8 0.09999999999985551\n",
      "63500 1.0 0.09999999999985551\n",
      "64000 0.8 0.09999999999985551\n",
      "64500 0.0 0.09999999999985551\n",
      "65000 -0.1 0.09999999999985551\n",
      "65500 0.7 0.09999999999985551\n",
      "66000 1.0 0.09999999999985551\n",
      "66500 0.9 0.09999999999985551\n",
      "67000 1.4 0.09999999999985551\n",
      "67500 0.7 0.09999999999985551\n",
      "68000 1.7 0.09999999999985551\n",
      "68500 0.8 0.09999999999985551\n",
      "69000 0.8 0.09999999999985551\n",
      "69500 1.2 0.09999999999985551\n",
      "70000 1.1 0.09999999999985551\n",
      "70500 1.1 0.09999999999985551\n",
      "71000 1.2 0.09999999999985551\n",
      "71500 0.8 0.09999999999985551\n",
      "72000 1.4 0.09999999999985551\n",
      "72500 1.9 0.09999999999985551\n",
      "73000 2.0 0.09999999999985551\n",
      "73500 1.5 0.09999999999985551\n",
      "74000 1.5 0.09999999999985551\n",
      "74500 1.1 0.09999999999985551\n",
      "75000 1.3 0.09999999999985551\n",
      "75500 1.8 0.09999999999985551\n",
      "76000 1.6 0.09999999999985551\n",
      "76500 1.6 0.09999999999985551\n",
      "77000 2.0 0.09999999999985551\n",
      "77500 1.1 0.09999999999985551\n",
      "78000 2.3 0.09999999999985551\n",
      "78500 1.1 0.09999999999985551\n",
      "79000 2.7 0.09999999999985551\n",
      "79500 2.4 0.09999999999985551\n",
      "80000 1.0 0.09999999999985551\n",
      "80500 1.6 0.09999999999985551\n",
      "81000 1.1 0.09999999999985551\n",
      "81500 1.8 0.09999999999985551\n",
      "82000 0.7 0.09999999999985551\n",
      "82500 1.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83000 1.6 0.09999999999985551\n",
      "83500 2.3 0.09999999999985551\n",
      "84000 3.8 0.09999999999985551\n",
      "84500 3.4 0.09999999999985551\n",
      "85000 2.9 0.09999999999985551\n",
      "85500 2.6 0.09999999999985551\n",
      "86000 3.0 0.09999999999985551\n",
      "86500 2.4 0.09999999999985551\n",
      "87000 3.2 0.09999999999985551\n",
      "87500 1.2 0.09999999999985551\n",
      "88000 3.5 0.09999999999985551\n",
      "88500 3.1 0.09999999999985551\n",
      "89000 1.9 0.09999999999985551\n",
      "89500 2.4 0.09999999999985551\n",
      "90000 2.5 0.09999999999985551\n",
      "90500 2.0 0.09999999999985551\n",
      "91000 3.5 0.09999999999985551\n",
      "91500 2.4 0.09999999999985551\n",
      "92000 5.1 0.09999999999985551\n",
      "92500 3.0 0.09999999999985551\n",
      "93000 3.8 0.09999999999985551\n",
      "93500 3.4 0.09999999999985551\n",
      "94000 4.1 0.09999999999985551\n",
      "94500 1.4 0.09999999999985551\n",
      "95000 3.2 0.09999999999985551\n",
      "95500 4.2 0.09999999999985551\n",
      "96000 4.0 0.09999999999985551\n",
      "96500 4.9 0.09999999999985551\n",
      "97000 2.6 0.09999999999985551\n",
      "97500 3.5 0.09999999999985551\n",
      "98000 4.7 0.09999999999985551\n",
      "98500 2.8 0.09999999999985551\n",
      "99000 4.0 0.09999999999985551\n",
      "99500 3.9 0.09999999999985551\n",
      "100000 3.2 0.09999999999985551\n",
      "Saved Model\n",
      "100500 4.0 0.09999999999985551\n",
      "101000 3.3 0.09999999999985551\n",
      "101500 4.0 0.09999999999985551\n",
      "102000 5.5 0.09999999999985551\n",
      "102500 4.2 0.09999999999985551\n",
      "103000 5.4 0.09999999999985551\n",
      "103500 3.9 0.09999999999985551\n",
      "104000 3.7 0.09999999999985551\n",
      "104500 4.4 0.09999999999985551\n",
      "105000 4.0 0.09999999999985551\n",
      "105500 3.6 0.09999999999985551\n",
      "106000 5.7 0.09999999999985551\n",
      "106500 5.3 0.09999999999985551\n",
      "107000 5.5 0.09999999999985551\n",
      "107500 4.4 0.09999999999985551\n",
      "108000 5.5 0.09999999999985551\n",
      "108500 5.9 0.09999999999985551\n",
      "109000 5.3 0.09999999999985551\n",
      "109500 3.5 0.09999999999985551\n",
      "110000 6.8 0.09999999999985551\n",
      "110500 8.4 0.09999999999985551\n",
      "111000 7.1 0.09999999999985551\n",
      "111500 4.6 0.09999999999985551\n",
      "112000 4.5 0.09999999999985551\n",
      "112500 5.4 0.09999999999985551\n",
      "113000 5.8 0.09999999999985551\n",
      "113500 8.3 0.09999999999985551\n",
      "114000 7.2 0.09999999999985551\n",
      "114500 6.3 0.09999999999985551\n",
      "115000 5.0 0.09999999999985551\n",
      "115500 6.1 0.09999999999985551\n",
      "116000 8.2 0.09999999999985551\n",
      "116500 6.6 0.09999999999985551\n",
      "117000 5.8 0.09999999999985551\n",
      "117500 3.1 0.09999999999985551\n",
      "118000 5.9 0.09999999999985551\n",
      "118500 7.7 0.09999999999985551\n",
      "119000 6.1 0.09999999999985551\n",
      "119500 8.7 0.09999999999985551\n",
      "120000 6.3 0.09999999999985551\n",
      "120500 4.6 0.09999999999985551\n",
      "121000 7.8 0.09999999999985551\n",
      "121500 4.8 0.09999999999985551\n",
      "122000 6.9 0.09999999999985551\n",
      "122500 4.5 0.09999999999985551\n",
      "123000 8.2 0.09999999999985551\n",
      "123500 6.8 0.09999999999985551\n",
      "124000 8.2 0.09999999999985551\n",
      "124500 7.9 0.09999999999985551\n",
      "125000 5.3 0.09999999999985551\n",
      "125500 6.5 0.09999999999985551\n",
      "126000 4.4 0.09999999999985551\n",
      "126500 5.7 0.09999999999985551\n",
      "127000 7.7 0.09999999999985551\n",
      "127500 7.7 0.09999999999985551\n",
      "128000 7.0 0.09999999999985551\n",
      "128500 5.8 0.09999999999985551\n",
      "129000 7.8 0.09999999999985551\n",
      "129500 9.6 0.09999999999985551\n",
      "130000 8.7 0.09999999999985551\n",
      "130500 7.7 0.09999999999985551\n",
      "131000 7.3 0.09999999999985551\n",
      "131500 8.5 0.09999999999985551\n",
      "132000 6.3 0.09999999999985551\n",
      "132500 6.8 0.09999999999985551\n",
      "133000 8.4 0.09999999999985551\n",
      "133500 6.1 0.09999999999985551\n",
      "134000 10.2 0.09999999999985551\n",
      "134500 7.1 0.09999999999985551\n",
      "135000 8.5 0.09999999999985551\n",
      "135500 6.9 0.09999999999985551\n",
      "136000 6.6 0.09999999999985551\n",
      "136500 6.8 0.09999999999985551\n",
      "137000 10.0 0.09999999999985551\n",
      "137500 8.5 0.09999999999985551\n",
      "138000 6.7 0.09999999999985551\n",
      "138500 6.7 0.09999999999985551\n",
      "139000 7.9 0.09999999999985551\n",
      "139500 8.7 0.09999999999985551\n",
      "140000 8.3 0.09999999999985551\n",
      "140500 9.1 0.09999999999985551\n",
      "141000 7.9 0.09999999999985551\n",
      "141500 6.8 0.09999999999985551\n",
      "142000 5.3 0.09999999999985551\n",
      "142500 8.1 0.09999999999985551\n",
      "143000 6.9 0.09999999999985551\n",
      "143500 7.0 0.09999999999985551\n",
      "144000 7.7 0.09999999999985551\n",
      "144500 6.9 0.09999999999985551\n",
      "145000 9.8 0.09999999999985551\n",
      "145500 9.2 0.09999999999985551\n",
      "146000 6.6 0.09999999999985551\n",
      "146500 8.9 0.09999999999985551\n",
      "147000 5.6 0.09999999999985551\n",
      "147500 6.3 0.09999999999985551\n",
      "148000 5.6 0.09999999999985551\n",
      "148500 8.7 0.09999999999985551\n",
      "149000 9.0 0.09999999999985551\n",
      "149500 9.1 0.09999999999985551\n",
      "150000 7.7 0.09999999999985551\n",
      "Saved Model\n",
      "150500 8.1 0.09999999999985551\n",
      "151000 6.8 0.09999999999985551\n",
      "151500 8.1 0.09999999999985551\n",
      "152000 9.9 0.09999999999985551\n",
      "152500 8.0 0.09999999999985551\n",
      "153000 7.7 0.09999999999985551\n",
      "153500 7.0 0.09999999999985551\n",
      "154000 8.9 0.09999999999985551\n",
      "154500 9.0 0.09999999999985551\n",
      "155000 7.0 0.09999999999985551\n",
      "155500 10.1 0.09999999999985551\n",
      "156000 8.2 0.09999999999985551\n",
      "156500 8.9 0.09999999999985551\n",
      "157000 8.8 0.09999999999985551\n",
      "157500 6.3 0.09999999999985551\n",
      "158000 6.7 0.09999999999985551\n",
      "158500 6.4 0.09999999999985551\n",
      "159000 9.0 0.09999999999985551\n",
      "159500 6.6 0.09999999999985551\n",
      "160000 6.0 0.09999999999985551\n",
      "160500 9.0 0.09999999999985551\n",
      "161000 5.3 0.09999999999985551\n",
      "161500 8.1 0.09999999999985551\n",
      "162000 9.6 0.09999999999985551\n",
      "162500 8.0 0.09999999999985551\n",
      "163000 9.7 0.09999999999985551\n",
      "163500 9.3 0.09999999999985551\n",
      "164000 7.2 0.09999999999985551\n",
      "164500 10.5 0.09999999999985551\n",
      "165000 7.4 0.09999999999985551\n",
      "165500 5.6 0.09999999999985551\n",
      "166000 9.2 0.09999999999985551\n",
      "166500 7.9 0.09999999999985551\n",
      "167000 10.6 0.09999999999985551\n",
      "167500 8.9 0.09999999999985551\n",
      "168000 6.4 0.09999999999985551\n",
      "168500 9.9 0.09999999999985551\n",
      "169000 8.8 0.09999999999985551\n",
      "169500 6.6 0.09999999999985551\n",
      "170000 6.8 0.09999999999985551\n",
      "170500 8.4 0.09999999999985551\n",
      "171000 7.0 0.09999999999985551\n",
      "171500 7.9 0.09999999999985551\n",
      "172000 8.8 0.09999999999985551\n",
      "172500 6.6 0.09999999999985551\n",
      "173000 8.5 0.09999999999985551\n",
      "173500 8.5 0.09999999999985551\n",
      "174000 5.9 0.09999999999985551\n",
      "174500 10.3 0.09999999999985551\n",
      "175000 6.6 0.09999999999985551\n",
      "175500 7.7 0.09999999999985551\n",
      "176000 9.7 0.09999999999985551\n",
      "176500 8.6 0.09999999999985551\n",
      "177000 9.5 0.09999999999985551\n",
      "177500 8.0 0.09999999999985551\n",
      "178000 9.6 0.09999999999985551\n",
      "178500 10.9 0.09999999999985551\n",
      "179000 8.3 0.09999999999985551\n",
      "179500 5.9 0.09999999999985551\n",
      "180000 9.0 0.09999999999985551\n",
      "180500 6.8 0.09999999999985551\n",
      "181000 8.4 0.09999999999985551\n",
      "181500 6.6 0.09999999999985551\n",
      "182000 8.2 0.09999999999985551\n",
      "182500 6.5 0.09999999999985551\n",
      "183000 8.0 0.09999999999985551\n",
      "183500 9.7 0.09999999999985551\n",
      "184000 8.0 0.09999999999985551\n",
      "184500 6.5 0.09999999999985551\n",
      "185000 7.8 0.09999999999985551\n",
      "185500 6.1 0.09999999999985551\n",
      "186000 8.5 0.09999999999985551\n",
      "186500 9.0 0.09999999999985551\n",
      "187000 7.7 0.09999999999985551\n",
      "187500 7.7 0.09999999999985551\n",
      "188000 9.2 0.09999999999985551\n",
      "188500 9.4 0.09999999999985551\n",
      "189000 8.4 0.09999999999985551\n",
      "189500 8.3 0.09999999999985551\n",
      "190000 10.7 0.09999999999985551\n",
      "190500 9.0 0.09999999999985551\n",
      "191000 7.5 0.09999999999985551\n",
      "191500 8.9 0.09999999999985551\n",
      "192000 8.2 0.09999999999985551\n",
      "192500 6.6 0.09999999999985551\n",
      "193000 7.7 0.09999999999985551\n",
      "193500 6.9 0.09999999999985551\n",
      "194000 8.9 0.09999999999985551\n",
      "194500 8.2 0.09999999999985551\n",
      "195000 8.6 0.09999999999985551\n",
      "195500 10.7 0.09999999999985551\n",
      "196000 7.9 0.09999999999985551\n",
      "196500 9.1 0.09999999999985551\n",
      "197000 6.6 0.09999999999985551\n",
      "197500 4.6 0.09999999999985551\n",
      "198000 5.9 0.09999999999985551\n",
      "198500 8.6 0.09999999999985551\n",
      "199000 10.2 0.09999999999985551\n",
      "199500 11.8 0.09999999999985551\n",
      "200000 7.9 0.09999999999985551\n",
      "Saved Model\n",
      "200500 7.0 0.09999999999985551\n",
      "201000 6.6 0.09999999999985551\n",
      "201500 7.4 0.09999999999985551\n",
      "202000 7.6 0.09999999999985551\n",
      "202500 10.3 0.09999999999985551\n",
      "203000 8.9 0.09999999999985551\n",
      "203500 6.9 0.09999999999985551\n",
      "204000 6.8 0.09999999999985551\n",
      "204500 9.3 0.09999999999985551\n",
      "205000 9.5 0.09999999999985551\n",
      "205500 9.5 0.09999999999985551\n",
      "206000 7.7 0.09999999999985551\n",
      "206500 9.7 0.09999999999985551\n",
      "207000 7.7 0.09999999999985551\n",
      "207500 8.4 0.09999999999985551\n",
      "208000 7.6 0.09999999999985551\n",
      "208500 8.6 0.09999999999985551\n",
      "209000 11.2 0.09999999999985551\n",
      "209500 5.6 0.09999999999985551\n",
      "210000 7.0 0.09999999999985551\n",
      "210500 9.7 0.09999999999985551\n",
      "211000 8.5 0.09999999999985551\n",
      "211500 8.4 0.09999999999985551\n",
      "212000 7.6 0.09999999999985551\n",
      "212500 9.2 0.09999999999985551\n",
      "213000 7.8 0.09999999999985551\n",
      "213500 10.7 0.09999999999985551\n",
      "214000 8.5 0.09999999999985551\n",
      "214500 9.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215000 8.4 0.09999999999985551\n",
      "215500 10.4 0.09999999999985551\n",
      "216000 9.4 0.09999999999985551\n",
      "216500 9.8 0.09999999999985551\n",
      "217000 8.3 0.09999999999985551\n",
      "217500 9.3 0.09999999999985551\n",
      "218000 8.1 0.09999999999985551\n",
      "218500 9.6 0.09999999999985551\n",
      "219000 9.0 0.09999999999985551\n",
      "219500 7.4 0.09999999999985551\n",
      "220000 8.9 0.09999999999985551\n",
      "220500 8.9 0.09999999999985551\n",
      "221000 9.6 0.09999999999985551\n",
      "221500 8.7 0.09999999999985551\n",
      "222000 8.6 0.09999999999985551\n",
      "222500 8.1 0.09999999999985551\n",
      "223000 10.2 0.09999999999985551\n",
      "223500 5.9 0.09999999999985551\n",
      "224000 7.6 0.09999999999985551\n",
      "224500 8.1 0.09999999999985551\n",
      "225000 6.1 0.09999999999985551\n",
      "225500 8.3 0.09999999999985551\n",
      "226000 9.7 0.09999999999985551\n",
      "226500 7.8 0.09999999999985551\n",
      "227000 5.8 0.09999999999985551\n",
      "227500 8.4 0.09999999999985551\n",
      "228000 7.6 0.09999999999985551\n",
      "228500 7.8 0.09999999999985551\n",
      "229000 7.5 0.09999999999985551\n",
      "229500 9.4 0.09999999999985551\n",
      "230000 8.7 0.09999999999985551\n",
      "230500 9.0 0.09999999999985551\n",
      "231000 9.4 0.09999999999985551\n",
      "231500 8.3 0.09999999999985551\n",
      "232000 8.3 0.09999999999985551\n",
      "232500 9.9 0.09999999999985551\n",
      "233000 9.9 0.09999999999985551\n",
      "233500 9.8 0.09999999999985551\n",
      "234000 8.7 0.09999999999985551\n",
      "234500 8.1 0.09999999999985551\n",
      "235000 9.1 0.09999999999985551\n",
      "235500 9.8 0.09999999999985551\n",
      "236000 7.6 0.09999999999985551\n",
      "236500 7.0 0.09999999999985551\n",
      "237000 8.5 0.09999999999985551\n",
      "237500 10.1 0.09999999999985551\n",
      "238000 9.1 0.09999999999985551\n",
      "238500 9.7 0.09999999999985551\n",
      "239000 9.5 0.09999999999985551\n",
      "239500 8.3 0.09999999999985551\n",
      "240000 9.7 0.09999999999985551\n",
      "240500 9.2 0.09999999999985551\n",
      "241000 6.8 0.09999999999985551\n",
      "241500 8.6 0.09999999999985551\n",
      "242000 11.9 0.09999999999985551\n",
      "242500 11.9 0.09999999999985551\n",
      "243000 9.8 0.09999999999985551\n",
      "243500 8.1 0.09999999999985551\n",
      "244000 7.7 0.09999999999985551\n",
      "244500 7.6 0.09999999999985551\n",
      "245000 10.9 0.09999999999985551\n",
      "245500 7.7 0.09999999999985551\n",
      "246000 7.8 0.09999999999985551\n",
      "246500 10.5 0.09999999999985551\n",
      "247000 9.5 0.09999999999985551\n",
      "247500 10.5 0.09999999999985551\n",
      "248000 10.0 0.09999999999985551\n",
      "248500 9.6 0.09999999999985551\n",
      "249000 8.5 0.09999999999985551\n",
      "249500 9.5 0.09999999999985551\n",
      "250000 4.8 0.09999999999985551\n",
      "WARNING:tensorflow:From C:\\Users\\Assistant_2\\Anaconda3\\envs\\RL_test\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 9.5 0.09999999999985551\n",
      "251000 10.0 0.09999999999985551\n",
      "251500 8.9 0.09999999999985551\n",
      "252000 11.4 0.09999999999985551\n",
      "252500 9.7 0.09999999999985551\n",
      "253000 9.2 0.09999999999985551\n",
      "253500 8.9 0.09999999999985551\n",
      "254000 7.7 0.09999999999985551\n",
      "254500 8.5 0.09999999999985551\n",
      "255000 8.3 0.09999999999985551\n",
      "255500 8.7 0.09999999999985551\n",
      "256000 9.8 0.09999999999985551\n",
      "256500 9.2 0.09999999999985551\n",
      "257000 8.1 0.09999999999985551\n",
      "257500 7.1 0.09999999999985551\n",
      "258000 9.0 0.09999999999985551\n",
      "258500 10.4 0.09999999999985551\n",
      "259000 9.8 0.09999999999985551\n",
      "259500 9.1 0.09999999999985551\n",
      "260000 10.5 0.09999999999985551\n",
      "260500 7.5 0.09999999999985551\n",
      "261000 6.9 0.09999999999985551\n",
      "261500 9.3 0.09999999999985551\n",
      "262000 8.0 0.09999999999985551\n",
      "262500 6.7 0.09999999999985551\n",
      "263000 9.8 0.09999999999985551\n",
      "263500 11.4 0.09999999999985551\n",
      "264000 11.0 0.09999999999985551\n",
      "264500 6.9 0.09999999999985551\n",
      "265000 9.3 0.09999999999985551\n",
      "265500 8.2 0.09999999999985551\n",
      "266000 8.8 0.09999999999985551\n",
      "266500 9.0 0.09999999999985551\n",
      "267000 9.7 0.09999999999985551\n",
      "267500 8.3 0.09999999999985551\n",
      "268000 7.0 0.09999999999985551\n",
      "268500 9.4 0.09999999999985551\n",
      "269000 10.7 0.09999999999985551\n",
      "269500 6.7 0.09999999999985551\n",
      "270000 10.9 0.09999999999985551\n",
      "270500 10.2 0.09999999999985551\n",
      "271000 8.1 0.09999999999985551\n",
      "271500 10.4 0.09999999999985551\n",
      "272000 8.6 0.09999999999985551\n",
      "272500 10.8 0.09999999999985551\n",
      "273000 9.9 0.09999999999985551\n",
      "273500 11.2 0.09999999999985551\n",
      "274000 9.5 0.09999999999985551\n",
      "274500 9.1 0.09999999999985551\n",
      "275000 10.2 0.09999999999985551\n",
      "275500 10.8 0.09999999999985551\n",
      "276000 10.0 0.09999999999985551\n",
      "276500 11.8 0.09999999999985551\n",
      "277000 7.2 0.09999999999985551\n",
      "277500 8.2 0.09999999999985551\n",
      "278000 8.5 0.09999999999985551\n",
      "278500 6.6 0.09999999999985551\n",
      "279000 9.7 0.09999999999985551\n",
      "279500 7.1 0.09999999999985551\n",
      "280000 7.2 0.09999999999985551\n",
      "280500 10.0 0.09999999999985551\n",
      "281000 6.6 0.09999999999985551\n",
      "281500 7.5 0.09999999999985551\n",
      "282000 7.7 0.09999999999985551\n",
      "282500 8.3 0.09999999999985551\n",
      "283000 8.0 0.09999999999985551\n",
      "283500 10.4 0.09999999999985551\n",
      "284000 8.9 0.09999999999985551\n",
      "284500 10.6 0.09999999999985551\n",
      "285000 10.2 0.09999999999985551\n",
      "285500 9.7 0.09999999999985551\n",
      "286000 11.4 0.09999999999985551\n",
      "286500 8.5 0.09999999999985551\n",
      "287000 10.2 0.09999999999985551\n",
      "287500 7.5 0.09999999999985551\n",
      "288000 8.4 0.09999999999985551\n",
      "288500 9.4 0.09999999999985551\n",
      "289000 7.2 0.09999999999985551\n",
      "289500 8.1 0.09999999999985551\n",
      "290000 9.8 0.09999999999985551\n",
      "290500 8.5 0.09999999999985551\n",
      "291000 8.2 0.09999999999985551\n",
      "291500 9.9 0.09999999999985551\n",
      "292000 8.8 0.09999999999985551\n",
      "292500 9.0 0.09999999999985551\n",
      "293000 10.6 0.09999999999985551\n",
      "293500 8.4 0.09999999999985551\n",
      "294000 8.7 0.09999999999985551\n",
      "294500 7.0 0.09999999999985551\n",
      "295000 10.1 0.09999999999985551\n",
      "295500 8.3 0.09999999999985551\n",
      "296000 8.1 0.09999999999985551\n",
      "296500 10.3 0.09999999999985551\n",
      "297000 10.2 0.09999999999985551\n",
      "297500 8.3 0.09999999999985551\n",
      "298000 9.8 0.09999999999985551\n",
      "298500 9.6 0.09999999999985551\n",
      "299000 8.1 0.09999999999985551\n",
      "299500 10.7 0.09999999999985551\n",
      "300000 9.1 0.09999999999985551\n",
      "Saved Model\n",
      "300500 6.2 0.09999999999985551\n",
      "301000 9.4 0.09999999999985551\n",
      "301500 11.8 0.09999999999985551\n",
      "302000 6.6 0.09999999999985551\n",
      "302500 8.5 0.09999999999985551\n",
      "303000 10.1 0.09999999999985551\n",
      "303500 11.1 0.09999999999985551\n",
      "304000 10.0 0.09999999999985551\n",
      "304500 8.2 0.09999999999985551\n",
      "305000 11.2 0.09999999999985551\n",
      "305500 7.6 0.09999999999985551\n",
      "306000 8.2 0.09999999999985551\n",
      "306500 7.8 0.09999999999985551\n",
      "307000 7.1 0.09999999999985551\n",
      "307500 6.5 0.09999999999985551\n",
      "308000 8.6 0.09999999999985551\n",
      "308500 10.1 0.09999999999985551\n",
      "309000 9.7 0.09999999999985551\n",
      "309500 10.1 0.09999999999985551\n",
      "310000 9.9 0.09999999999985551\n",
      "310500 10.4 0.09999999999985551\n",
      "311000 9.9 0.09999999999985551\n",
      "311500 9.4 0.09999999999985551\n",
      "312000 9.7 0.09999999999985551\n",
      "312500 7.8 0.09999999999985551\n",
      "313000 10.7 0.09999999999985551\n",
      "313500 10.1 0.09999999999985551\n",
      "314000 13.2 0.09999999999985551\n",
      "314500 7.6 0.09999999999985551\n",
      "315000 10.4 0.09999999999985551\n",
      "315500 9.8 0.09999999999985551\n",
      "316000 8.4 0.09999999999985551\n",
      "316500 8.8 0.09999999999985551\n",
      "317000 8.0 0.09999999999985551\n",
      "317500 9.4 0.09999999999985551\n",
      "318000 8.3 0.09999999999985551\n",
      "318500 10.6 0.09999999999985551\n",
      "319000 8.5 0.09999999999985551\n",
      "319500 9.5 0.09999999999985551\n",
      "320000 8.4 0.09999999999985551\n",
      "320500 10.9 0.09999999999985551\n",
      "321000 9.2 0.09999999999985551\n",
      "321500 7.8 0.09999999999985551\n",
      "322000 8.5 0.09999999999985551\n",
      "322500 8.5 0.09999999999985551\n",
      "323000 10.8 0.09999999999985551\n",
      "323500 10.8 0.09999999999985551\n",
      "324000 10.3 0.09999999999985551\n",
      "324500 9.7 0.09999999999985551\n",
      "325000 10.0 0.09999999999985551\n",
      "325500 9.0 0.09999999999985551\n",
      "326000 7.5 0.09999999999985551\n",
      "326500 7.7 0.09999999999985551\n",
      "327000 9.7 0.09999999999985551\n",
      "327500 11.3 0.09999999999985551\n",
      "328000 9.8 0.09999999999985551\n",
      "328500 8.7 0.09999999999985551\n",
      "329000 9.0 0.09999999999985551\n",
      "329500 11.4 0.09999999999985551\n",
      "330000 9.7 0.09999999999985551\n",
      "330500 9.4 0.09999999999985551\n",
      "331000 8.2 0.09999999999985551\n",
      "331500 10.4 0.09999999999985551\n",
      "332000 9.5 0.09999999999985551\n",
      "332500 10.3 0.09999999999985551\n",
      "333000 8.6 0.09999999999985551\n",
      "333500 8.5 0.09999999999985551\n",
      "334000 9.1 0.09999999999985551\n",
      "334500 10.2 0.09999999999985551\n",
      "335000 8.2 0.09999999999985551\n",
      "335500 8.9 0.09999999999985551\n",
      "336000 9.5 0.09999999999985551\n",
      "336500 8.0 0.09999999999985551\n",
      "337000 9.9 0.09999999999985551\n",
      "337500 8.4 0.09999999999985551\n",
      "338000 8.9 0.09999999999985551\n",
      "338500 10.1 0.09999999999985551\n",
      "339000 9.2 0.09999999999985551\n",
      "339500 10.4 0.09999999999985551\n",
      "340000 7.8 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340500 9.4 0.09999999999985551\n",
      "341000 8.9 0.09999999999985551\n",
      "341500 10.3 0.09999999999985551\n",
      "342000 11.3 0.09999999999985551\n",
      "342500 8.0 0.09999999999985551\n",
      "343000 8.9 0.09999999999985551\n",
      "343500 7.6 0.09999999999985551\n",
      "344000 10.4 0.09999999999985551\n",
      "344500 8.8 0.09999999999985551\n",
      "345000 9.3 0.09999999999985551\n",
      "345500 6.6 0.09999999999985551\n",
      "346000 6.3 0.09999999999985551\n",
      "346500 10.9 0.09999999999985551\n",
      "347000 8.7 0.09999999999985551\n",
      "347500 10.4 0.09999999999985551\n",
      "348000 7.7 0.09999999999985551\n",
      "348500 9.3 0.09999999999985551\n",
      "349000 8.3 0.09999999999985551\n",
      "349500 10.2 0.09999999999985551\n",
      "350000 8.5 0.09999999999985551\n",
      "Saved Model\n",
      "350500 9.1 0.09999999999985551\n",
      "351000 7.5 0.09999999999985551\n",
      "351500 7.1 0.09999999999985551\n",
      "352000 8.9 0.09999999999985551\n",
      "352500 8.8 0.09999999999985551\n",
      "353000 12.2 0.09999999999985551\n",
      "353500 8.9 0.09999999999985551\n",
      "354000 8.0 0.09999999999985551\n",
      "354500 8.7 0.09999999999985551\n",
      "355000 10.1 0.09999999999985551\n",
      "355500 8.7 0.09999999999985551\n",
      "356000 8.5 0.09999999999985551\n",
      "356500 10.8 0.09999999999985551\n",
      "357000 9.8 0.09999999999985551\n",
      "357500 8.9 0.09999999999985551\n",
      "358000 9.0 0.09999999999985551\n",
      "358500 9.8 0.09999999999985551\n",
      "359000 10.8 0.09999999999985551\n",
      "359500 8.1 0.09999999999985551\n",
      "360000 7.4 0.09999999999985551\n",
      "360500 8.8 0.09999999999985551\n",
      "361000 6.0 0.09999999999985551\n",
      "361500 8.6 0.09999999999985551\n",
      "362000 10.3 0.09999999999985551\n",
      "362500 10.1 0.09999999999985551\n",
      "363000 10.9 0.09999999999985551\n",
      "363500 7.5 0.09999999999985551\n",
      "364000 7.7 0.09999999999985551\n",
      "364500 10.2 0.09999999999985551\n",
      "365000 9.0 0.09999999999985551\n",
      "365500 12.7 0.09999999999985551\n",
      "366000 12.9 0.09999999999985551\n",
      "366500 10.3 0.09999999999985551\n",
      "367000 9.7 0.09999999999985551\n",
      "367500 11.9 0.09999999999985551\n",
      "368000 9.9 0.09999999999985551\n",
      "368500 10.7 0.09999999999985551\n",
      "369000 7.9 0.09999999999985551\n",
      "369500 12.2 0.09999999999985551\n",
      "370000 11.1 0.09999999999985551\n",
      "370500 11.8 0.09999999999985551\n",
      "371000 9.6 0.09999999999985551\n",
      "371500 8.8 0.09999999999985551\n",
      "372000 10.1 0.09999999999985551\n",
      "372500 9.2 0.09999999999985551\n",
      "373000 9.4 0.09999999999985551\n",
      "373500 10.4 0.09999999999985551\n",
      "374000 9.1 0.09999999999985551\n",
      "374500 11.9 0.09999999999985551\n",
      "375000 9.1 0.09999999999985551\n",
      "375500 10.7 0.09999999999985551\n",
      "376000 8.8 0.09999999999985551\n",
      "376500 10.8 0.09999999999985551\n",
      "377000 9.5 0.09999999999985551\n",
      "377500 9.8 0.09999999999985551\n",
      "378000 10.2 0.09999999999985551\n",
      "378500 9.1 0.09999999999985551\n",
      "379000 10.1 0.09999999999985551\n",
      "379500 10.3 0.09999999999985551\n",
      "380000 8.1 0.09999999999985551\n",
      "380500 10.1 0.09999999999985551\n",
      "381000 10.9 0.09999999999985551\n",
      "381500 10.6 0.09999999999985551\n",
      "382000 11.5 0.09999999999985551\n",
      "382500 11.6 0.09999999999985551\n",
      "383000 9.5 0.09999999999985551\n",
      "383500 7.8 0.09999999999985551\n",
      "384000 12.1 0.09999999999985551\n",
      "384500 8.5 0.09999999999985551\n",
      "385000 11.2 0.09999999999985551\n",
      "385500 9.6 0.09999999999985551\n",
      "386000 9.8 0.09999999999985551\n",
      "386500 10.8 0.09999999999985551\n",
      "387000 11.3 0.09999999999985551\n",
      "387500 9.0 0.09999999999985551\n",
      "388000 9.8 0.09999999999985551\n",
      "388500 9.4 0.09999999999985551\n",
      "389000 6.6 0.09999999999985551\n",
      "389500 11.6 0.09999999999985551\n",
      "390000 11.7 0.09999999999985551\n",
      "390500 10.4 0.09999999999985551\n",
      "391000 9.4 0.09999999999985551\n",
      "391500 8.6 0.09999999999985551\n",
      "392000 9.5 0.09999999999985551\n",
      "392500 10.1 0.09999999999985551\n",
      "393000 8.0 0.09999999999985551\n",
      "393500 10.9 0.09999999999985551\n",
      "394000 10.6 0.09999999999985551\n",
      "394500 8.3 0.09999999999985551\n",
      "395000 8.8 0.09999999999985551\n",
      "395500 13.4 0.09999999999985551\n",
      "396000 11.3 0.09999999999985551\n",
      "396500 8.2 0.09999999999985551\n",
      "397000 10.6 0.09999999999985551\n",
      "397500 10.3 0.09999999999985551\n",
      "398000 12.6 0.09999999999985551\n",
      "398500 12.3 0.09999999999985551\n",
      "399000 9.6 0.09999999999985551\n",
      "399500 8.8 0.09999999999985551\n",
      "400000 12.0 0.09999999999985551\n",
      "Saved Model\n",
      "400500 10.4 0.09999999999985551\n",
      "401000 7.9 0.09999999999985551\n",
      "401500 12.8 0.09999999999985551\n",
      "402000 13.3 0.09999999999985551\n",
      "402500 10.5 0.09999999999985551\n",
      "403000 11.5 0.09999999999985551\n",
      "403500 8.5 0.09999999999985551\n",
      "404000 11.5 0.09999999999985551\n",
      "404500 6.9 0.09999999999985551\n",
      "405000 8.7 0.09999999999985551\n",
      "405500 10.9 0.09999999999985551\n",
      "406000 10.0 0.09999999999985551\n",
      "406500 9.6 0.09999999999985551\n",
      "407000 9.7 0.09999999999985551\n",
      "407500 9.4 0.09999999999985551\n",
      "408000 7.7 0.09999999999985551\n",
      "408500 7.4 0.09999999999985551\n",
      "409000 8.4 0.09999999999985551\n",
      "409500 10.4 0.09999999999985551\n",
      "410000 9.9 0.09999999999985551\n",
      "410500 8.1 0.09999999999985551\n",
      "411000 11.1 0.09999999999985551\n",
      "411500 7.2 0.09999999999985551\n",
      "412000 7.5 0.09999999999985551\n",
      "412500 11.7 0.09999999999985551\n",
      "413000 8.7 0.09999999999985551\n",
      "413500 8.9 0.09999999999985551\n",
      "414000 8.9 0.09999999999985551\n",
      "414500 10.6 0.09999999999985551\n",
      "415000 8.2 0.09999999999985551\n",
      "415500 8.6 0.09999999999985551\n",
      "416000 8.3 0.09999999999985551\n",
      "416500 10.1 0.09999999999985551\n",
      "417000 11.8 0.09999999999985551\n",
      "417500 11.3 0.09999999999985551\n",
      "418000 7.6 0.09999999999985551\n",
      "418500 11.1 0.09999999999985551\n",
      "419000 8.4 0.09999999999985551\n",
      "419500 11.1 0.09999999999985551\n",
      "420000 8.7 0.09999999999985551\n",
      "420500 9.0 0.09999999999985551\n",
      "421000 11.7 0.09999999999985551\n",
      "421500 7.9 0.09999999999985551\n",
      "422000 10.6 0.09999999999985551\n",
      "422500 8.2 0.09999999999985551\n",
      "423000 12.5 0.09999999999985551\n",
      "423500 9.1 0.09999999999985551\n",
      "424000 7.7 0.09999999999985551\n",
      "424500 8.2 0.09999999999985551\n",
      "425000 8.3 0.09999999999985551\n",
      "425500 8.7 0.09999999999985551\n",
      "426000 10.6 0.09999999999985551\n",
      "426500 11.4 0.09999999999985551\n",
      "427000 11.6 0.09999999999985551\n",
      "427500 9.4 0.09999999999985551\n",
      "428000 7.4 0.09999999999985551\n",
      "428500 10.5 0.09999999999985551\n",
      "429000 8.3 0.09999999999985551\n",
      "429500 10.1 0.09999999999985551\n",
      "430000 9.1 0.09999999999985551\n",
      "430500 9.7 0.09999999999985551\n",
      "431000 9.4 0.09999999999985551\n",
      "431500 6.6 0.09999999999985551\n",
      "432000 12.3 0.09999999999985551\n",
      "432500 8.8 0.09999999999985551\n",
      "433000 12.2 0.09999999999985551\n",
      "433500 12.1 0.09999999999985551\n",
      "434000 9.4 0.09999999999985551\n",
      "434500 11.9 0.09999999999985551\n",
      "435000 10.3 0.09999999999985551\n",
      "435500 9.9 0.09999999999985551\n",
      "436000 9.1 0.09999999999985551\n",
      "436500 8.3 0.09999999999985551\n",
      "437000 10.3 0.09999999999985551\n",
      "437500 10.0 0.09999999999985551\n",
      "438000 11.3 0.09999999999985551\n",
      "438500 10.0 0.09999999999985551\n",
      "439000 9.4 0.09999999999985551\n",
      "439500 10.3 0.09999999999985551\n",
      "440000 9.6 0.09999999999985551\n",
      "440500 10.2 0.09999999999985551\n",
      "441000 8.9 0.09999999999985551\n",
      "441500 12.3 0.09999999999985551\n",
      "442000 9.4 0.09999999999985551\n",
      "442500 9.6 0.09999999999985551\n",
      "443000 10.1 0.09999999999985551\n",
      "443500 7.9 0.09999999999985551\n",
      "444000 7.3 0.09999999999985551\n",
      "444500 8.3 0.09999999999985551\n",
      "445000 8.0 0.09999999999985551\n",
      "445500 12.2 0.09999999999985551\n",
      "446000 13.0 0.09999999999985551\n",
      "446500 9.1 0.09999999999985551\n",
      "447000 11.0 0.09999999999985551\n",
      "447500 11.4 0.09999999999985551\n",
      "448000 10.2 0.09999999999985551\n",
      "448500 8.9 0.09999999999985551\n",
      "449000 10.2 0.09999999999985551\n",
      "449500 11.4 0.09999999999985551\n",
      "450000 6.8 0.09999999999985551\n",
      "Saved Model\n",
      "450500 9.8 0.09999999999985551\n",
      "451000 12.2 0.09999999999985551\n",
      "451500 11.9 0.09999999999985551\n",
      "452000 11.6 0.09999999999985551\n",
      "452500 8.9 0.09999999999985551\n",
      "453000 10.8 0.09999999999985551\n",
      "453500 8.1 0.09999999999985551\n",
      "454000 9.8 0.09999999999985551\n",
      "454500 9.6 0.09999999999985551\n",
      "455000 12.2 0.09999999999985551\n",
      "455500 7.5 0.09999999999985551\n",
      "456000 11.5 0.09999999999985551\n",
      "456500 11.1 0.09999999999985551\n",
      "457000 12.3 0.09999999999985551\n",
      "457500 10.1 0.09999999999985551\n",
      "458000 10.0 0.09999999999985551\n",
      "458500 11.5 0.09999999999985551\n",
      "459000 10.8 0.09999999999985551\n",
      "459500 9.0 0.09999999999985551\n",
      "460000 10.3 0.09999999999985551\n",
      "460500 11.1 0.09999999999985551\n",
      "461000 9.6 0.09999999999985551\n",
      "461500 10.0 0.09999999999985551\n",
      "462000 9.5 0.09999999999985551\n",
      "462500 11.4 0.09999999999985551\n",
      "463000 10.6 0.09999999999985551\n",
      "463500 10.0 0.09999999999985551\n",
      "464000 8.5 0.09999999999985551\n",
      "464500 10.5 0.09999999999985551\n",
      "465000 10.0 0.09999999999985551\n",
      "465500 10.1 0.09999999999985551\n",
      "466000 12.7 0.09999999999985551\n",
      "466500 9.1 0.09999999999985551\n",
      "467000 8.8 0.09999999999985551\n",
      "467500 10.4 0.09999999999985551\n",
      "468000 11.6 0.09999999999985551\n",
      "468500 10.4 0.09999999999985551\n",
      "469000 10.4 0.09999999999985551\n",
      "469500 12.0 0.09999999999985551\n",
      "470000 10.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470500 12.2 0.09999999999985551\n",
      "471000 8.7 0.09999999999985551\n",
      "471500 12.0 0.09999999999985551\n",
      "472000 11.7 0.09999999999985551\n",
      "472500 11.0 0.09999999999985551\n",
      "473000 11.5 0.09999999999985551\n",
      "473500 10.2 0.09999999999985551\n",
      "474000 7.6 0.09999999999985551\n",
      "474500 8.8 0.09999999999985551\n",
      "475000 11.6 0.09999999999985551\n",
      "475500 10.9 0.09999999999985551\n",
      "476000 10.3 0.09999999999985551\n",
      "476500 12.0 0.09999999999985551\n",
      "477000 10.6 0.09999999999985551\n",
      "477500 8.5 0.09999999999985551\n",
      "478000 9.5 0.09999999999985551\n",
      "478500 9.4 0.09999999999985551\n",
      "479000 8.8 0.09999999999985551\n",
      "479500 9.3 0.09999999999985551\n",
      "480000 10.9 0.09999999999985551\n",
      "480500 10.1 0.09999999999985551\n",
      "481000 13.0 0.09999999999985551\n",
      "481500 10.8 0.09999999999985551\n",
      "482000 10.6 0.09999999999985551\n",
      "482500 11.0 0.09999999999985551\n",
      "483000 10.9 0.09999999999985551\n",
      "483500 9.7 0.09999999999985551\n",
      "484000 11.0 0.09999999999985551\n",
      "484500 10.8 0.09999999999985551\n",
      "485000 11.1 0.09999999999985551\n",
      "485500 11.4 0.09999999999985551\n",
      "486000 8.1 0.09999999999985551\n",
      "486500 9.1 0.09999999999985551\n",
      "487000 10.1 0.09999999999985551\n",
      "487500 11.3 0.09999999999985551\n",
      "488000 10.7 0.09999999999985551\n",
      "488500 9.5 0.09999999999985551\n",
      "489000 9.6 0.09999999999985551\n",
      "489500 9.7 0.09999999999985551\n",
      "490000 9.6 0.09999999999985551\n",
      "490500 8.0 0.09999999999985551\n",
      "491000 10.6 0.09999999999985551\n",
      "491500 8.2 0.09999999999985551\n",
      "492000 7.2 0.09999999999985551\n",
      "492500 11.7 0.09999999999985551\n",
      "493000 8.1 0.09999999999985551\n",
      "493500 9.8 0.09999999999985551\n",
      "494000 10.2 0.09999999999985551\n",
      "494500 10.2 0.09999999999985551\n",
      "495000 11.3 0.09999999999985551\n",
      "495500 12.1 0.09999999999985551\n",
      "496000 8.0 0.09999999999985551\n",
      "496500 10.8 0.09999999999985551\n",
      "497000 11.5 0.09999999999985551\n",
      "497500 11.7 0.09999999999985551\n",
      "498000 10.3 0.09999999999985551\n",
      "498500 9.7 0.09999999999985551\n",
      "499000 10.2 0.09999999999985551\n",
      "499500 9.9 0.09999999999985551\n",
      "500000 9.5 0.09999999999985551\n",
      "Percent of succesful episodes: 7.3404%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rList_gaussian = rList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random íê²½ ìì\n",
    "from gridworld_random import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./DQN_random\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75EB7F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75EB7F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75EB7F0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75EB7F0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75FF390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FFB00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FFB00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FFB00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FFB00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FF1D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FF1D0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FF1D0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C75FF1D0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C76656D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C76656D8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C76656D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C76656D8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C755EC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C755EC18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C755EC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C755EC18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3AC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C75B3AC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C761C908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C761C908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C761C908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x00000241C761C908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x00000241C761C710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 -1.7 1\n",
      "1000 0.1 1\n",
      "1500 0.3 1\n",
      "2000 -0.5 1\n",
      "2500 -0.5 1\n",
      "3000 0.4 1\n",
      "3500 0.0 1\n",
      "4000 -0.2 1\n",
      "4500 -0.5 1\n",
      "5000 0.9 1\n",
      "5500 0.3 1\n",
      "6000 1.5 1\n",
      "6500 -0.5 1\n",
      "7000 0.7 1\n",
      "7500 1.6 1\n",
      "8000 0.6 1\n",
      "8500 0.4 1\n",
      "9000 0.8 1\n",
      "9500 0.0 1\n",
      "10000 1.2 1\n",
      "10500 -0.9 0.9549999999999828\n",
      "11000 0.6 0.9099999999999655\n",
      "11500 0.4 0.8649999999999483\n",
      "12000 -1.2 0.819999999999931\n",
      "12500 0.4 0.7749999999999138\n",
      "13000 0.1 0.7299999999998965\n",
      "13500 0.7 0.6849999999998793\n",
      "14000 -0.6 0.639999999999862\n",
      "14500 0.7 0.5949999999998448\n",
      "15000 0.3 0.5499999999998275\n",
      "15500 0.7 0.5049999999998103\n",
      "16000 -0.3 0.4599999999998177\n",
      "16500 0.4 0.41499999999982823\n",
      "17000 0.2 0.36999999999983874\n",
      "17500 -0.7 0.32499999999984924\n",
      "18000 0.0 0.27999999999985975\n",
      "18500 -0.1 0.23499999999986562\n",
      "19000 0.8 0.18999999999986225\n",
      "19500 0.0 0.14499999999985888\n",
      "20000 0.9 0.09999999999985551\n",
      "20500 0.2 0.09999999999985551\n",
      "21000 0.4 0.09999999999985551\n",
      "21500 -0.1 0.09999999999985551\n",
      "22000 0.3 0.09999999999985551\n",
      "22500 0.3 0.09999999999985551\n",
      "23000 0.7 0.09999999999985551\n",
      "23500 0.1 0.09999999999985551\n",
      "24000 0.5 0.09999999999985551\n",
      "24500 0.4 0.09999999999985551\n",
      "25000 0.4 0.09999999999985551\n",
      "25500 0.5 0.09999999999985551\n",
      "26000 -0.1 0.09999999999985551\n",
      "26500 -0.2 0.09999999999985551\n",
      "27000 0.0 0.09999999999985551\n",
      "27500 1.1 0.09999999999985551\n",
      "28000 1.0 0.09999999999985551\n",
      "28500 0.4 0.09999999999985551\n",
      "29000 -0.6 0.09999999999985551\n",
      "29500 0.0 0.09999999999985551\n",
      "30000 0.1 0.09999999999985551\n",
      "30500 0.6 0.09999999999985551\n",
      "31000 1.1 0.09999999999985551\n",
      "31500 -0.2 0.09999999999985551\n",
      "32000 0.4 0.09999999999985551\n",
      "32500 -0.4 0.09999999999985551\n",
      "33000 0.1 0.09999999999985551\n",
      "33500 0.4 0.09999999999985551\n",
      "34000 -0.4 0.09999999999985551\n",
      "34500 0.8 0.09999999999985551\n",
      "35000 0.6 0.09999999999985551\n",
      "35500 -0.1 0.09999999999985551\n",
      "36000 0.0 0.09999999999985551\n",
      "36500 0.0 0.09999999999985551\n",
      "37000 0.1 0.09999999999985551\n",
      "37500 0.7 0.09999999999985551\n",
      "38000 -0.4 0.09999999999985551\n",
      "38500 0.0 0.09999999999985551\n",
      "39000 0.3 0.09999999999985551\n",
      "39500 1.1 0.09999999999985551\n",
      "40000 0.8 0.09999999999985551\n",
      "40500 1.2 0.09999999999985551\n",
      "41000 0.9 0.09999999999985551\n",
      "41500 0.0 0.09999999999985551\n",
      "42000 0.4 0.09999999999985551\n",
      "42500 1.0 0.09999999999985551\n",
      "43000 -0.1 0.09999999999985551\n",
      "43500 0.4 0.09999999999985551\n",
      "44000 0.9 0.09999999999985551\n",
      "44500 1.4 0.09999999999985551\n",
      "45000 0.8 0.09999999999985551\n",
      "45500 1.6 0.09999999999985551\n",
      "46000 0.8 0.09999999999985551\n",
      "46500 1.6 0.09999999999985551\n",
      "47000 1.6 0.09999999999985551\n",
      "47500 -0.1 0.09999999999985551\n",
      "48000 0.7 0.09999999999985551\n",
      "48500 0.4 0.09999999999985551\n",
      "49000 1.6 0.09999999999985551\n",
      "49500 0.8 0.09999999999985551\n",
      "50000 0.6 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.8 0.09999999999985551\n",
      "51000 1.6 0.09999999999985551\n",
      "51500 1.1 0.09999999999985551\n",
      "52000 1.7 0.09999999999985551\n",
      "52500 0.6 0.09999999999985551\n",
      "53000 1.0 0.09999999999985551\n",
      "53500 1.3 0.09999999999985551\n",
      "54000 2.1 0.09999999999985551\n",
      "54500 2.5 0.09999999999985551\n",
      "55000 2.0 0.09999999999985551\n",
      "55500 1.1 0.09999999999985551\n",
      "56000 1.4 0.09999999999985551\n",
      "56500 0.3 0.09999999999985551\n",
      "57000 1.0 0.09999999999985551\n",
      "57500 2.4 0.09999999999985551\n",
      "58000 2.2 0.09999999999985551\n",
      "58500 1.8 0.09999999999985551\n",
      "59000 1.2 0.09999999999985551\n",
      "59500 2.2 0.09999999999985551\n",
      "60000 1.5 0.09999999999985551\n",
      "60500 2.7 0.09999999999985551\n",
      "61000 2.0 0.09999999999985551\n",
      "61500 1.0 0.09999999999985551\n",
      "62000 1.3 0.09999999999985551\n",
      "62500 2.1 0.09999999999985551\n",
      "63000 2.9 0.09999999999985551\n",
      "63500 2.0 0.09999999999985551\n",
      "64000 2.9 0.09999999999985551\n",
      "64500 1.6 0.09999999999985551\n",
      "65000 0.6 0.09999999999985551\n",
      "65500 1.1 0.09999999999985551\n",
      "66000 1.5 0.09999999999985551\n",
      "66500 2.0 0.09999999999985551\n",
      "67000 3.0 0.09999999999985551\n",
      "67500 2.4 0.09999999999985551\n",
      "68000 2.4 0.09999999999985551\n",
      "68500 3.6 0.09999999999985551\n",
      "69000 2.4 0.09999999999985551\n",
      "69500 3.8 0.09999999999985551\n",
      "70000 1.4 0.09999999999985551\n",
      "70500 3.1 0.09999999999985551\n",
      "71000 2.2 0.09999999999985551\n",
      "71500 4.5 0.09999999999985551\n",
      "72000 4.2 0.09999999999985551\n",
      "72500 1.1 0.09999999999985551\n",
      "73000 3.8 0.09999999999985551\n",
      "73500 3.6 0.09999999999985551\n",
      "74000 4.6 0.09999999999985551\n",
      "74500 4.3 0.09999999999985551\n",
      "75000 2.4 0.09999999999985551\n",
      "75500 2.8 0.09999999999985551\n",
      "76000 3.5 0.09999999999985551\n",
      "76500 4.6 0.09999999999985551\n",
      "77000 4.6 0.09999999999985551\n",
      "77500 4.4 0.09999999999985551\n",
      "78000 4.7 0.09999999999985551\n",
      "78500 4.7 0.09999999999985551\n",
      "79000 4.3 0.09999999999985551\n",
      "79500 4.7 0.09999999999985551\n",
      "80000 4.0 0.09999999999985551\n",
      "80500 4.8 0.09999999999985551\n",
      "81000 6.5 0.09999999999985551\n",
      "81500 4.2 0.09999999999985551\n",
      "82000 4.2 0.09999999999985551\n",
      "82500 4.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83000 4.1 0.09999999999985551\n",
      "83500 5.7 0.09999999999985551\n",
      "84000 4.6 0.09999999999985551\n",
      "84500 4.9 0.09999999999985551\n",
      "85000 4.4 0.09999999999985551\n",
      "85500 4.1 0.09999999999985551\n",
      "86000 4.9 0.09999999999985551\n",
      "86500 6.8 0.09999999999985551\n",
      "87000 7.9 0.09999999999985551\n",
      "87500 5.7 0.09999999999985551\n",
      "88000 7.3 0.09999999999985551\n",
      "88500 8.8 0.09999999999985551\n",
      "89000 3.5 0.09999999999985551\n",
      "89500 8.0 0.09999999999985551\n",
      "90000 7.0 0.09999999999985551\n",
      "90500 7.1 0.09999999999985551\n",
      "91000 6.9 0.09999999999985551\n",
      "91500 8.2 0.09999999999985551\n",
      "92000 7.1 0.09999999999985551\n",
      "92500 6.5 0.09999999999985551\n",
      "93000 6.0 0.09999999999985551\n",
      "93500 4.8 0.09999999999985551\n",
      "94000 3.8 0.09999999999985551\n",
      "94500 9.4 0.09999999999985551\n",
      "95000 5.4 0.09999999999985551\n",
      "95500 7.7 0.09999999999985551\n",
      "96000 8.3 0.09999999999985551\n",
      "96500 8.2 0.09999999999985551\n",
      "97000 6.4 0.09999999999985551\n",
      "97500 7.6 0.09999999999985551\n",
      "98000 6.4 0.09999999999985551\n",
      "98500 8.9 0.09999999999985551\n",
      "99000 5.1 0.09999999999985551\n",
      "99500 11.7 0.09999999999985551\n",
      "100000 8.7 0.09999999999985551\n",
      "Saved Model\n",
      "100500 11.5 0.09999999999985551\n",
      "101000 6.3 0.09999999999985551\n",
      "101500 6.2 0.09999999999985551\n",
      "102000 5.1 0.09999999999985551\n",
      "102500 7.2 0.09999999999985551\n",
      "103000 8.3 0.09999999999985551\n",
      "103500 7.9 0.09999999999985551\n",
      "104000 7.1 0.09999999999985551\n",
      "104500 9.9 0.09999999999985551\n",
      "105000 7.8 0.09999999999985551\n",
      "105500 9.1 0.09999999999985551\n",
      "106000 7.9 0.09999999999985551\n",
      "106500 9.0 0.09999999999985551\n",
      "107000 7.6 0.09999999999985551\n",
      "107500 8.4 0.09999999999985551\n",
      "108000 8.3 0.09999999999985551\n",
      "108500 5.0 0.09999999999985551\n",
      "109000 9.2 0.09999999999985551\n",
      "109500 8.8 0.09999999999985551\n",
      "110000 8.3 0.09999999999985551\n",
      "110500 6.6 0.09999999999985551\n",
      "111000 8.3 0.09999999999985551\n",
      "111500 8.5 0.09999999999985551\n",
      "112000 8.5 0.09999999999985551\n",
      "112500 7.4 0.09999999999985551\n",
      "113000 8.1 0.09999999999985551\n",
      "113500 10.6 0.09999999999985551\n",
      "114000 10.0 0.09999999999985551\n",
      "114500 8.4 0.09999999999985551\n",
      "115000 10.0 0.09999999999985551\n",
      "115500 9.5 0.09999999999985551\n",
      "116000 8.9 0.09999999999985551\n",
      "116500 8.0 0.09999999999985551\n",
      "117000 11.7 0.09999999999985551\n",
      "117500 7.5 0.09999999999985551\n",
      "118000 7.0 0.09999999999985551\n",
      "118500 6.1 0.09999999999985551\n",
      "119000 8.5 0.09999999999985551\n",
      "119500 7.8 0.09999999999985551\n",
      "120000 5.9 0.09999999999985551\n",
      "120500 9.9 0.09999999999985551\n",
      "121000 7.2 0.09999999999985551\n",
      "121500 7.7 0.09999999999985551\n",
      "122000 12.1 0.09999999999985551\n",
      "122500 7.3 0.09999999999985551\n",
      "123000 10.2 0.09999999999985551\n",
      "123500 6.2 0.09999999999985551\n",
      "124000 12.5 0.09999999999985551\n",
      "124500 9.4 0.09999999999985551\n",
      "125000 7.7 0.09999999999985551\n",
      "125500 10.5 0.09999999999985551\n",
      "126000 7.3 0.09999999999985551\n",
      "126500 9.1 0.09999999999985551\n",
      "127000 9.5 0.09999999999985551\n",
      "127500 10.3 0.09999999999985551\n",
      "128000 7.6 0.09999999999985551\n",
      "128500 8.8 0.09999999999985551\n",
      "129000 9.2 0.09999999999985551\n",
      "129500 10.1 0.09999999999985551\n",
      "130000 9.6 0.09999999999985551\n",
      "130500 9.4 0.09999999999985551\n",
      "131000 7.4 0.09999999999985551\n",
      "131500 8.2 0.09999999999985551\n",
      "132000 8.9 0.09999999999985551\n",
      "132500 8.0 0.09999999999985551\n",
      "133000 11.1 0.09999999999985551\n",
      "133500 8.2 0.09999999999985551\n",
      "134000 10.1 0.09999999999985551\n",
      "134500 6.8 0.09999999999985551\n",
      "135000 12.0 0.09999999999985551\n",
      "135500 11.3 0.09999999999985551\n",
      "136000 8.6 0.09999999999985551\n",
      "136500 10.2 0.09999999999985551\n",
      "137000 9.1 0.09999999999985551\n",
      "137500 6.4 0.09999999999985551\n",
      "138000 6.9 0.09999999999985551\n",
      "138500 9.6 0.09999999999985551\n",
      "139000 8.1 0.09999999999985551\n",
      "139500 10.2 0.09999999999985551\n",
      "140000 7.6 0.09999999999985551\n",
      "140500 9.9 0.09999999999985551\n",
      "141000 11.1 0.09999999999985551\n",
      "141500 8.9 0.09999999999985551\n",
      "142000 9.3 0.09999999999985551\n",
      "142500 7.0 0.09999999999985551\n",
      "143000 10.2 0.09999999999985551\n",
      "143500 11.0 0.09999999999985551\n",
      "144000 8.9 0.09999999999985551\n",
      "144500 7.6 0.09999999999985551\n",
      "145000 9.5 0.09999999999985551\n",
      "145500 11.2 0.09999999999985551\n",
      "146000 9.8 0.09999999999985551\n",
      "146500 12.4 0.09999999999985551\n",
      "147000 10.0 0.09999999999985551\n",
      "147500 8.5 0.09999999999985551\n",
      "148000 11.1 0.09999999999985551\n",
      "148500 9.3 0.09999999999985551\n",
      "149000 9.5 0.09999999999985551\n",
      "149500 7.7 0.09999999999985551\n",
      "150000 10.5 0.09999999999985551\n",
      "Saved Model\n",
      "150500 12.9 0.09999999999985551\n",
      "151000 10.4 0.09999999999985551\n",
      "151500 11.2 0.09999999999985551\n",
      "152000 9.8 0.09999999999985551\n",
      "152500 8.3 0.09999999999985551\n",
      "153000 11.4 0.09999999999985551\n",
      "153500 11.8 0.09999999999985551\n",
      "154000 10.9 0.09999999999985551\n",
      "154500 10.4 0.09999999999985551\n",
      "155000 10.3 0.09999999999985551\n",
      "155500 9.3 0.09999999999985551\n",
      "156000 10.4 0.09999999999985551\n",
      "156500 7.7 0.09999999999985551\n",
      "157000 9.1 0.09999999999985551\n",
      "157500 10.9 0.09999999999985551\n",
      "158000 9.1 0.09999999999985551\n",
      "158500 10.5 0.09999999999985551\n",
      "159000 8.7 0.09999999999985551\n",
      "159500 12.0 0.09999999999985551\n",
      "160000 8.7 0.09999999999985551\n",
      "160500 9.6 0.09999999999985551\n",
      "161000 8.4 0.09999999999985551\n",
      "161500 8.0 0.09999999999985551\n",
      "162000 8.6 0.09999999999985551\n",
      "162500 11.3 0.09999999999985551\n",
      "163000 7.7 0.09999999999985551\n",
      "163500 11.8 0.09999999999985551\n",
      "164000 11.9 0.09999999999985551\n",
      "164500 11.4 0.09999999999985551\n",
      "165000 10.5 0.09999999999985551\n",
      "165500 7.7 0.09999999999985551\n",
      "166000 12.7 0.09999999999985551\n",
      "166500 14.4 0.09999999999985551\n",
      "167000 9.9 0.09999999999985551\n",
      "167500 10.7 0.09999999999985551\n",
      "168000 10.9 0.09999999999985551\n",
      "168500 9.7 0.09999999999985551\n",
      "169000 11.7 0.09999999999985551\n",
      "169500 10.1 0.09999999999985551\n",
      "170000 6.7 0.09999999999985551\n",
      "170500 8.1 0.09999999999985551\n",
      "171000 11.8 0.09999999999985551\n",
      "171500 11.3 0.09999999999985551\n",
      "172000 5.3 0.09999999999985551\n",
      "172500 12.4 0.09999999999985551\n",
      "173000 12.1 0.09999999999985551\n",
      "173500 7.9 0.09999999999985551\n",
      "174000 13.0 0.09999999999985551\n",
      "174500 10.6 0.09999999999985551\n",
      "175000 10.2 0.09999999999985551\n",
      "175500 13.7 0.09999999999985551\n",
      "176000 11.7 0.09999999999985551\n",
      "176500 9.6 0.09999999999985551\n",
      "177000 11.2 0.09999999999985551\n",
      "177500 9.1 0.09999999999985551\n",
      "178000 9.5 0.09999999999985551\n",
      "178500 9.4 0.09999999999985551\n",
      "179000 9.1 0.09999999999985551\n",
      "179500 10.5 0.09999999999985551\n",
      "180000 9.8 0.09999999999985551\n",
      "180500 12.1 0.09999999999985551\n",
      "181000 10.3 0.09999999999985551\n",
      "181500 11.8 0.09999999999985551\n",
      "182000 9.2 0.09999999999985551\n",
      "182500 10.1 0.09999999999985551\n",
      "183000 9.0 0.09999999999985551\n",
      "183500 8.6 0.09999999999985551\n",
      "184000 8.6 0.09999999999985551\n",
      "184500 9.2 0.09999999999985551\n",
      "185000 7.7 0.09999999999985551\n",
      "185500 14.1 0.09999999999985551\n",
      "186000 9.1 0.09999999999985551\n",
      "186500 12.1 0.09999999999985551\n",
      "187000 12.6 0.09999999999985551\n",
      "187500 13.3 0.09999999999985551\n",
      "188000 10.4 0.09999999999985551\n",
      "188500 11.9 0.09999999999985551\n",
      "189000 10.8 0.09999999999985551\n",
      "189500 10.6 0.09999999999985551\n",
      "190000 11.4 0.09999999999985551\n",
      "190500 10.2 0.09999999999985551\n",
      "191000 12.1 0.09999999999985551\n",
      "191500 12.3 0.09999999999985551\n",
      "192000 9.5 0.09999999999985551\n",
      "192500 10.2 0.09999999999985551\n",
      "193000 12.1 0.09999999999985551\n",
      "193500 10.9 0.09999999999985551\n",
      "194000 12.5 0.09999999999985551\n",
      "194500 8.8 0.09999999999985551\n",
      "195000 9.8 0.09999999999985551\n",
      "195500 9.8 0.09999999999985551\n",
      "196000 9.8 0.09999999999985551\n",
      "196500 10.9 0.09999999999985551\n",
      "197000 10.4 0.09999999999985551\n",
      "197500 7.9 0.09999999999985551\n",
      "198000 14.0 0.09999999999985551\n",
      "198500 11.4 0.09999999999985551\n",
      "199000 11.8 0.09999999999985551\n",
      "199500 10.1 0.09999999999985551\n",
      "200000 10.2 0.09999999999985551\n",
      "Saved Model\n",
      "200500 10.4 0.09999999999985551\n",
      "201000 9.9 0.09999999999985551\n",
      "201500 10.9 0.09999999999985551\n",
      "202000 10.3 0.09999999999985551\n",
      "202500 8.3 0.09999999999985551\n",
      "203000 10.3 0.09999999999985551\n",
      "203500 12.4 0.09999999999985551\n",
      "204000 11.6 0.09999999999985551\n",
      "204500 5.8 0.09999999999985551\n",
      "205000 10.4 0.09999999999985551\n",
      "205500 9.4 0.09999999999985551\n",
      "206000 9.8 0.09999999999985551\n",
      "206500 8.5 0.09999999999985551\n",
      "207000 8.5 0.09999999999985551\n",
      "207500 9.8 0.09999999999985551\n",
      "208000 12.9 0.09999999999985551\n",
      "208500 7.9 0.09999999999985551\n",
      "209000 8.0 0.09999999999985551\n",
      "209500 11.9 0.09999999999985551\n",
      "210000 11.2 0.09999999999985551\n",
      "210500 11.5 0.09999999999985551\n",
      "211000 12.7 0.09999999999985551\n",
      "211500 10.8 0.09999999999985551\n",
      "212000 13.3 0.09999999999985551\n",
      "212500 11.0 0.09999999999985551\n",
      "213000 9.8 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213500 12.6 0.09999999999985551\n",
      "214000 11.0 0.09999999999985551\n",
      "214500 12.7 0.09999999999985551\n",
      "215000 8.7 0.09999999999985551\n",
      "215500 10.4 0.09999999999985551\n",
      "216000 7.1 0.09999999999985551\n",
      "216500 10.2 0.09999999999985551\n",
      "217000 9.0 0.09999999999985551\n",
      "217500 8.9 0.09999999999985551\n",
      "218000 11.3 0.09999999999985551\n",
      "218500 8.7 0.09999999999985551\n",
      "219000 9.7 0.09999999999985551\n",
      "219500 11.1 0.09999999999985551\n",
      "220000 12.9 0.09999999999985551\n",
      "220500 12.2 0.09999999999985551\n",
      "221000 8.7 0.09999999999985551\n",
      "221500 11.3 0.09999999999985551\n",
      "222000 9.3 0.09999999999985551\n",
      "222500 11.4 0.09999999999985551\n",
      "223000 8.4 0.09999999999985551\n",
      "223500 8.6 0.09999999999985551\n",
      "224000 6.7 0.09999999999985551\n",
      "224500 9.1 0.09999999999985551\n",
      "225000 10.2 0.09999999999985551\n",
      "225500 11.8 0.09999999999985551\n",
      "226000 10.1 0.09999999999985551\n",
      "226500 12.0 0.09999999999985551\n",
      "227000 7.5 0.09999999999985551\n",
      "227500 12.7 0.09999999999985551\n",
      "228000 10.8 0.09999999999985551\n",
      "228500 9.8 0.09999999999985551\n",
      "229000 11.5 0.09999999999985551\n",
      "229500 12.0 0.09999999999985551\n",
      "230000 9.5 0.09999999999985551\n",
      "230500 9.8 0.09999999999985551\n",
      "231000 10.4 0.09999999999985551\n",
      "231500 8.8 0.09999999999985551\n",
      "232000 12.1 0.09999999999985551\n",
      "232500 9.6 0.09999999999985551\n",
      "233000 8.7 0.09999999999985551\n",
      "233500 7.0 0.09999999999985551\n",
      "234000 13.6 0.09999999999985551\n",
      "234500 9.9 0.09999999999985551\n",
      "235000 8.3 0.09999999999985551\n",
      "235500 10.1 0.09999999999985551\n",
      "236000 10.0 0.09999999999985551\n",
      "236500 13.7 0.09999999999985551\n",
      "237000 10.5 0.09999999999985551\n",
      "237500 10.4 0.09999999999985551\n",
      "238000 7.9 0.09999999999985551\n",
      "238500 11.5 0.09999999999985551\n",
      "239000 12.6 0.09999999999985551\n",
      "239500 12.9 0.09999999999985551\n",
      "240000 9.5 0.09999999999985551\n",
      "240500 13.6 0.09999999999985551\n",
      "241000 12.4 0.09999999999985551\n",
      "241500 14.7 0.09999999999985551\n",
      "242000 10.6 0.09999999999985551\n",
      "242500 11.7 0.09999999999985551\n",
      "243000 10.6 0.09999999999985551\n",
      "243500 12.5 0.09999999999985551\n",
      "244000 11.2 0.09999999999985551\n",
      "244500 11.6 0.09999999999985551\n",
      "245000 9.1 0.09999999999985551\n",
      "245500 12.4 0.09999999999985551\n",
      "246000 9.7 0.09999999999985551\n",
      "246500 9.2 0.09999999999985551\n",
      "247000 9.1 0.09999999999985551\n",
      "247500 16.2 0.09999999999985551\n",
      "248000 10.9 0.09999999999985551\n",
      "248500 9.2 0.09999999999985551\n",
      "249000 12.4 0.09999999999985551\n",
      "249500 6.5 0.09999999999985551\n",
      "250000 10.5 0.09999999999985551\n",
      "Saved Model\n",
      "250500 13.2 0.09999999999985551\n",
      "251000 12.0 0.09999999999985551\n",
      "251500 7.1 0.09999999999985551\n",
      "252000 11.1 0.09999999999985551\n",
      "252500 12.4 0.09999999999985551\n",
      "253000 11.9 0.09999999999985551\n",
      "253500 12.2 0.09999999999985551\n",
      "254000 10.6 0.09999999999985551\n",
      "254500 12.8 0.09999999999985551\n",
      "255000 11.4 0.09999999999985551\n",
      "255500 13.8 0.09999999999985551\n",
      "256000 12.1 0.09999999999985551\n",
      "256500 7.7 0.09999999999985551\n",
      "257000 10.9 0.09999999999985551\n",
      "257500 10.0 0.09999999999985551\n",
      "258000 11.8 0.09999999999985551\n",
      "258500 10.8 0.09999999999985551\n",
      "259000 12.6 0.09999999999985551\n",
      "259500 13.4 0.09999999999985551\n",
      "260000 11.8 0.09999999999985551\n",
      "260500 8.7 0.09999999999985551\n",
      "261000 9.7 0.09999999999985551\n",
      "261500 12.7 0.09999999999985551\n",
      "262000 12.5 0.09999999999985551\n",
      "262500 13.2 0.09999999999985551\n",
      "263000 8.7 0.09999999999985551\n",
      "263500 12.7 0.09999999999985551\n",
      "264000 10.5 0.09999999999985551\n",
      "264500 6.7 0.09999999999985551\n",
      "265000 10.3 0.09999999999985551\n",
      "265500 12.8 0.09999999999985551\n",
      "266000 10.9 0.09999999999985551\n",
      "266500 9.5 0.09999999999985551\n",
      "267000 13.4 0.09999999999985551\n",
      "267500 10.9 0.09999999999985551\n",
      "268000 10.0 0.09999999999985551\n",
      "268500 9.2 0.09999999999985551\n",
      "269000 9.5 0.09999999999985551\n",
      "269500 13.0 0.09999999999985551\n",
      "270000 12.0 0.09999999999985551\n",
      "270500 11.2 0.09999999999985551\n",
      "271000 11.5 0.09999999999985551\n",
      "271500 10.2 0.09999999999985551\n",
      "272000 8.8 0.09999999999985551\n",
      "272500 11.4 0.09999999999985551\n",
      "273000 13.2 0.09999999999985551\n",
      "273500 12.5 0.09999999999985551\n",
      "274000 12.2 0.09999999999985551\n",
      "274500 9.7 0.09999999999985551\n",
      "275000 11.3 0.09999999999985551\n",
      "275500 10.8 0.09999999999985551\n",
      "276000 13.8 0.09999999999985551\n",
      "276500 8.8 0.09999999999985551\n",
      "277000 10.0 0.09999999999985551\n",
      "277500 13.2 0.09999999999985551\n",
      "278000 12.1 0.09999999999985551\n",
      "278500 13.5 0.09999999999985551\n",
      "279000 8.9 0.09999999999985551\n",
      "279500 10.6 0.09999999999985551\n",
      "280000 9.5 0.09999999999985551\n",
      "280500 8.7 0.09999999999985551\n",
      "281000 8.4 0.09999999999985551\n",
      "281500 9.4 0.09999999999985551\n",
      "282000 11.1 0.09999999999985551\n",
      "282500 12.9 0.09999999999985551\n",
      "283000 11.5 0.09999999999985551\n",
      "283500 9.1 0.09999999999985551\n",
      "284000 8.0 0.09999999999985551\n",
      "284500 8.9 0.09999999999985551\n",
      "285000 9.1 0.09999999999985551\n",
      "285500 11.1 0.09999999999985551\n",
      "286000 7.5 0.09999999999985551\n",
      "286500 11.4 0.09999999999985551\n",
      "287000 11.4 0.09999999999985551\n",
      "287500 11.3 0.09999999999985551\n",
      "288000 14.2 0.09999999999985551\n",
      "288500 9.2 0.09999999999985551\n",
      "289000 11.1 0.09999999999985551\n",
      "289500 10.2 0.09999999999985551\n",
      "290000 10.8 0.09999999999985551\n",
      "290500 14.0 0.09999999999985551\n",
      "291000 11.2 0.09999999999985551\n",
      "291500 7.8 0.09999999999985551\n",
      "292000 10.7 0.09999999999985551\n",
      "292500 8.6 0.09999999999985551\n",
      "293000 9.2 0.09999999999985551\n",
      "293500 9.4 0.09999999999985551\n",
      "294000 10.8 0.09999999999985551\n",
      "294500 11.9 0.09999999999985551\n",
      "295000 7.6 0.09999999999985551\n",
      "295500 13.5 0.09999999999985551\n",
      "296000 9.8 0.09999999999985551\n",
      "296500 8.4 0.09999999999985551\n",
      "297000 8.5 0.09999999999985551\n",
      "297500 13.2 0.09999999999985551\n",
      "298000 8.4 0.09999999999985551\n",
      "298500 14.1 0.09999999999985551\n",
      "299000 11.6 0.09999999999985551\n",
      "299500 12.8 0.09999999999985551\n",
      "300000 8.4 0.09999999999985551\n",
      "Saved Model\n",
      "300500 15.4 0.09999999999985551\n",
      "301000 11.1 0.09999999999985551\n",
      "301500 12.4 0.09999999999985551\n",
      "302000 9.5 0.09999999999985551\n",
      "302500 10.5 0.09999999999985551\n",
      "303000 13.1 0.09999999999985551\n",
      "303500 12.0 0.09999999999985551\n",
      "304000 12.5 0.09999999999985551\n",
      "304500 9.4 0.09999999999985551\n",
      "305000 8.3 0.09999999999985551\n",
      "305500 6.7 0.09999999999985551\n",
      "306000 12.7 0.09999999999985551\n",
      "306500 13.6 0.09999999999985551\n",
      "307000 12.6 0.09999999999985551\n",
      "307500 6.2 0.09999999999985551\n",
      "308000 10.1 0.09999999999985551\n",
      "308500 13.2 0.09999999999985551\n",
      "309000 11.5 0.09999999999985551\n",
      "309500 7.6 0.09999999999985551\n",
      "310000 9.1 0.09999999999985551\n",
      "310500 13.4 0.09999999999985551\n",
      "311000 13.6 0.09999999999985551\n",
      "311500 14.0 0.09999999999985551\n",
      "312000 12.2 0.09999999999985551\n",
      "312500 9.1 0.09999999999985551\n",
      "313000 8.3 0.09999999999985551\n",
      "313500 10.2 0.09999999999985551\n",
      "314000 13.8 0.09999999999985551\n",
      "314500 9.4 0.09999999999985551\n",
      "315000 11.5 0.09999999999985551\n",
      "315500 13.2 0.09999999999985551\n",
      "316000 13.2 0.09999999999985551\n",
      "316500 9.6 0.09999999999985551\n",
      "317000 9.0 0.09999999999985551\n",
      "317500 9.3 0.09999999999985551\n",
      "318000 9.2 0.09999999999985551\n",
      "318500 10.8 0.09999999999985551\n",
      "319000 10.2 0.09999999999985551\n",
      "319500 8.7 0.09999999999985551\n",
      "320000 11.5 0.09999999999985551\n",
      "320500 10.5 0.09999999999985551\n",
      "321000 11.9 0.09999999999985551\n",
      "321500 11.8 0.09999999999985551\n",
      "322000 11.2 0.09999999999985551\n",
      "322500 10.6 0.09999999999985551\n",
      "323000 9.7 0.09999999999985551\n",
      "323500 12.5 0.09999999999985551\n",
      "324000 9.7 0.09999999999985551\n",
      "324500 11.3 0.09999999999985551\n",
      "325000 9.8 0.09999999999985551\n",
      "325500 13.2 0.09999999999985551\n",
      "326000 13.9 0.09999999999985551\n",
      "326500 9.0 0.09999999999985551\n",
      "327000 13.0 0.09999999999985551\n",
      "327500 12.6 0.09999999999985551\n",
      "328000 12.9 0.09999999999985551\n",
      "328500 14.9 0.09999999999985551\n",
      "329000 10.0 0.09999999999985551\n",
      "329500 7.4 0.09999999999985551\n",
      "330000 13.4 0.09999999999985551\n",
      "330500 9.2 0.09999999999985551\n",
      "331000 13.7 0.09999999999985551\n",
      "331500 9.8 0.09999999999985551\n",
      "332000 10.7 0.09999999999985551\n",
      "332500 12.9 0.09999999999985551\n",
      "333000 11.5 0.09999999999985551\n",
      "333500 9.8 0.09999999999985551\n",
      "334000 9.7 0.09999999999985551\n",
      "334500 11.1 0.09999999999985551\n",
      "335000 9.4 0.09999999999985551\n",
      "335500 15.2 0.09999999999985551\n",
      "336000 13.1 0.09999999999985551\n",
      "336500 10.0 0.09999999999985551\n",
      "337000 10.5 0.09999999999985551\n",
      "337500 10.8 0.09999999999985551\n",
      "338000 11.9 0.09999999999985551\n",
      "338500 8.4 0.09999999999985551\n",
      "339000 14.4 0.09999999999985551\n",
      "339500 11.8 0.09999999999985551\n",
      "340000 9.6 0.09999999999985551\n",
      "340500 8.6 0.09999999999985551\n",
      "341000 11.7 0.09999999999985551\n",
      "341500 11.1 0.09999999999985551\n",
      "342000 9.9 0.09999999999985551\n",
      "342500 9.9 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343000 12.4 0.09999999999985551\n",
      "343500 10.6 0.09999999999985551\n",
      "344000 8.5 0.09999999999985551\n",
      "344500 10.2 0.09999999999985551\n",
      "345000 13.1 0.09999999999985551\n",
      "345500 11.1 0.09999999999985551\n",
      "346000 12.3 0.09999999999985551\n",
      "346500 8.4 0.09999999999985551\n",
      "347000 12.6 0.09999999999985551\n",
      "347500 12.3 0.09999999999985551\n",
      "348000 12.4 0.09999999999985551\n",
      "348500 9.8 0.09999999999985551\n",
      "349000 8.7 0.09999999999985551\n",
      "349500 12.2 0.09999999999985551\n",
      "350000 14.6 0.09999999999985551\n",
      "Saved Model\n",
      "350500 13.3 0.09999999999985551\n",
      "351000 9.4 0.09999999999985551\n",
      "351500 11.2 0.09999999999985551\n",
      "352000 8.6 0.09999999999985551\n",
      "352500 11.9 0.09999999999985551\n",
      "353000 12.1 0.09999999999985551\n",
      "353500 12.5 0.09999999999985551\n",
      "354000 8.3 0.09999999999985551\n",
      "354500 15.2 0.09999999999985551\n",
      "355000 10.0 0.09999999999985551\n",
      "355500 8.2 0.09999999999985551\n",
      "356000 10.9 0.09999999999985551\n",
      "356500 12.4 0.09999999999985551\n",
      "357000 10.4 0.09999999999985551\n",
      "357500 15.1 0.09999999999985551\n",
      "358000 11.0 0.09999999999985551\n",
      "358500 7.9 0.09999999999985551\n",
      "359000 10.2 0.09999999999985551\n",
      "359500 10.0 0.09999999999985551\n",
      "360000 11.3 0.09999999999985551\n",
      "360500 9.8 0.09999999999985551\n",
      "361000 15.5 0.09999999999985551\n",
      "361500 12.1 0.09999999999985551\n",
      "362000 14.2 0.09999999999985551\n",
      "362500 10.0 0.09999999999985551\n",
      "363000 12.8 0.09999999999985551\n",
      "363500 10.1 0.09999999999985551\n",
      "364000 8.9 0.09999999999985551\n",
      "364500 12.3 0.09999999999985551\n",
      "365000 9.6 0.09999999999985551\n",
      "365500 7.7 0.09999999999985551\n",
      "366000 8.2 0.09999999999985551\n",
      "366500 12.6 0.09999999999985551\n",
      "367000 10.6 0.09999999999985551\n",
      "367500 13.4 0.09999999999985551\n",
      "368000 9.2 0.09999999999985551\n",
      "368500 8.5 0.09999999999985551\n",
      "369000 11.1 0.09999999999985551\n",
      "369500 13.2 0.09999999999985551\n",
      "370000 11.6 0.09999999999985551\n",
      "370500 14.7 0.09999999999985551\n",
      "371000 12.6 0.09999999999985551\n",
      "371500 9.5 0.09999999999985551\n",
      "372000 12.3 0.09999999999985551\n",
      "372500 11.7 0.09999999999985551\n",
      "373000 12.0 0.09999999999985551\n",
      "373500 12.2 0.09999999999985551\n",
      "374000 11.9 0.09999999999985551\n",
      "374500 12.0 0.09999999999985551\n",
      "375000 12.1 0.09999999999985551\n",
      "375500 10.8 0.09999999999985551\n",
      "376000 13.0 0.09999999999985551\n",
      "376500 11.0 0.09999999999985551\n",
      "377000 11.0 0.09999999999985551\n",
      "377500 8.4 0.09999999999985551\n",
      "378000 12.2 0.09999999999985551\n",
      "378500 11.3 0.09999999999985551\n",
      "379000 9.9 0.09999999999985551\n",
      "379500 8.5 0.09999999999985551\n",
      "380000 9.2 0.09999999999985551\n",
      "380500 14.4 0.09999999999985551\n",
      "381000 12.5 0.09999999999985551\n",
      "381500 14.4 0.09999999999985551\n",
      "382000 11.7 0.09999999999985551\n",
      "382500 8.2 0.09999999999985551\n",
      "383000 12.1 0.09999999999985551\n",
      "383500 11.0 0.09999999999985551\n",
      "384000 10.3 0.09999999999985551\n",
      "384500 12.9 0.09999999999985551\n",
      "385000 12.4 0.09999999999985551\n",
      "385500 12.2 0.09999999999985551\n",
      "386000 9.0 0.09999999999985551\n",
      "386500 11.1 0.09999999999985551\n",
      "387000 11.2 0.09999999999985551\n",
      "387500 9.1 0.09999999999985551\n",
      "388000 12.9 0.09999999999985551\n",
      "388500 12.3 0.09999999999985551\n",
      "389000 8.3 0.09999999999985551\n",
      "389500 12.2 0.09999999999985551\n",
      "390000 13.8 0.09999999999985551\n",
      "390500 10.1 0.09999999999985551\n",
      "391000 10.3 0.09999999999985551\n",
      "391500 12.4 0.09999999999985551\n",
      "392000 10.9 0.09999999999985551\n",
      "392500 12.7 0.09999999999985551\n",
      "393000 13.1 0.09999999999985551\n",
      "393500 12.1 0.09999999999985551\n",
      "394000 10.6 0.09999999999985551\n",
      "394500 12.2 0.09999999999985551\n",
      "395000 12.1 0.09999999999985551\n",
      "395500 11.6 0.09999999999985551\n",
      "396000 8.9 0.09999999999985551\n",
      "396500 10.8 0.09999999999985551\n",
      "397000 12.1 0.09999999999985551\n",
      "397500 15.5 0.09999999999985551\n",
      "398000 11.2 0.09999999999985551\n",
      "398500 11.0 0.09999999999985551\n",
      "399000 13.5 0.09999999999985551\n",
      "399500 10.3 0.09999999999985551\n",
      "400000 11.6 0.09999999999985551\n",
      "Saved Model\n",
      "400500 10.7 0.09999999999985551\n",
      "401000 13.0 0.09999999999985551\n",
      "401500 12.5 0.09999999999985551\n",
      "402000 12.4 0.09999999999985551\n",
      "402500 10.0 0.09999999999985551\n",
      "403000 14.9 0.09999999999985551\n",
      "403500 12.1 0.09999999999985551\n",
      "404000 13.5 0.09999999999985551\n",
      "404500 11.7 0.09999999999985551\n",
      "405000 10.8 0.09999999999985551\n",
      "405500 11.8 0.09999999999985551\n",
      "406000 8.7 0.09999999999985551\n",
      "406500 9.1 0.09999999999985551\n",
      "407000 11.8 0.09999999999985551\n",
      "407500 15.2 0.09999999999985551\n",
      "408000 8.7 0.09999999999985551\n",
      "408500 10.6 0.09999999999985551\n",
      "409000 14.4 0.09999999999985551\n",
      "409500 12.1 0.09999999999985551\n",
      "410000 12.5 0.09999999999985551\n",
      "410500 12.2 0.09999999999985551\n",
      "411000 13.7 0.09999999999985551\n",
      "411500 9.4 0.09999999999985551\n",
      "412000 5.7 0.09999999999985551\n",
      "412500 15.6 0.09999999999985551\n",
      "413000 13.1 0.09999999999985551\n",
      "413500 11.4 0.09999999999985551\n",
      "414000 9.7 0.09999999999985551\n",
      "414500 13.3 0.09999999999985551\n",
      "415000 15.0 0.09999999999985551\n",
      "415500 11.4 0.09999999999985551\n",
      "416000 10.6 0.09999999999985551\n",
      "416500 12.8 0.09999999999985551\n",
      "417000 8.4 0.09999999999985551\n",
      "417500 13.5 0.09999999999985551\n",
      "418000 13.4 0.09999999999985551\n",
      "418500 10.8 0.09999999999985551\n",
      "419000 6.8 0.09999999999985551\n",
      "419500 13.5 0.09999999999985551\n",
      "420000 12.0 0.09999999999985551\n",
      "420500 13.5 0.09999999999985551\n",
      "421000 11.0 0.09999999999985551\n",
      "421500 11.6 0.09999999999985551\n",
      "422000 10.6 0.09999999999985551\n",
      "422500 11.4 0.09999999999985551\n",
      "423000 8.4 0.09999999999985551\n",
      "423500 11.0 0.09999999999985551\n",
      "424000 12.5 0.09999999999985551\n",
      "424500 8.5 0.09999999999985551\n",
      "425000 12.1 0.09999999999985551\n",
      "425500 13.0 0.09999999999985551\n",
      "426000 12.6 0.09999999999985551\n",
      "426500 10.6 0.09999999999985551\n",
      "427000 11.7 0.09999999999985551\n",
      "427500 14.8 0.09999999999985551\n",
      "428000 11.5 0.09999999999985551\n",
      "428500 11.1 0.09999999999985551\n",
      "429000 8.5 0.09999999999985551\n",
      "429500 13.1 0.09999999999985551\n",
      "430000 12.8 0.09999999999985551\n",
      "430500 11.9 0.09999999999985551\n",
      "431000 11.5 0.09999999999985551\n",
      "431500 13.3 0.09999999999985551\n",
      "432000 11.4 0.09999999999985551\n",
      "432500 12.2 0.09999999999985551\n",
      "433000 10.0 0.09999999999985551\n",
      "433500 9.8 0.09999999999985551\n",
      "434000 7.7 0.09999999999985551\n",
      "434500 12.4 0.09999999999985551\n",
      "435000 12.1 0.09999999999985551\n",
      "435500 15.1 0.09999999999985551\n",
      "436000 11.1 0.09999999999985551\n",
      "436500 14.8 0.09999999999985551\n",
      "437000 13.2 0.09999999999985551\n",
      "437500 13.4 0.09999999999985551\n",
      "438000 12.2 0.09999999999985551\n",
      "438500 10.4 0.09999999999985551\n",
      "439000 13.9 0.09999999999985551\n",
      "439500 12.8 0.09999999999985551\n",
      "440000 12.7 0.09999999999985551\n",
      "440500 13.2 0.09999999999985551\n",
      "441000 12.2 0.09999999999985551\n",
      "441500 9.4 0.09999999999985551\n",
      "442000 13.5 0.09999999999985551\n",
      "442500 9.3 0.09999999999985551\n",
      "443000 8.7 0.09999999999985551\n",
      "443500 9.5 0.09999999999985551\n",
      "444000 13.7 0.09999999999985551\n",
      "444500 9.0 0.09999999999985551\n",
      "445000 9.8 0.09999999999985551\n",
      "445500 11.0 0.09999999999985551\n",
      "446000 14.3 0.09999999999985551\n",
      "446500 10.8 0.09999999999985551\n",
      "447000 9.9 0.09999999999985551\n",
      "447500 10.7 0.09999999999985551\n",
      "448000 13.8 0.09999999999985551\n",
      "448500 8.3 0.09999999999985551\n",
      "449000 13.0 0.09999999999985551\n",
      "449500 11.4 0.09999999999985551\n",
      "450000 9.1 0.09999999999985551\n",
      "Saved Model\n",
      "450500 12.9 0.09999999999985551\n",
      "451000 9.7 0.09999999999985551\n",
      "451500 11.6 0.09999999999985551\n",
      "452000 11.7 0.09999999999985551\n",
      "452500 12.2 0.09999999999985551\n",
      "453000 11.2 0.09999999999985551\n",
      "453500 12.9 0.09999999999985551\n",
      "454000 13.4 0.09999999999985551\n",
      "454500 11.9 0.09999999999985551\n",
      "455000 12.1 0.09999999999985551\n",
      "455500 11.5 0.09999999999985551\n",
      "456000 14.4 0.09999999999985551\n",
      "456500 12.6 0.09999999999985551\n",
      "457000 9.8 0.09999999999985551\n",
      "457500 10.7 0.09999999999985551\n",
      "458000 11.9 0.09999999999985551\n",
      "458500 9.3 0.09999999999985551\n",
      "459000 15.8 0.09999999999985551\n",
      "459500 9.5 0.09999999999985551\n",
      "460000 12.4 0.09999999999985551\n",
      "460500 11.6 0.09999999999985551\n",
      "461000 9.3 0.09999999999985551\n",
      "461500 11.3 0.09999999999985551\n",
      "462000 13.9 0.09999999999985551\n",
      "462500 12.5 0.09999999999985551\n",
      "463000 14.5 0.09999999999985551\n",
      "463500 11.4 0.09999999999985551\n",
      "464000 13.8 0.09999999999985551\n",
      "464500 11.0 0.09999999999985551\n",
      "465000 10.7 0.09999999999985551\n",
      "465500 12.9 0.09999999999985551\n",
      "466000 11.6 0.09999999999985551\n",
      "466500 10.9 0.09999999999985551\n",
      "467000 12.8 0.09999999999985551\n",
      "467500 10.7 0.09999999999985551\n",
      "468000 15.8 0.09999999999985551\n",
      "468500 12.5 0.09999999999985551\n",
      "469000 9.1 0.09999999999985551\n",
      "469500 10.1 0.09999999999985551\n",
      "470000 11.2 0.09999999999985551\n",
      "470500 11.6 0.09999999999985551\n",
      "471000 11.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471500 9.8 0.09999999999985551\n",
      "472000 12.1 0.09999999999985551\n",
      "472500 10.6 0.09999999999985551\n",
      "473000 12.5 0.09999999999985551\n",
      "473500 13.3 0.09999999999985551\n",
      "474000 10.7 0.09999999999985551\n",
      "474500 12.1 0.09999999999985551\n",
      "475000 15.9 0.09999999999985551\n",
      "475500 11.5 0.09999999999985551\n",
      "476000 13.3 0.09999999999985551\n",
      "476500 13.9 0.09999999999985551\n",
      "477000 9.9 0.09999999999985551\n",
      "477500 12.0 0.09999999999985551\n",
      "478000 12.3 0.09999999999985551\n",
      "478500 11.4 0.09999999999985551\n",
      "479000 10.8 0.09999999999985551\n",
      "479500 15.1 0.09999999999985551\n",
      "480000 13.7 0.09999999999985551\n",
      "480500 13.2 0.09999999999985551\n",
      "481000 14.4 0.09999999999985551\n",
      "481500 10.5 0.09999999999985551\n",
      "482000 10.8 0.09999999999985551\n",
      "482500 14.1 0.09999999999985551\n",
      "483000 13.1 0.09999999999985551\n",
      "483500 12.4 0.09999999999985551\n",
      "484000 6.7 0.09999999999985551\n",
      "484500 12.9 0.09999999999985551\n",
      "485000 11.2 0.09999999999985551\n",
      "485500 6.5 0.09999999999985551\n",
      "486000 12.6 0.09999999999985551\n",
      "486500 11.0 0.09999999999985551\n",
      "487000 13.1 0.09999999999985551\n",
      "487500 11.6 0.09999999999985551\n",
      "488000 7.7 0.09999999999985551\n",
      "488500 12.3 0.09999999999985551\n",
      "489000 12.6 0.09999999999985551\n",
      "489500 13.3 0.09999999999985551\n",
      "490000 9.4 0.09999999999985551\n",
      "490500 13.9 0.09999999999985551\n",
      "491000 11.6 0.09999999999985551\n",
      "491500 10.9 0.09999999999985551\n",
      "492000 13.9 0.09999999999985551\n",
      "492500 16.1 0.09999999999985551\n",
      "493000 11.2 0.09999999999985551\n",
      "493500 11.9 0.09999999999985551\n",
      "494000 14.6 0.09999999999985551\n",
      "494500 9.5 0.09999999999985551\n",
      "495000 14.2 0.09999999999985551\n",
      "495500 8.9 0.09999999999985551\n",
      "496000 11.6 0.09999999999985551\n",
      "496500 11.1 0.09999999999985551\n",
      "497000 14.5 0.09999999999985551\n",
      "497500 13.5 0.09999999999985551\n",
      "498000 12.3 0.09999999999985551\n",
      "498500 10.9 0.09999999999985551\n",
      "499000 11.3 0.09999999999985551\n",
      "499500 10.6 0.09999999999985551\n",
      "500000 11.9 0.09999999999985551\n",
      "Percent of succesful episodes: 9.0906%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rList_random = rList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat_gaussian = np.resize(np.array(rList_gaussian),[len(rList_gaussian)//100,100])\n",
    "rMean_gaussian = np.average(rMat_gaussian,1)\n",
    "rMat_random = np.resize(np.array(rList_random),[len(rList_random)//100,100])\n",
    "rMean_random = np.average(rMat_random,1)\n",
    "\n",
    "#plt.plot(rMean_gaussian,'r', label = 'Gaussian')\n",
    "plt.plot(rMean_random,'b', label = 'Uniform')\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Reward')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "\n",
    "In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "\n",
    "For more reinforcment learning tutorials, see:\n",
    "https://github.com/awjuliani/DeepRL-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the game environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example of a starting environment in our simple game. The agent controls the blue square, and can move up, down, left, or right. The goal is to move to the green square (for +1 reward) and avoid the red square (for -1 reward). The position of the three blocks is randomized every episode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the network itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class allows us to store experies and sample then randomly to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple function to resize our game frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions allow us to update the parameters of our target network with those of the primary network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cdba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cdba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cdba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cdba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f3cd898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9eb72fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9eb72fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9eb72fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9eb72fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9eb05320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f8bbeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f8bbeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f8bbeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9f8bbeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e91ab00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e91ab00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e91ab00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e91ab00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fbe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f2a9e86fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2a9e86fcc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 0.8 1\n",
      "1000 1.9 1\n",
      "1500 3.0 1\n",
      "2000 2.3 1\n",
      "2500 2.4 1\n",
      "3000 2.1 1\n",
      "3500 2.4 1\n",
      "4000 0.8 1\n",
      "4500 1.5 1\n",
      "5000 2.4 1\n",
      "5500 1.5 1\n",
      "6000 0.9 1\n",
      "6500 1.2 1\n",
      "7000 2.7 1\n",
      "7500 0.9 1\n",
      "8000 0.5 1\n",
      "8500 3.2 1\n",
      "9000 0.8 1\n",
      "9500 2.4 1\n",
      "10000 1.0 1\n",
      "10500 2.1 0.9549999999999828\n",
      "11000 2.5 0.9099999999999655\n",
      "11500 1.1 0.8649999999999483\n",
      "12000 2.8 0.819999999999931\n",
      "12500 2.1 0.7749999999999138\n",
      "13000 0.4 0.7299999999998965\n",
      "13500 2.2 0.6849999999998793\n",
      "14000 2.0 0.639999999999862\n",
      "14500 2.8 0.5949999999998448\n",
      "15000 2.2 0.5499999999998275\n",
      "15500 3.5 0.5049999999998103\n",
      "16000 2.1 0.4599999999998177\n",
      "16500 1.6 0.41499999999982823\n",
      "17000 2.1 0.36999999999983874\n",
      "17500 0.6 0.32499999999984924\n",
      "18000 1.6 0.27999999999985975\n",
      "18500 2.0 0.23499999999986562\n",
      "19000 1.5 0.18999999999986225\n",
      "19500 2.9 0.14499999999985888\n",
      "20000 2.0 0.09999999999985551\n",
      "20500 2.9 0.09999999999985551\n",
      "21000 1.4 0.09999999999985551\n",
      "21500 2.1 0.09999999999985551\n",
      "22000 2.4 0.09999999999985551\n",
      "22500 4.4 0.09999999999985551\n",
      "23000 2.4 0.09999999999985551\n",
      "23500 4.0 0.09999999999985551\n",
      "24000 3.5 0.09999999999985551\n",
      "24500 2.8 0.09999999999985551\n",
      "25000 4.3 0.09999999999985551\n",
      "25500 4.1 0.09999999999985551\n",
      "26000 5.4 0.09999999999985551\n",
      "26500 4.8 0.09999999999985551\n",
      "27000 5.1 0.09999999999985551\n",
      "27500 5.2 0.09999999999985551\n",
      "28000 4.9 0.09999999999985551\n",
      "28500 6.2 0.09999999999985551\n",
      "29000 5.2 0.09999999999985551\n",
      "29500 7.3 0.09999999999985551\n",
      "30000 4.9 0.09999999999985551\n",
      "30500 7.9 0.09999999999985551\n",
      "31000 8.7 0.09999999999985551\n",
      "31500 8.3 0.09999999999985551\n",
      "32000 7.2 0.09999999999985551\n",
      "32500 8.1 0.09999999999985551\n",
      "33000 8.9 0.09999999999985551\n",
      "33500 12.6 0.09999999999985551\n",
      "34000 9.9 0.09999999999985551\n",
      "34500 16.1 0.09999999999985551\n",
      "35000 12.5 0.09999999999985551\n",
      "35500 10.8 0.09999999999985551\n",
      "36000 11.2 0.09999999999985551\n",
      "36500 10.9 0.09999999999985551\n",
      "37000 13.0 0.09999999999985551\n",
      "37500 14.3 0.09999999999985551\n",
      "38000 14.3 0.09999999999985551\n",
      "38500 15.5 0.09999999999985551\n",
      "39000 15.7 0.09999999999985551\n",
      "39500 16.2 0.09999999999985551\n",
      "40000 17.0 0.09999999999985551\n",
      "40500 14.8 0.09999999999985551\n",
      "41000 13.5 0.09999999999985551\n",
      "41500 17.3 0.09999999999985551\n",
      "42000 17.5 0.09999999999985551\n",
      "42500 19.7 0.09999999999985551\n",
      "43000 16.9 0.09999999999985551\n",
      "43500 17.5 0.09999999999985551\n",
      "44000 17.2 0.09999999999985551\n",
      "44500 16.8 0.09999999999985551\n",
      "45000 20.6 0.09999999999985551\n",
      "45500 16.5 0.09999999999985551\n",
      "46000 20.4 0.09999999999985551\n",
      "46500 20.4 0.09999999999985551\n",
      "47000 22.5 0.09999999999985551\n",
      "47500 19.5 0.09999999999985551\n",
      "48000 21.9 0.09999999999985551\n",
      "48500 14.8 0.09999999999985551\n",
      "49000 21.5 0.09999999999985551\n",
      "49500 18.5 0.09999999999985551\n",
      "50000 18.2 0.09999999999985551\n",
      "Saved Model\n",
      "50500 19.2 0.09999999999985551\n",
      "51000 19.6 0.09999999999985551\n",
      "51500 19.6 0.09999999999985551\n",
      "52000 19.7 0.09999999999985551\n",
      "52500 21.6 0.09999999999985551\n",
      "53000 21.4 0.09999999999985551\n",
      "53500 21.4 0.09999999999985551\n",
      "54000 21.4 0.09999999999985551\n",
      "54500 19.7 0.09999999999985551\n",
      "55000 21.5 0.09999999999985551\n",
      "55500 21.7 0.09999999999985551\n",
      "56000 21.1 0.09999999999985551\n",
      "56500 21.4 0.09999999999985551\n",
      "57000 20.5 0.09999999999985551\n",
      "57500 23.6 0.09999999999985551\n",
      "58000 21.8 0.09999999999985551\n",
      "58500 21.2 0.09999999999985551\n",
      "59000 20.7 0.09999999999985551\n",
      "59500 18.5 0.09999999999985551\n",
      "60000 18.4 0.09999999999985551\n",
      "60500 17.8 0.09999999999985551\n",
      "61000 21.8 0.09999999999985551\n",
      "61500 20.3 0.09999999999985551\n",
      "62000 21.6 0.09999999999985551\n",
      "62500 22.7 0.09999999999985551\n",
      "63000 21.3 0.09999999999985551\n",
      "63500 19.0 0.09999999999985551\n",
      "64000 22.7 0.09999999999985551\n",
      "64500 22.1 0.09999999999985551\n",
      "65000 22.8 0.09999999999985551\n",
      "65500 23.6 0.09999999999985551\n",
      "66000 19.3 0.09999999999985551\n",
      "66500 21.6 0.09999999999985551\n",
      "67000 20.9 0.09999999999985551\n",
      "67500 20.9 0.09999999999985551\n",
      "68000 22.2 0.09999999999985551\n",
      "68500 21.8 0.09999999999985551\n",
      "69000 22.6 0.09999999999985551\n",
      "69500 21.1 0.09999999999985551\n",
      "70000 19.9 0.09999999999985551\n",
      "70500 22.1 0.09999999999985551\n",
      "71000 22.3 0.09999999999985551\n",
      "71500 23.7 0.09999999999985551\n",
      "72000 19.9 0.09999999999985551\n",
      "72500 22.5 0.09999999999985551\n",
      "73000 18.1 0.09999999999985551\n",
      "73500 19.7 0.09999999999985551\n",
      "74000 23.1 0.09999999999985551\n",
      "74500 22.2 0.09999999999985551\n",
      "75000 20.8 0.09999999999985551\n",
      "75500 23.8 0.09999999999985551\n",
      "76000 19.6 0.09999999999985551\n",
      "76500 22.2 0.09999999999985551\n",
      "77000 20.0 0.09999999999985551\n",
      "77500 20.9 0.09999999999985551\n",
      "78000 20.6 0.09999999999985551\n",
      "78500 20.6 0.09999999999985551\n",
      "79000 23.2 0.09999999999985551\n",
      "79500 22.5 0.09999999999985551\n",
      "80000 22.3 0.09999999999985551\n",
      "80500 24.0 0.09999999999985551\n",
      "81000 23.1 0.09999999999985551\n",
      "81500 20.3 0.09999999999985551\n",
      "82000 20.9 0.09999999999985551\n",
      "82500 18.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83000 21.7 0.09999999999985551\n",
      "83500 22.7 0.09999999999985551\n",
      "84000 17.3 0.09999999999985551\n",
      "84500 23.1 0.09999999999985551\n",
      "85000 21.7 0.09999999999985551\n",
      "85500 23.5 0.09999999999985551\n",
      "86000 21.0 0.09999999999985551\n",
      "86500 21.7 0.09999999999985551\n",
      "87000 21.4 0.09999999999985551\n",
      "87500 21.1 0.09999999999985551\n",
      "88000 24.1 0.09999999999985551\n",
      "88500 22.6 0.09999999999985551\n",
      "89000 21.9 0.09999999999985551\n",
      "89500 21.7 0.09999999999985551\n",
      "90000 21.4 0.09999999999985551\n",
      "90500 21.1 0.09999999999985551\n",
      "91000 23.7 0.09999999999985551\n",
      "91500 21.5 0.09999999999985551\n",
      "92000 20.5 0.09999999999985551\n",
      "92500 23.1 0.09999999999985551\n",
      "93000 18.5 0.09999999999985551\n",
      "93500 23.5 0.09999999999985551\n",
      "94000 19.3 0.09999999999985551\n",
      "94500 21.9 0.09999999999985551\n",
      "95000 22.2 0.09999999999985551\n",
      "95500 23.3 0.09999999999985551\n",
      "96000 20.4 0.09999999999985551\n",
      "96500 20.5 0.09999999999985551\n",
      "97000 20.0 0.09999999999985551\n",
      "97500 19.2 0.09999999999985551\n",
      "98000 20.9 0.09999999999985551\n",
      "98500 20.6 0.09999999999985551\n",
      "99000 21.5 0.09999999999985551\n",
      "99500 21.9 0.09999999999985551\n",
      "100000 18.7 0.09999999999985551\n",
      "Saved Model\n",
      "100500 19.8 0.09999999999985551\n",
      "101000 20.7 0.09999999999985551\n",
      "101500 21.5 0.09999999999985551\n",
      "102000 19.8 0.09999999999985551\n",
      "102500 24.1 0.09999999999985551\n",
      "103000 20.1 0.09999999999985551\n",
      "103500 20.7 0.09999999999985551\n",
      "104000 22.8 0.09999999999985551\n",
      "104500 21.6 0.09999999999985551\n",
      "105000 21.3 0.09999999999985551\n",
      "105500 19.7 0.09999999999985551\n",
      "106000 18.4 0.09999999999985551\n",
      "106500 23.6 0.09999999999985551\n",
      "107000 22.7 0.09999999999985551\n",
      "107500 23.1 0.09999999999985551\n",
      "108000 20.5 0.09999999999985551\n",
      "108500 19.2 0.09999999999985551\n",
      "109000 22.5 0.09999999999985551\n",
      "109500 24.5 0.09999999999985551\n",
      "110000 18.4 0.09999999999985551\n",
      "110500 24.0 0.09999999999985551\n",
      "111000 20.5 0.09999999999985551\n",
      "111500 22.6 0.09999999999985551\n",
      "112000 21.4 0.09999999999985551\n",
      "112500 21.9 0.09999999999985551\n",
      "113000 22.3 0.09999999999985551\n",
      "113500 21.2 0.09999999999985551\n",
      "114000 23.0 0.09999999999985551\n",
      "114500 20.3 0.09999999999985551\n",
      "115000 23.0 0.09999999999985551\n",
      "115500 21.1 0.09999999999985551\n",
      "116000 19.2 0.09999999999985551\n",
      "116500 22.6 0.09999999999985551\n",
      "117000 20.6 0.09999999999985551\n",
      "117500 21.6 0.09999999999985551\n",
      "118000 23.3 0.09999999999985551\n",
      "118500 21.3 0.09999999999985551\n",
      "119000 21.8 0.09999999999985551\n",
      "119500 20.4 0.09999999999985551\n",
      "120000 23.7 0.09999999999985551\n",
      "120500 22.1 0.09999999999985551\n",
      "121000 22.8 0.09999999999985551\n",
      "121500 21.7 0.09999999999985551\n",
      "122000 22.2 0.09999999999985551\n",
      "122500 23.0 0.09999999999985551\n",
      "123000 19.3 0.09999999999985551\n",
      "123500 23.4 0.09999999999985551\n",
      "124000 21.7 0.09999999999985551\n",
      "124500 20.1 0.09999999999985551\n",
      "125000 19.9 0.09999999999985551\n",
      "125500 20.9 0.09999999999985551\n",
      "126000 20.3 0.09999999999985551\n",
      "126500 23.5 0.09999999999985551\n",
      "127000 22.5 0.09999999999985551\n",
      "127500 23.3 0.09999999999985551\n",
      "128000 22.0 0.09999999999985551\n",
      "128500 22.9 0.09999999999985551\n",
      "129000 24.3 0.09999999999985551\n",
      "129500 23.4 0.09999999999985551\n",
      "130000 21.4 0.09999999999985551\n",
      "130500 20.7 0.09999999999985551\n",
      "131000 21.7 0.09999999999985551\n",
      "131500 22.9 0.09999999999985551\n",
      "132000 22.4 0.09999999999985551\n",
      "132500 20.9 0.09999999999985551\n",
      "133000 21.8 0.09999999999985551\n",
      "133500 24.4 0.09999999999985551\n",
      "134000 20.2 0.09999999999985551\n",
      "134500 19.2 0.09999999999985551\n",
      "135000 19.1 0.09999999999985551\n",
      "135500 23.3 0.09999999999985551\n",
      "136000 22.5 0.09999999999985551\n",
      "136500 21.9 0.09999999999985551\n",
      "137000 21.0 0.09999999999985551\n",
      "137500 21.8 0.09999999999985551\n",
      "138000 20.1 0.09999999999985551\n",
      "138500 22.1 0.09999999999985551\n",
      "139000 18.8 0.09999999999985551\n",
      "139500 21.9 0.09999999999985551\n",
      "140000 21.5 0.09999999999985551\n",
      "140500 23.0 0.09999999999985551\n",
      "141000 19.6 0.09999999999985551\n",
      "141500 20.0 0.09999999999985551\n",
      "142000 19.3 0.09999999999985551\n",
      "142500 20.1 0.09999999999985551\n",
      "143000 23.4 0.09999999999985551\n",
      "143500 22.6 0.09999999999985551\n",
      "144000 20.6 0.09999999999985551\n",
      "144500 22.7 0.09999999999985551\n",
      "145000 22.3 0.09999999999985551\n",
      "145500 21.7 0.09999999999985551\n",
      "146000 20.7 0.09999999999985551\n",
      "146500 21.9 0.09999999999985551\n",
      "147000 21.8 0.09999999999985551\n",
      "147500 23.2 0.09999999999985551\n",
      "148000 21.4 0.09999999999985551\n",
      "148500 23.3 0.09999999999985551\n",
      "149000 21.4 0.09999999999985551\n",
      "149500 21.9 0.09999999999985551\n",
      "150000 23.2 0.09999999999985551\n",
      "Saved Model\n",
      "150500 22.8 0.09999999999985551\n",
      "151000 19.2 0.09999999999985551\n",
      "151500 20.4 0.09999999999985551\n",
      "152000 21.1 0.09999999999985551\n",
      "152500 22.3 0.09999999999985551\n",
      "153000 21.1 0.09999999999985551\n",
      "153500 22.9 0.09999999999985551\n",
      "154000 20.2 0.09999999999985551\n",
      "154500 22.6 0.09999999999985551\n",
      "155000 23.1 0.09999999999985551\n",
      "155500 23.1 0.09999999999985551\n",
      "156000 22.7 0.09999999999985551\n",
      "156500 20.6 0.09999999999985551\n",
      "157000 24.3 0.09999999999985551\n",
      "157500 22.0 0.09999999999985551\n",
      "158000 21.1 0.09999999999985551\n",
      "158500 23.4 0.09999999999985551\n",
      "159000 21.4 0.09999999999985551\n",
      "159500 23.0 0.09999999999985551\n",
      "160000 21.8 0.09999999999985551\n",
      "160500 22.6 0.09999999999985551\n",
      "161000 22.7 0.09999999999985551\n",
      "161500 23.7 0.09999999999985551\n",
      "162000 19.5 0.09999999999985551\n",
      "162500 21.1 0.09999999999985551\n",
      "163000 24.0 0.09999999999985551\n",
      "163500 19.5 0.09999999999985551\n",
      "164000 21.6 0.09999999999985551\n",
      "164500 23.8 0.09999999999985551\n",
      "165000 15.7 0.09999999999985551\n",
      "165500 19.3 0.09999999999985551\n",
      "166000 19.7 0.09999999999985551\n",
      "166500 23.3 0.09999999999985551\n",
      "167000 20.5 0.09999999999985551\n",
      "167500 20.9 0.09999999999985551\n",
      "168000 20.6 0.09999999999985551\n",
      "168500 22.9 0.09999999999985551\n",
      "169000 21.8 0.09999999999985551\n",
      "169500 22.8 0.09999999999985551\n",
      "170000 22.7 0.09999999999985551\n",
      "170500 21.1 0.09999999999985551\n",
      "171000 20.7 0.09999999999985551\n",
      "171500 23.9 0.09999999999985551\n",
      "172000 23.7 0.09999999999985551\n",
      "172500 24.4 0.09999999999985551\n",
      "173000 19.6 0.09999999999985551\n",
      "173500 22.6 0.09999999999985551\n",
      "174000 21.1 0.09999999999985551\n",
      "174500 23.4 0.09999999999985551\n",
      "175000 22.1 0.09999999999985551\n",
      "175500 24.1 0.09999999999985551\n",
      "176000 21.6 0.09999999999985551\n",
      "176500 19.2 0.09999999999985551\n",
      "177000 22.2 0.09999999999985551\n",
      "177500 24.3 0.09999999999985551\n",
      "178000 21.7 0.09999999999985551\n",
      "178500 22.9 0.09999999999985551\n",
      "179000 19.7 0.09999999999985551\n",
      "179500 22.5 0.09999999999985551\n",
      "180000 23.0 0.09999999999985551\n",
      "180500 21.4 0.09999999999985551\n",
      "181000 22.0 0.09999999999985551\n",
      "181500 18.5 0.09999999999985551\n",
      "182000 22.0 0.09999999999985551\n",
      "182500 22.6 0.09999999999985551\n",
      "183000 21.7 0.09999999999985551\n",
      "183500 19.3 0.09999999999985551\n",
      "184000 23.3 0.09999999999985551\n",
      "184500 21.2 0.09999999999985551\n",
      "185000 23.4 0.09999999999985551\n",
      "185500 21.9 0.09999999999985551\n",
      "186000 22.2 0.09999999999985551\n",
      "186500 24.2 0.09999999999985551\n",
      "187000 19.5 0.09999999999985551\n",
      "187500 21.0 0.09999999999985551\n",
      "188000 21.8 0.09999999999985551\n",
      "188500 21.5 0.09999999999985551\n",
      "189000 21.0 0.09999999999985551\n",
      "189500 21.8 0.09999999999985551\n",
      "190000 22.9 0.09999999999985551\n",
      "190500 20.7 0.09999999999985551\n",
      "191000 22.7 0.09999999999985551\n",
      "191500 24.2 0.09999999999985551\n",
      "192000 22.4 0.09999999999985551\n",
      "192500 21.9 0.09999999999985551\n",
      "193000 22.2 0.09999999999985551\n",
      "193500 21.7 0.09999999999985551\n",
      "194000 23.0 0.09999999999985551\n",
      "194500 22.0 0.09999999999985551\n",
      "195000 21.5 0.09999999999985551\n",
      "195500 21.5 0.09999999999985551\n",
      "196000 23.8 0.09999999999985551\n",
      "196500 22.2 0.09999999999985551\n",
      "197000 22.2 0.09999999999985551\n",
      "197500 23.0 0.09999999999985551\n",
      "198000 22.0 0.09999999999985551\n",
      "198500 19.2 0.09999999999985551\n",
      "199000 23.9 0.09999999999985551\n",
      "199500 21.4 0.09999999999985551\n",
      "200000 23.3 0.09999999999985551\n",
      "Saved Model\n",
      "200500 20.6 0.09999999999985551\n",
      "201000 22.1 0.09999999999985551\n",
      "201500 22.0 0.09999999999985551\n",
      "202000 22.7 0.09999999999985551\n",
      "202500 23.0 0.09999999999985551\n",
      "203000 21.9 0.09999999999985551\n",
      "203500 21.4 0.09999999999985551\n",
      "204000 23.2 0.09999999999985551\n",
      "204500 22.4 0.09999999999985551\n",
      "205000 22.6 0.09999999999985551\n",
      "205500 21.4 0.09999999999985551\n",
      "206000 24.1 0.09999999999985551\n",
      "206500 24.6 0.09999999999985551\n",
      "207000 20.4 0.09999999999985551\n",
      "207500 21.9 0.09999999999985551\n",
      "208000 21.5 0.09999999999985551\n",
      "208500 22.4 0.09999999999985551\n",
      "209000 19.8 0.09999999999985551\n",
      "209500 21.8 0.09999999999985551\n",
      "210000 21.2 0.09999999999985551\n",
      "210500 21.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211000 23.4 0.09999999999985551\n",
      "211500 22.4 0.09999999999985551\n",
      "212000 20.3 0.09999999999985551\n",
      "212500 22.8 0.09999999999985551\n",
      "213000 21.7 0.09999999999985551\n",
      "213500 22.6 0.09999999999985551\n",
      "214000 21.2 0.09999999999985551\n",
      "214500 19.9 0.09999999999985551\n",
      "215000 21.8 0.09999999999985551\n",
      "215500 21.6 0.09999999999985551\n",
      "216000 20.8 0.09999999999985551\n",
      "216500 23.1 0.09999999999985551\n",
      "217000 21.7 0.09999999999985551\n",
      "217500 22.5 0.09999999999985551\n",
      "218000 23.4 0.09999999999985551\n",
      "218500 23.6 0.09999999999985551\n",
      "219000 22.2 0.09999999999985551\n",
      "219500 21.6 0.09999999999985551\n",
      "220000 23.4 0.09999999999985551\n",
      "220500 23.3 0.09999999999985551\n",
      "221000 21.7 0.09999999999985551\n",
      "221500 21.0 0.09999999999985551\n",
      "222000 22.2 0.09999999999985551\n",
      "222500 22.4 0.09999999999985551\n",
      "223000 21.6 0.09999999999985551\n",
      "223500 20.6 0.09999999999985551\n",
      "224000 23.2 0.09999999999985551\n",
      "224500 21.6 0.09999999999985551\n",
      "225000 24.5 0.09999999999985551\n",
      "225500 21.8 0.09999999999985551\n",
      "226000 20.2 0.09999999999985551\n",
      "226500 21.7 0.09999999999985551\n",
      "227000 19.6 0.09999999999985551\n",
      "227500 20.0 0.09999999999985551\n",
      "228000 20.3 0.09999999999985551\n",
      "228500 22.7 0.09999999999985551\n",
      "229000 22.9 0.09999999999985551\n",
      "229500 21.6 0.09999999999985551\n",
      "230000 23.7 0.09999999999985551\n",
      "230500 22.6 0.09999999999985551\n",
      "231000 22.1 0.09999999999985551\n",
      "231500 22.4 0.09999999999985551\n",
      "232000 23.0 0.09999999999985551\n",
      "232500 20.7 0.09999999999985551\n",
      "233000 21.7 0.09999999999985551\n",
      "233500 19.9 0.09999999999985551\n",
      "234000 23.1 0.09999999999985551\n",
      "234500 23.2 0.09999999999985551\n",
      "235000 22.4 0.09999999999985551\n",
      "235500 20.1 0.09999999999985551\n",
      "236000 23.6 0.09999999999985551\n",
      "236500 22.2 0.09999999999985551\n",
      "237000 24.4 0.09999999999985551\n",
      "237500 21.1 0.09999999999985551\n",
      "238000 21.5 0.09999999999985551\n",
      "238500 22.2 0.09999999999985551\n",
      "239000 20.2 0.09999999999985551\n",
      "239500 20.6 0.09999999999985551\n",
      "240000 20.8 0.09999999999985551\n",
      "240500 22.4 0.09999999999985551\n",
      "241000 24.0 0.09999999999985551\n",
      "241500 21.0 0.09999999999985551\n",
      "242000 22.2 0.09999999999985551\n",
      "242500 21.8 0.09999999999985551\n",
      "243000 21.3 0.09999999999985551\n",
      "243500 23.5 0.09999999999985551\n",
      "244000 21.7 0.09999999999985551\n",
      "244500 21.2 0.09999999999985551\n",
      "245000 18.4 0.09999999999985551\n",
      "245500 21.6 0.09999999999985551\n",
      "246000 22.9 0.09999999999985551\n",
      "246500 21.5 0.09999999999985551\n",
      "247000 22.3 0.09999999999985551\n",
      "247500 19.7 0.09999999999985551\n",
      "248000 22.6 0.09999999999985551\n",
      "248500 23.9 0.09999999999985551\n",
      "249000 22.2 0.09999999999985551\n",
      "249500 24.5 0.09999999999985551\n",
      "250000 23.1 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 22.1 0.09999999999985551\n",
      "251000 23.9 0.09999999999985551\n",
      "251500 21.8 0.09999999999985551\n",
      "252000 24.0 0.09999999999985551\n",
      "252500 20.9 0.09999999999985551\n",
      "253000 21.3 0.09999999999985551\n",
      "253500 21.7 0.09999999999985551\n",
      "254000 22.7 0.09999999999985551\n",
      "254500 22.2 0.09999999999985551\n",
      "255000 20.0 0.09999999999985551\n",
      "255500 22.5 0.09999999999985551\n",
      "256000 23.7 0.09999999999985551\n",
      "256500 20.9 0.09999999999985551\n",
      "257000 21.8 0.09999999999985551\n",
      "257500 21.9 0.09999999999985551\n",
      "258000 21.1 0.09999999999985551\n",
      "258500 21.0 0.09999999999985551\n",
      "259000 23.0 0.09999999999985551\n",
      "259500 21.6 0.09999999999985551\n",
      "260000 22.0 0.09999999999985551\n",
      "260500 22.7 0.09999999999985551\n",
      "261000 24.0 0.09999999999985551\n",
      "261500 23.6 0.09999999999985551\n",
      "262000 22.7 0.09999999999985551\n",
      "262500 23.1 0.09999999999985551\n",
      "263000 20.9 0.09999999999985551\n",
      "263500 17.3 0.09999999999985551\n",
      "264000 21.9 0.09999999999985551\n",
      "264500 22.5 0.09999999999985551\n",
      "265000 23.9 0.09999999999985551\n",
      "265500 22.6 0.09999999999985551\n",
      "266000 21.0 0.09999999999985551\n",
      "266500 21.8 0.09999999999985551\n",
      "267000 24.6 0.09999999999985551\n",
      "267500 21.9 0.09999999999985551\n",
      "268000 23.1 0.09999999999985551\n",
      "268500 21.1 0.09999999999985551\n",
      "269000 22.2 0.09999999999985551\n",
      "269500 23.5 0.09999999999985551\n",
      "270000 19.5 0.09999999999985551\n",
      "270500 21.6 0.09999999999985551\n",
      "271000 21.1 0.09999999999985551\n",
      "271500 24.0 0.09999999999985551\n",
      "272000 21.6 0.09999999999985551\n",
      "272500 20.3 0.09999999999985551\n",
      "273000 23.7 0.09999999999985551\n",
      "273500 23.2 0.09999999999985551\n",
      "274000 22.8 0.09999999999985551\n",
      "274500 21.0 0.09999999999985551\n",
      "275000 23.7 0.09999999999985551\n",
      "275500 23.3 0.09999999999985551\n",
      "276000 23.4 0.09999999999985551\n",
      "276500 20.8 0.09999999999985551\n",
      "277000 22.7 0.09999999999985551\n",
      "277500 22.4 0.09999999999985551\n",
      "278000 22.0 0.09999999999985551\n",
      "278500 22.6 0.09999999999985551\n",
      "279000 24.4 0.09999999999985551\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking network learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean reward over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

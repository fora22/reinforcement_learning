{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439FBA8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439FBA8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439FBA8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439FBA8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439F710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439F710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439F710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E439F710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2D21FC748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2D21FC748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2D21FC748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2D21FC748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4461C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4461C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4461C50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4461C50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E439F7B8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E45FFE10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E45FFE10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E45FFE10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E45FFE10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E46BDEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E46BDEB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E46BDEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E46BDEB8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4727A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4727A20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4727A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E4727A20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E47055C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E47055C0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E47055C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001F2E47055C0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001F2E4415A58>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 0.6 1\n",
      "1000 -0.4 1\n",
      "1500 -0.9 1\n",
      "2000 -0.2 1\n",
      "2500 -0.8 1\n",
      "3000 0.5 1\n",
      "3500 -0.3 1\n",
      "4000 -0.7 1\n",
      "4500 0.5 1\n",
      "5000 -1.1 1\n",
      "5500 -1.4 1\n",
      "6000 1.2 1\n",
      "6500 -1.9 1\n",
      "7000 -0.1 1\n",
      "7500 0.6 1\n",
      "8000 -0.1 1\n",
      "8500 0.4 1\n",
      "9000 -0.2 1\n",
      "9500 -0.3 1\n",
      "10000 -0.1 1\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Conv/Conv2D (defined at <ipython-input-3-8d953b9871a6>:8) ]]\n\t [[ArgMax/_91]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Conv/Conv2D (defined at <ipython-input-3-8d953b9871a6>:8) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv/Conv2D:\n Reshape (defined at <ipython-input-3-8d953b9871a6>:6)\n\nInput Source operations connected to node Conv/Conv2D:\n Reshape (defined at <ipython-input-3-8d953b9871a6>:6)\n\nOriginal stack trace for 'Conv/Conv2D':\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-eb3658efee38>\", line 2, in <module>\n    mainQN = Qnetwork(h_size)\n  File \"<ipython-input-3-8d953b9871a6>\", line 8, in __init__\n    inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1159, in convolution2d\n    conv_dims=2)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1057, in convolution\n    outputs = layer.apply(inputs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1479, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 537, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 634, in __call__\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 146, in wrapper\n    ), args, kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 446, in converted_call\n    return _call_unconverted(f, args, kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 253, in _call_unconverted\n    return f(*args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 196, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1079, in __call__\n    return self.conv_op(inp, filter)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 635, in __call__\n    return self.call(inp, filter)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 234, in __call__\n    name=self.name)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1953, in conv2d\n    name=name)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1161, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node Conv/Conv2D}}]]\n\t [[ArgMax/_91]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node Conv/Conv2D}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-eb3658efee38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[0mtrainBatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyBuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Get a random batch of experiences.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                     \u001b[1;31m#Below we perform the Double-DQN update to the target Q-values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                     \u001b[0mQ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalarInput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                     \u001b[0mQ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtargetQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalarInput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                     \u001b[0mend_multiplier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1368\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Conv/Conv2D (defined at <ipython-input-3-8d953b9871a6>:8) ]]\n\t [[ArgMax/_91]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node Conv/Conv2D (defined at <ipython-input-3-8d953b9871a6>:8) ]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Conv/Conv2D:\n Reshape (defined at <ipython-input-3-8d953b9871a6>:6)\n\nInput Source operations connected to node Conv/Conv2D:\n Reshape (defined at <ipython-input-3-8d953b9871a6>:6)\n\nOriginal stack trace for 'Conv/Conv2D':\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\asyncio\\base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\asyncio\\base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-eb3658efee38>\", line 2, in <module>\n    mainQN = Qnetwork(h_size)\n  File \"<ipython-input-3-8d953b9871a6>\", line 8, in __init__\n    inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1159, in convolution2d\n    conv_dims=2)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 1057, in convolution\n    outputs = layer.apply(inputs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1479, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 537, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 634, in __call__\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 146, in wrapper\n    ), args, kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 446, in converted_call\n    return _call_unconverted(f, args, kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 253, in _call_unconverted\n    return f(*args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 196, in call\n    outputs = self._convolution_op(inputs, self.kernel)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1079, in __call__\n    return self.conv_op(inp, filter)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 635, in __call__\n    return self.call(inp, filter)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 234, in __call__\n    name=self.name)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 1953, in conv2d\n    name=name)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1161, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"c:\\users\\assistant_2\\anaconda3\\envs\\rl_test\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

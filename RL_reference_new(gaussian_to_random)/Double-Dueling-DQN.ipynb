{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = True #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e243c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e243c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e243c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e243c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343e24ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343e24240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343e24240>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343e24240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343e24240>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb34356ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb34356ad30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb34356ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb34356ad30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb3434168d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb3434168d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb3434168d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb3434168d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358be0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fb343358be0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fb343358908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Loading Model...\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./dqn/model-9999.ckpt\n",
      "Saved Model\n",
      "500 -1.0 1\n",
      "1000 -0.4 1\n",
      "1500 0.0 1\n",
      "2000 0.3 1\n",
      "2500 -0.4 1\n",
      "3000 0.3 1\n",
      "3500 0.6 1\n",
      "4000 -0.4 1\n",
      "4500 -0.4 1\n",
      "5000 0.5 1\n",
      "5500 0.1 1\n",
      "6000 -0.8 1\n",
      "6500 -0.9 1\n",
      "7000 1.0 1\n",
      "7500 -1.2 1\n",
      "8000 1.2 1\n",
      "8500 0.3 1\n",
      "9000 0.4 1\n",
      "9500 -0.4 1\n",
      "10000 -2.1 1\n",
      "10500 0.8 0.9549999999999828\n",
      "11000 1.2 0.9099999999999655\n",
      "11500 0.9 0.8649999999999483\n",
      "12000 1.8 0.819999999999931\n",
      "12500 3.5 0.7749999999999138\n",
      "13000 1.2 0.7299999999998965\n",
      "13500 2.5 0.6849999999998793\n",
      "14000 3.2 0.639999999999862\n",
      "14500 3.1 0.5949999999998448\n",
      "15000 4.2 0.5499999999998275\n",
      "15500 4.5 0.5049999999998103\n",
      "16000 8.9 0.4599999999998177\n",
      "16500 8.3 0.41499999999982823\n",
      "17000 6.4 0.36999999999983874\n",
      "17500 9.2 0.32499999999984924\n",
      "18000 8.8 0.27999999999985975\n",
      "18500 8.2 0.23499999999986562\n",
      "19000 9.8 0.18999999999986225\n",
      "19500 13.1 0.14499999999985888\n",
      "20000 7.7 0.09999999999985551\n",
      "20500 9.9 0.09999999999985551\n",
      "21000 9.0 0.09999999999985551\n",
      "21500 12.6 0.09999999999985551\n",
      "22000 12.2 0.09999999999985551\n",
      "22500 12.9 0.09999999999985551\n",
      "23000 8.1 0.09999999999985551\n",
      "23500 10.3 0.09999999999985551\n",
      "24000 13.6 0.09999999999985551\n",
      "24500 13.7 0.09999999999985551\n",
      "25000 11.4 0.09999999999985551\n",
      "25500 8.5 0.09999999999985551\n",
      "26000 9.2 0.09999999999985551\n",
      "26500 12.4 0.09999999999985551\n",
      "27000 13.1 0.09999999999985551\n",
      "27500 11.6 0.09999999999985551\n",
      "28000 6.0 0.09999999999985551\n",
      "28500 11.3 0.09999999999985551\n",
      "29000 9.0 0.09999999999985551\n",
      "29500 15.3 0.09999999999985551\n",
      "30000 11.2 0.09999999999985551\n",
      "30500 12.7 0.09999999999985551\n",
      "31000 12.3 0.09999999999985551\n",
      "31500 9.8 0.09999999999985551\n",
      "32000 11.0 0.09999999999985551\n",
      "32500 13.1 0.09999999999985551\n",
      "33000 14.4 0.09999999999985551\n",
      "33500 13.3 0.09999999999985551\n",
      "34000 14.0 0.09999999999985551\n",
      "34500 11.4 0.09999999999985551\n",
      "35000 12.6 0.09999999999985551\n",
      "35500 12.6 0.09999999999985551\n",
      "36000 11.6 0.09999999999985551\n",
      "36500 15.6 0.09999999999985551\n",
      "37000 12.0 0.09999999999985551\n",
      "37500 10.0 0.09999999999985551\n",
      "38000 13.7 0.09999999999985551\n",
      "38500 9.8 0.09999999999985551\n",
      "39000 10.4 0.09999999999985551\n",
      "39500 11.4 0.09999999999985551\n",
      "40000 10.3 0.09999999999985551\n",
      "40500 11.2 0.09999999999985551\n",
      "41000 11.4 0.09999999999985551\n",
      "41500 9.0 0.09999999999985551\n",
      "42000 7.9 0.09999999999985551\n",
      "42500 10.0 0.09999999999985551\n",
      "43000 12.9 0.09999999999985551\n",
      "43500 9.9 0.09999999999985551\n",
      "44000 12.0 0.09999999999985551\n",
      "44500 11.4 0.09999999999985551\n",
      "45000 13.3 0.09999999999985551\n",
      "45500 13.7 0.09999999999985551\n",
      "46000 10.2 0.09999999999985551\n",
      "46500 13.6 0.09999999999985551\n",
      "47000 12.1 0.09999999999985551\n",
      "47500 12.4 0.09999999999985551\n",
      "48000 12.1 0.09999999999985551\n",
      "48500 15.7 0.09999999999985551\n",
      "49000 10.9 0.09999999999985551\n",
      "49500 9.9 0.09999999999985551\n",
      "50000 7.9 0.09999999999985551\n",
      "Saved Model\n",
      "50500 11.8 0.09999999999985551\n",
      "51000 14.6 0.09999999999985551\n",
      "51500 14.1 0.09999999999985551\n",
      "52000 10.8 0.09999999999985551\n",
      "52500 12.6 0.09999999999985551\n",
      "53000 11.3 0.09999999999985551\n",
      "53500 12.7 0.09999999999985551\n",
      "54000 15.8 0.09999999999985551\n",
      "54500 12.2 0.09999999999985551\n",
      "55000 11.6 0.09999999999985551\n",
      "55500 11.1 0.09999999999985551\n",
      "56000 10.3 0.09999999999985551\n",
      "56500 12.3 0.09999999999985551\n",
      "57000 9.3 0.09999999999985551\n",
      "57500 13.8 0.09999999999985551\n",
      "58000 12.6 0.09999999999985551\n",
      "58500 11.5 0.09999999999985551\n",
      "59000 11.6 0.09999999999985551\n",
      "59500 13.5 0.09999999999985551\n",
      "60000 9.9 0.09999999999985551\n",
      "60500 15.5 0.09999999999985551\n",
      "61000 13.5 0.09999999999985551\n",
      "61500 11.5 0.09999999999985551\n",
      "62000 11.9 0.09999999999985551\n",
      "62500 10.9 0.09999999999985551\n",
      "63000 12.9 0.09999999999985551\n",
      "63500 11.8 0.09999999999985551\n",
      "64000 13.4 0.09999999999985551\n",
      "64500 11.3 0.09999999999985551\n",
      "65000 13.5 0.09999999999985551\n",
      "65500 10.8 0.09999999999985551\n",
      "66000 11.2 0.09999999999985551\n",
      "66500 14.2 0.09999999999985551\n",
      "67000 15.1 0.09999999999985551\n",
      "67500 12.8 0.09999999999985551\n",
      "68000 12.1 0.09999999999985551\n",
      "68500 10.0 0.09999999999985551\n",
      "69000 12.0 0.09999999999985551\n",
      "69500 9.0 0.09999999999985551\n",
      "70000 11.7 0.09999999999985551\n",
      "70500 10.4 0.09999999999985551\n",
      "71000 11.0 0.09999999999985551\n",
      "71500 10.4 0.09999999999985551\n",
      "72000 9.4 0.09999999999985551\n",
      "72500 9.9 0.09999999999985551\n",
      "73000 14.3 0.09999999999985551\n",
      "73500 10.6 0.09999999999985551\n",
      "74000 11.5 0.09999999999985551\n",
      "74500 14.0 0.09999999999985551\n",
      "75000 13.6 0.09999999999985551\n",
      "75500 8.8 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76000 12.7 0.09999999999985551\n",
      "76500 11.2 0.09999999999985551\n",
      "77000 10.3 0.09999999999985551\n",
      "77500 11.8 0.09999999999985551\n",
      "78000 13.5 0.09999999999985551\n",
      "78500 8.0 0.09999999999985551\n",
      "79000 12.9 0.09999999999985551\n",
      "79500 11.6 0.09999999999985551\n",
      "80000 8.8 0.09999999999985551\n",
      "80500 14.7 0.09999999999985551\n",
      "81000 13.2 0.09999999999985551\n",
      "81500 13.6 0.09999999999985551\n",
      "82000 12.3 0.09999999999985551\n",
      "82500 12.9 0.09999999999985551\n",
      "83000 11.1 0.09999999999985551\n",
      "83500 8.4 0.09999999999985551\n",
      "84000 14.1 0.09999999999985551\n",
      "84500 10.9 0.09999999999985551\n",
      "85000 13.6 0.09999999999985551\n",
      "85500 10.4 0.09999999999985551\n",
      "86000 13.7 0.09999999999985551\n",
      "86500 11.2 0.09999999999985551\n",
      "87000 10.9 0.09999999999985551\n",
      "87500 14.0 0.09999999999985551\n",
      "88000 13.3 0.09999999999985551\n",
      "88500 15.3 0.09999999999985551\n",
      "89000 11.8 0.09999999999985551\n",
      "89500 14.5 0.09999999999985551\n",
      "90000 13.6 0.09999999999985551\n",
      "90500 12.4 0.09999999999985551\n",
      "91000 13.3 0.09999999999985551\n",
      "91500 12.5 0.09999999999985551\n",
      "92000 10.9 0.09999999999985551\n",
      "92500 12.9 0.09999999999985551\n",
      "93000 14.0 0.09999999999985551\n",
      "93500 10.4 0.09999999999985551\n",
      "94000 8.7 0.09999999999985551\n",
      "94500 12.2 0.09999999999985551\n",
      "95000 9.8 0.09999999999985551\n",
      "95500 13.9 0.09999999999985551\n",
      "96000 9.5 0.09999999999985551\n",
      "96500 10.3 0.09999999999985551\n",
      "97000 12.0 0.09999999999985551\n",
      "97500 12.4 0.09999999999985551\n",
      "98000 10.7 0.09999999999985551\n",
      "98500 15.5 0.09999999999985551\n",
      "99000 14.2 0.09999999999985551\n",
      "99500 12.6 0.09999999999985551\n",
      "100000 13.0 0.09999999999985551\n",
      "Saved Model\n",
      "100500 11.5 0.09999999999985551\n",
      "101000 10.9 0.09999999999985551\n",
      "101500 10.0 0.09999999999985551\n",
      "102000 13.5 0.09999999999985551\n",
      "102500 9.4 0.09999999999985551\n",
      "103000 11.3 0.09999999999985551\n",
      "103500 10.1 0.09999999999985551\n",
      "104000 12.4 0.09999999999985551\n",
      "104500 10.5 0.09999999999985551\n",
      "105000 12.6 0.09999999999985551\n",
      "105500 13.4 0.09999999999985551\n",
      "106000 12.7 0.09999999999985551\n",
      "106500 10.8 0.09999999999985551\n",
      "107000 14.5 0.09999999999985551\n",
      "107500 11.6 0.09999999999985551\n",
      "108000 11.0 0.09999999999985551\n",
      "108500 12.1 0.09999999999985551\n",
      "109000 15.2 0.09999999999985551\n",
      "109500 12.0 0.09999999999985551\n",
      "110000 11.5 0.09999999999985551\n",
      "110500 13.9 0.09999999999985551\n",
      "111000 14.5 0.09999999999985551\n",
      "111500 9.8 0.09999999999985551\n",
      "112000 13.3 0.09999999999985551\n",
      "112500 10.7 0.09999999999985551\n",
      "113000 14.5 0.09999999999985551\n",
      "113500 14.2 0.09999999999985551\n",
      "114000 12.3 0.09999999999985551\n",
      "114500 12.6 0.09999999999985551\n",
      "115000 12.5 0.09999999999985551\n",
      "115500 9.7 0.09999999999985551\n",
      "116000 11.5 0.09999999999985551\n",
      "116500 10.2 0.09999999999985551\n",
      "117000 12.4 0.09999999999985551\n",
      "117500 10.3 0.09999999999985551\n",
      "118000 10.7 0.09999999999985551\n",
      "118500 15.5 0.09999999999985551\n",
      "119000 9.6 0.09999999999985551\n",
      "119500 12.3 0.09999999999985551\n",
      "120000 12.1 0.09999999999985551\n",
      "120500 14.5 0.09999999999985551\n",
      "121000 12.4 0.09999999999985551\n",
      "121500 12.0 0.09999999999985551\n",
      "122000 12.1 0.09999999999985551\n",
      "122500 13.7 0.09999999999985551\n",
      "123000 14.6 0.09999999999985551\n",
      "123500 13.9 0.09999999999985551\n",
      "124000 12.5 0.09999999999985551\n",
      "124500 11.3 0.09999999999985551\n",
      "125000 14.0 0.09999999999985551\n",
      "125500 10.8 0.09999999999985551\n",
      "126000 11.0 0.09999999999985551\n",
      "126500 12.3 0.09999999999985551\n",
      "127000 12.7 0.09999999999985551\n",
      "127500 12.9 0.09999999999985551\n",
      "128000 12.2 0.09999999999985551\n",
      "128500 12.0 0.09999999999985551\n",
      "129000 8.9 0.09999999999985551\n",
      "129500 10.0 0.09999999999985551\n",
      "130000 11.1 0.09999999999985551\n",
      "130500 9.5 0.09999999999985551\n",
      "131000 12.2 0.09999999999985551\n",
      "131500 12.2 0.09999999999985551\n",
      "132000 13.4 0.09999999999985551\n",
      "132500 12.7 0.09999999999985551\n",
      "133000 13.5 0.09999999999985551\n",
      "133500 11.7 0.09999999999985551\n",
      "134000 14.3 0.09999999999985551\n",
      "134500 15.8 0.09999999999985551\n",
      "135000 11.2 0.09999999999985551\n",
      "135500 13.3 0.09999999999985551\n",
      "136000 12.5 0.09999999999985551\n",
      "136500 13.5 0.09999999999985551\n",
      "137000 11.4 0.09999999999985551\n",
      "137500 12.4 0.09999999999985551\n",
      "138000 11.6 0.09999999999985551\n",
      "138500 12.7 0.09999999999985551\n",
      "139000 11.5 0.09999999999985551\n",
      "139500 13.1 0.09999999999985551\n",
      "140000 13.9 0.09999999999985551\n",
      "140500 13.2 0.09999999999985551\n",
      "141000 9.8 0.09999999999985551\n",
      "141500 10.6 0.09999999999985551\n",
      "142000 11.0 0.09999999999985551\n",
      "142500 14.1 0.09999999999985551\n",
      "143000 14.3 0.09999999999985551\n",
      "143500 10.4 0.09999999999985551\n",
      "144000 12.5 0.09999999999985551\n",
      "144500 12.6 0.09999999999985551\n",
      "145000 12.9 0.09999999999985551\n",
      "145500 14.4 0.09999999999985551\n",
      "146000 13.3 0.09999999999985551\n",
      "146500 11.4 0.09999999999985551\n",
      "147000 15.1 0.09999999999985551\n",
      "147500 14.7 0.09999999999985551\n",
      "148000 10.4 0.09999999999985551\n",
      "148500 13.5 0.09999999999985551\n",
      "149000 11.8 0.09999999999985551\n",
      "149500 9.3 0.09999999999985551\n",
      "150000 14.3 0.09999999999985551\n",
      "Saved Model\n",
      "150500 12.3 0.09999999999985551\n",
      "151000 13.5 0.09999999999985551\n",
      "151500 10.4 0.09999999999985551\n",
      "152000 11.7 0.09999999999985551\n",
      "152500 16.1 0.09999999999985551\n",
      "153000 11.5 0.09999999999985551\n",
      "153500 13.0 0.09999999999985551\n",
      "154000 13.0 0.09999999999985551\n",
      "154500 12.6 0.09999999999985551\n",
      "155000 12.4 0.09999999999985551\n",
      "155500 12.2 0.09999999999985551\n",
      "156000 11.4 0.09999999999985551\n",
      "156500 5.5 0.09999999999985551\n",
      "157000 13.5 0.09999999999985551\n",
      "157500 12.6 0.09999999999985551\n",
      "158000 12.3 0.09999999999985551\n",
      "158500 12.9 0.09999999999985551\n",
      "159000 13.8 0.09999999999985551\n",
      "159500 10.5 0.09999999999985551\n",
      "160000 11.9 0.09999999999985551\n",
      "160500 14.6 0.09999999999985551\n",
      "161000 10.6 0.09999999999985551\n",
      "161500 12.2 0.09999999999985551\n",
      "162000 13.7 0.09999999999985551\n",
      "162500 12.7 0.09999999999985551\n",
      "163000 11.1 0.09999999999985551\n",
      "163500 12.1 0.09999999999985551\n",
      "164000 10.7 0.09999999999985551\n",
      "164500 12.8 0.09999999999985551\n",
      "165000 11.8 0.09999999999985551\n",
      "165500 10.4 0.09999999999985551\n",
      "166000 15.0 0.09999999999985551\n",
      "166500 11.8 0.09999999999985551\n",
      "167000 13.2 0.09999999999985551\n",
      "167500 9.5 0.09999999999985551\n",
      "168000 10.2 0.09999999999985551\n",
      "168500 13.2 0.09999999999985551\n",
      "169000 12.8 0.09999999999985551\n",
      "169500 11.5 0.09999999999985551\n",
      "170000 13.0 0.09999999999985551\n",
      "170500 14.4 0.09999999999985551\n",
      "171000 11.1 0.09999999999985551\n",
      "171500 15.6 0.09999999999985551\n",
      "172000 10.0 0.09999999999985551\n",
      "172500 15.5 0.09999999999985551\n",
      "173000 12.7 0.09999999999985551\n",
      "173500 12.5 0.09999999999985551\n",
      "174000 13.9 0.09999999999985551\n",
      "174500 11.7 0.09999999999985551\n",
      "175000 12.3 0.09999999999985551\n",
      "175500 12.4 0.09999999999985551\n",
      "176000 12.0 0.09999999999985551\n",
      "176500 13.9 0.09999999999985551\n",
      "177000 16.0 0.09999999999985551\n",
      "177500 10.1 0.09999999999985551\n",
      "178000 11.6 0.09999999999985551\n",
      "178500 12.9 0.09999999999985551\n",
      "179000 13.4 0.09999999999985551\n",
      "179500 12.3 0.09999999999985551\n",
      "180000 11.5 0.09999999999985551\n",
      "180500 14.0 0.09999999999985551\n",
      "181000 13.2 0.09999999999985551\n",
      "181500 13.2 0.09999999999985551\n",
      "182000 12.5 0.09999999999985551\n",
      "182500 14.3 0.09999999999985551\n",
      "183000 14.7 0.09999999999985551\n",
      "183500 12.9 0.09999999999985551\n",
      "184000 13.5 0.09999999999985551\n",
      "184500 11.2 0.09999999999985551\n",
      "185000 11.3 0.09999999999985551\n",
      "185500 9.5 0.09999999999985551\n",
      "186000 14.0 0.09999999999985551\n",
      "186500 11.8 0.09999999999985551\n",
      "187000 14.2 0.09999999999985551\n",
      "187500 15.2 0.09999999999985551\n",
      "188000 12.3 0.09999999999985551\n",
      "188500 13.3 0.09999999999985551\n",
      "189000 13.5 0.09999999999985551\n",
      "189500 9.7 0.09999999999985551\n",
      "190000 10.2 0.09999999999985551\n",
      "190500 9.6 0.09999999999985551\n",
      "191000 13.2 0.09999999999985551\n",
      "191500 10.8 0.09999999999985551\n",
      "192000 14.0 0.09999999999985551\n",
      "192500 11.2 0.09999999999985551\n",
      "193000 10.1 0.09999999999985551\n",
      "193500 10.8 0.09999999999985551\n",
      "194000 10.7 0.09999999999985551\n",
      "194500 11.7 0.09999999999985551\n",
      "195000 14.0 0.09999999999985551\n",
      "195500 11.2 0.09999999999985551\n",
      "196000 14.5 0.09999999999985551\n",
      "196500 10.2 0.09999999999985551\n",
      "197000 11.6 0.09999999999985551\n",
      "197500 13.0 0.09999999999985551\n",
      "198000 13.1 0.09999999999985551\n",
      "198500 11.0 0.09999999999985551\n",
      "199000 12.3 0.09999999999985551\n",
      "199500 10.8 0.09999999999985551\n",
      "200000 12.2 0.09999999999985551\n",
      "Saved Model\n",
      "200500 13.7 0.09999999999985551\n",
      "201000 11.0 0.09999999999985551\n",
      "201500 12.9 0.09999999999985551\n",
      "202000 12.2 0.09999999999985551\n",
      "202500 12.3 0.09999999999985551\n",
      "203000 12.3 0.09999999999985551\n",
      "203500 12.0 0.09999999999985551\n",
      "204000 14.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204500 13.0 0.09999999999985551\n",
      "205000 15.5 0.09999999999985551\n",
      "205500 13.3 0.09999999999985551\n",
      "206000 8.6 0.09999999999985551\n",
      "206500 12.9 0.09999999999985551\n",
      "207000 13.1 0.09999999999985551\n",
      "207500 10.3 0.09999999999985551\n",
      "208000 12.6 0.09999999999985551\n",
      "208500 13.3 0.09999999999985551\n",
      "209000 11.0 0.09999999999985551\n",
      "209500 13.3 0.09999999999985551\n",
      "210000 9.9 0.09999999999985551\n",
      "210500 10.0 0.09999999999985551\n",
      "211000 13.7 0.09999999999985551\n",
      "211500 13.9 0.09999999999985551\n",
      "212000 14.4 0.09999999999985551\n",
      "212500 11.7 0.09999999999985551\n",
      "213000 12.1 0.09999999999985551\n",
      "213500 14.1 0.09999999999985551\n",
      "214000 12.8 0.09999999999985551\n",
      "214500 16.5 0.09999999999985551\n",
      "215000 11.5 0.09999999999985551\n",
      "215500 11.1 0.09999999999985551\n",
      "216000 12.2 0.09999999999985551\n",
      "216500 10.5 0.09999999999985551\n",
      "217000 13.5 0.09999999999985551\n",
      "217500 10.1 0.09999999999985551\n",
      "218000 13.1 0.09999999999985551\n",
      "218500 8.4 0.09999999999985551\n",
      "219000 12.1 0.09999999999985551\n",
      "219500 10.9 0.09999999999985551\n",
      "220000 9.8 0.09999999999985551\n",
      "220500 12.1 0.09999999999985551\n",
      "221000 11.2 0.09999999999985551\n",
      "221500 12.1 0.09999999999985551\n",
      "222000 11.3 0.09999999999985551\n",
      "222500 10.0 0.09999999999985551\n",
      "223000 10.7 0.09999999999985551\n",
      "223500 12.3 0.09999999999985551\n",
      "224000 10.7 0.09999999999985551\n",
      "224500 14.2 0.09999999999985551\n",
      "225000 14.1 0.09999999999985551\n",
      "225500 10.5 0.09999999999985551\n",
      "226000 12.6 0.09999999999985551\n",
      "226500 11.8 0.09999999999985551\n",
      "227000 11.5 0.09999999999985551\n",
      "227500 10.6 0.09999999999985551\n",
      "228000 13.0 0.09999999999985551\n",
      "228500 12.3 0.09999999999985551\n",
      "229000 13.5 0.09999999999985551\n",
      "229500 15.6 0.09999999999985551\n",
      "230000 9.9 0.09999999999985551\n",
      "230500 15.2 0.09999999999985551\n",
      "231000 11.3 0.09999999999985551\n",
      "231500 12.3 0.09999999999985551\n",
      "232000 13.7 0.09999999999985551\n",
      "232500 10.8 0.09999999999985551\n",
      "233000 12.0 0.09999999999985551\n",
      "233500 13.7 0.09999999999985551\n",
      "234000 10.5 0.09999999999985551\n",
      "234500 13.8 0.09999999999985551\n",
      "235000 11.9 0.09999999999985551\n",
      "235500 8.3 0.09999999999985551\n",
      "236000 15.3 0.09999999999985551\n",
      "236500 14.4 0.09999999999985551\n",
      "237000 13.1 0.09999999999985551\n",
      "237500 12.2 0.09999999999985551\n",
      "238000 12.3 0.09999999999985551\n",
      "238500 13.4 0.09999999999985551\n",
      "239000 13.1 0.09999999999985551\n",
      "239500 12.5 0.09999999999985551\n",
      "240000 14.6 0.09999999999985551\n",
      "240500 11.6 0.09999999999985551\n",
      "241000 8.8 0.09999999999985551\n",
      "241500 11.1 0.09999999999985551\n",
      "242000 11.3 0.09999999999985551\n",
      "242500 12.4 0.09999999999985551\n",
      "243000 13.7 0.09999999999985551\n",
      "243500 10.8 0.09999999999985551\n",
      "244000 11.8 0.09999999999985551\n",
      "244500 11.6 0.09999999999985551\n",
      "245000 12.7 0.09999999999985551\n",
      "245500 13.3 0.09999999999985551\n",
      "246000 9.6 0.09999999999985551\n",
      "246500 14.8 0.09999999999985551\n",
      "247000 13.3 0.09999999999985551\n",
      "247500 15.0 0.09999999999985551\n",
      "248000 12.8 0.09999999999985551\n",
      "248500 10.7 0.09999999999985551\n",
      "249000 8.9 0.09999999999985551\n",
      "249500 14.1 0.09999999999985551\n",
      "250000 13.5 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 14.4 0.09999999999985551\n",
      "251000 11.1 0.09999999999985551\n",
      "251500 7.4 0.09999999999985551\n",
      "252000 11.3 0.09999999999985551\n",
      "252500 16.0 0.09999999999985551\n",
      "253000 13.9 0.09999999999985551\n",
      "253500 15.6 0.09999999999985551\n",
      "254000 15.1 0.09999999999985551\n",
      "254500 13.4 0.09999999999985551\n",
      "255000 11.9 0.09999999999985551\n",
      "255500 11.0 0.09999999999985551\n",
      "256000 14.5 0.09999999999985551\n",
      "256500 9.2 0.09999999999985551\n",
      "257000 8.2 0.09999999999985551\n",
      "257500 15.8 0.09999999999985551\n",
      "258000 13.9 0.09999999999985551\n",
      "258500 12.9 0.09999999999985551\n",
      "259000 9.0 0.09999999999985551\n",
      "259500 9.9 0.09999999999985551\n",
      "260000 11.2 0.09999999999985551\n",
      "260500 11.6 0.09999999999985551\n",
      "261000 13.1 0.09999999999985551\n",
      "261500 11.0 0.09999999999985551\n",
      "262000 13.8 0.09999999999985551\n",
      "262500 14.9 0.09999999999985551\n",
      "263000 13.4 0.09999999999985551\n",
      "263500 12.0 0.09999999999985551\n",
      "264000 10.7 0.09999999999985551\n",
      "264500 13.0 0.09999999999985551\n",
      "265000 12.4 0.09999999999985551\n",
      "265500 12.9 0.09999999999985551\n",
      "266000 15.1 0.09999999999985551\n",
      "266500 12.7 0.09999999999985551\n",
      "267000 11.6 0.09999999999985551\n",
      "267500 9.3 0.09999999999985551\n",
      "268000 13.5 0.09999999999985551\n",
      "268500 11.8 0.09999999999985551\n",
      "269000 15.0 0.09999999999985551\n",
      "269500 13.0 0.09999999999985551\n",
      "270000 12.6 0.09999999999985551\n",
      "270500 13.2 0.09999999999985551\n",
      "271000 9.9 0.09999999999985551\n",
      "271500 12.7 0.09999999999985551\n",
      "272000 12.2 0.09999999999985551\n",
      "272500 10.4 0.09999999999985551\n",
      "273000 13.3 0.09999999999985551\n",
      "273500 12.4 0.09999999999985551\n",
      "274000 11.3 0.09999999999985551\n",
      "274500 13.9 0.09999999999985551\n",
      "275000 12.2 0.09999999999985551\n",
      "275500 13.5 0.09999999999985551\n",
      "276000 11.3 0.09999999999985551\n",
      "276500 10.6 0.09999999999985551\n",
      "277000 13.0 0.09999999999985551\n",
      "277500 12.8 0.09999999999985551\n",
      "278000 16.4 0.09999999999985551\n",
      "278500 14.0 0.09999999999985551\n",
      "279000 9.1 0.09999999999985551\n",
      "279500 11.1 0.09999999999985551\n",
      "280000 14.8 0.09999999999985551\n",
      "280500 10.5 0.09999999999985551\n",
      "281000 12.8 0.09999999999985551\n",
      "281500 13.6 0.09999999999985551\n",
      "282000 14.3 0.09999999999985551\n",
      "282500 11.3 0.09999999999985551\n",
      "283000 11.9 0.09999999999985551\n",
      "283500 13.2 0.09999999999985551\n",
      "284000 12.2 0.09999999999985551\n",
      "284500 10.6 0.09999999999985551\n",
      "285000 12.8 0.09999999999985551\n",
      "285500 11.8 0.09999999999985551\n",
      "286000 12.5 0.09999999999985551\n",
      "286500 13.7 0.09999999999985551\n",
      "287000 16.4 0.09999999999985551\n",
      "287500 8.8 0.09999999999985551\n",
      "288000 14.3 0.09999999999985551\n",
      "288500 11.0 0.09999999999985551\n",
      "289000 9.1 0.09999999999985551\n",
      "289500 13.7 0.09999999999985551\n",
      "290000 10.2 0.09999999999985551\n",
      "290500 16.6 0.09999999999985551\n",
      "291000 11.1 0.09999999999985551\n",
      "291500 9.8 0.09999999999985551\n",
      "292000 9.8 0.09999999999985551\n",
      "292500 10.1 0.09999999999985551\n",
      "293000 16.0 0.09999999999985551\n",
      "293500 10.8 0.09999999999985551\n",
      "294000 11.0 0.09999999999985551\n",
      "294500 14.0 0.09999999999985551\n",
      "295000 13.0 0.09999999999985551\n",
      "295500 15.3 0.09999999999985551\n",
      "296000 16.6 0.09999999999985551\n",
      "296500 12.3 0.09999999999985551\n",
      "297000 13.6 0.09999999999985551\n",
      "297500 10.9 0.09999999999985551\n",
      "298000 13.3 0.09999999999985551\n",
      "298500 10.6 0.09999999999985551\n",
      "299000 16.2 0.09999999999985551\n",
      "299500 10.5 0.09999999999985551\n",
      "300000 15.3 0.09999999999985551\n",
      "Saved Model\n",
      "300500 12.2 0.09999999999985551\n",
      "301000 13.3 0.09999999999985551\n",
      "301500 13.6 0.09999999999985551\n",
      "302000 12.1 0.09999999999985551\n",
      "302500 10.8 0.09999999999985551\n",
      "303000 13.8 0.09999999999985551\n",
      "303500 13.0 0.09999999999985551\n",
      "304000 14.8 0.09999999999985551\n",
      "304500 11.4 0.09999999999985551\n",
      "305000 13.7 0.09999999999985551\n",
      "305500 10.9 0.09999999999985551\n",
      "306000 14.8 0.09999999999985551\n",
      "306500 11.5 0.09999999999985551\n",
      "307000 12.9 0.09999999999985551\n",
      "307500 14.8 0.09999999999985551\n",
      "308000 9.7 0.09999999999985551\n",
      "308500 15.6 0.09999999999985551\n",
      "309000 13.3 0.09999999999985551\n",
      "309500 10.3 0.09999999999985551\n",
      "310000 7.0 0.09999999999985551\n",
      "310500 12.6 0.09999999999985551\n",
      "311000 11.0 0.09999999999985551\n",
      "311500 14.8 0.09999999999985551\n",
      "312000 11.0 0.09999999999985551\n",
      "312500 13.7 0.09999999999985551\n",
      "313000 15.2 0.09999999999985551\n",
      "313500 15.6 0.09999999999985551\n",
      "314000 14.7 0.09999999999985551\n",
      "314500 12.1 0.09999999999985551\n",
      "315000 16.6 0.09999999999985551\n",
      "315500 17.4 0.09999999999985551\n",
      "316000 16.1 0.09999999999985551\n",
      "316500 12.2 0.09999999999985551\n",
      "317000 9.4 0.09999999999985551\n",
      "317500 10.8 0.09999999999985551\n",
      "318000 12.4 0.09999999999985551\n",
      "318500 11.4 0.09999999999985551\n",
      "319000 9.9 0.09999999999985551\n",
      "319500 12.3 0.09999999999985551\n",
      "320000 15.8 0.09999999999985551\n",
      "320500 10.1 0.09999999999985551\n",
      "321000 13.0 0.09999999999985551\n",
      "321500 11.1 0.09999999999985551\n",
      "322000 10.3 0.09999999999985551\n",
      "322500 10.6 0.09999999999985551\n",
      "323000 11.3 0.09999999999985551\n",
      "323500 11.4 0.09999999999985551\n",
      "324000 15.5 0.09999999999985551\n",
      "324500 9.2 0.09999999999985551\n",
      "325000 12.6 0.09999999999985551\n",
      "325500 13.1 0.09999999999985551\n",
      "326000 14.3 0.09999999999985551\n",
      "326500 10.7 0.09999999999985551\n",
      "327000 11.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327500 10.8 0.09999999999985551\n",
      "328000 11.7 0.09999999999985551\n",
      "328500 9.3 0.09999999999985551\n",
      "329000 12.8 0.09999999999985551\n",
      "329500 11.8 0.09999999999985551\n",
      "330000 13.6 0.09999999999985551\n",
      "330500 13.6 0.09999999999985551\n",
      "331000 16.1 0.09999999999985551\n",
      "331500 15.8 0.09999999999985551\n",
      "332000 17.1 0.09999999999985551\n",
      "332500 15.1 0.09999999999985551\n",
      "333000 14.5 0.09999999999985551\n",
      "333500 13.4 0.09999999999985551\n",
      "334000 11.7 0.09999999999985551\n",
      "334500 13.8 0.09999999999985551\n",
      "335000 16.2 0.09999999999985551\n",
      "335500 12.9 0.09999999999985551\n",
      "336000 15.4 0.09999999999985551\n",
      "336500 11.4 0.09999999999985551\n",
      "337000 10.8 0.09999999999985551\n",
      "337500 13.5 0.09999999999985551\n",
      "338000 16.2 0.09999999999985551\n",
      "338500 12.1 0.09999999999985551\n",
      "339000 9.7 0.09999999999985551\n",
      "339500 12.7 0.09999999999985551\n",
      "340000 13.5 0.09999999999985551\n",
      "340500 11.6 0.09999999999985551\n",
      "341000 11.1 0.09999999999985551\n",
      "341500 11.9 0.09999999999985551\n",
      "342000 14.5 0.09999999999985551\n",
      "342500 14.0 0.09999999999985551\n",
      "343000 10.7 0.09999999999985551\n",
      "343500 13.5 0.09999999999985551\n",
      "344000 13.2 0.09999999999985551\n",
      "344500 13.6 0.09999999999985551\n",
      "345000 10.3 0.09999999999985551\n",
      "345500 11.0 0.09999999999985551\n",
      "346000 13.8 0.09999999999985551\n",
      "346500 9.8 0.09999999999985551\n",
      "347000 12.9 0.09999999999985551\n",
      "347500 10.9 0.09999999999985551\n",
      "348000 12.9 0.09999999999985551\n",
      "348500 9.1 0.09999999999985551\n",
      "349000 16.9 0.09999999999985551\n",
      "349500 11.7 0.09999999999985551\n",
      "350000 14.9 0.09999999999985551\n",
      "Saved Model\n",
      "350500 11.9 0.09999999999985551\n",
      "351000 12.9 0.09999999999985551\n",
      "351500 14.1 0.09999999999985551\n",
      "352000 10.5 0.09999999999985551\n",
      "352500 11.1 0.09999999999985551\n",
      "353000 11.7 0.09999999999985551\n",
      "353500 14.5 0.09999999999985551\n",
      "354000 14.4 0.09999999999985551\n",
      "354500 13.0 0.09999999999985551\n",
      "355000 11.6 0.09999999999985551\n",
      "355500 10.9 0.09999999999985551\n",
      "356000 11.0 0.09999999999985551\n",
      "356500 12.8 0.09999999999985551\n",
      "357000 11.6 0.09999999999985551\n",
      "357500 15.2 0.09999999999985551\n",
      "358000 13.8 0.09999999999985551\n",
      "358500 12.8 0.09999999999985551\n",
      "359000 10.4 0.09999999999985551\n",
      "359500 13.7 0.09999999999985551\n",
      "360000 10.0 0.09999999999985551\n",
      "360500 12.6 0.09999999999985551\n",
      "361000 14.4 0.09999999999985551\n",
      "361500 13.9 0.09999999999985551\n",
      "362000 10.9 0.09999999999985551\n",
      "362500 12.7 0.09999999999985551\n",
      "363000 14.0 0.09999999999985551\n",
      "363500 11.1 0.09999999999985551\n",
      "364000 15.0 0.09999999999985551\n",
      "364500 11.8 0.09999999999985551\n",
      "365000 12.6 0.09999999999985551\n",
      "365500 15.0 0.09999999999985551\n",
      "366000 9.0 0.09999999999985551\n",
      "366500 13.3 0.09999999999985551\n",
      "367000 10.1 0.09999999999985551\n",
      "367500 12.4 0.09999999999985551\n",
      "368000 13.4 0.09999999999985551\n",
      "368500 9.8 0.09999999999985551\n",
      "369000 13.6 0.09999999999985551\n",
      "369500 14.8 0.09999999999985551\n",
      "370000 14.7 0.09999999999985551\n",
      "370500 9.7 0.09999999999985551\n",
      "371000 14.6 0.09999999999985551\n",
      "371500 10.3 0.09999999999985551\n",
      "372000 10.5 0.09999999999985551\n",
      "372500 11.2 0.09999999999985551\n",
      "373000 9.6 0.09999999999985551\n",
      "373500 13.2 0.09999999999985551\n",
      "374000 10.1 0.09999999999985551\n",
      "374500 14.0 0.09999999999985551\n",
      "375000 12.5 0.09999999999985551\n",
      "375500 12.1 0.09999999999985551\n",
      "376000 12.2 0.09999999999985551\n",
      "376500 16.4 0.09999999999985551\n",
      "377000 13.2 0.09999999999985551\n",
      "377500 14.9 0.09999999999985551\n",
      "378000 12.1 0.09999999999985551\n",
      "378500 9.7 0.09999999999985551\n",
      "379000 15.8 0.09999999999985551\n",
      "379500 11.0 0.09999999999985551\n",
      "380000 14.6 0.09999999999985551\n",
      "380500 14.0 0.09999999999985551\n",
      "381000 11.1 0.09999999999985551\n",
      "381500 14.7 0.09999999999985551\n",
      "382000 13.7 0.09999999999985551\n",
      "382500 13.7 0.09999999999985551\n",
      "383000 15.7 0.09999999999985551\n",
      "383500 10.8 0.09999999999985551\n",
      "384000 14.9 0.09999999999985551\n",
      "384500 15.1 0.09999999999985551\n",
      "385000 10.1 0.09999999999985551\n",
      "385500 14.2 0.09999999999985551\n",
      "386000 13.3 0.09999999999985551\n",
      "386500 12.3 0.09999999999985551\n",
      "387000 12.4 0.09999999999985551\n",
      "387500 11.4 0.09999999999985551\n",
      "388000 15.4 0.09999999999985551\n",
      "388500 14.7 0.09999999999985551\n",
      "389000 11.3 0.09999999999985551\n",
      "389500 14.5 0.09999999999985551\n",
      "390000 11.6 0.09999999999985551\n",
      "390500 12.1 0.09999999999985551\n",
      "391000 15.0 0.09999999999985551\n",
      "391500 14.5 0.09999999999985551\n",
      "392000 15.6 0.09999999999985551\n",
      "392500 13.3 0.09999999999985551\n",
      "393000 11.4 0.09999999999985551\n",
      "393500 13.5 0.09999999999985551\n",
      "394000 13.4 0.09999999999985551\n",
      "394500 12.8 0.09999999999985551\n",
      "395000 13.6 0.09999999999985551\n",
      "395500 11.9 0.09999999999985551\n",
      "396000 12.5 0.09999999999985551\n",
      "396500 13.3 0.09999999999985551\n",
      "397000 15.7 0.09999999999985551\n",
      "397500 13.1 0.09999999999985551\n",
      "398000 12.5 0.09999999999985551\n",
      "398500 15.4 0.09999999999985551\n",
      "399000 11.2 0.09999999999985551\n",
      "399500 15.2 0.09999999999985551\n",
      "400000 15.5 0.09999999999985551\n",
      "Saved Model\n",
      "400500 14.3 0.09999999999985551\n",
      "401000 16.1 0.09999999999985551\n",
      "401500 13.5 0.09999999999985551\n",
      "402000 13.6 0.09999999999985551\n",
      "402500 15.2 0.09999999999985551\n",
      "403000 12.8 0.09999999999985551\n",
      "403500 14.2 0.09999999999985551\n",
      "404000 13.6 0.09999999999985551\n",
      "404500 14.5 0.09999999999985551\n",
      "405000 10.9 0.09999999999985551\n",
      "405500 13.9 0.09999999999985551\n",
      "406000 14.1 0.09999999999985551\n",
      "406500 10.8 0.09999999999985551\n",
      "407000 10.0 0.09999999999985551\n",
      "407500 13.5 0.09999999999985551\n",
      "408000 12.7 0.09999999999985551\n",
      "408500 12.0 0.09999999999985551\n",
      "409000 12.4 0.09999999999985551\n",
      "409500 10.8 0.09999999999985551\n",
      "410000 12.3 0.09999999999985551\n",
      "410500 11.8 0.09999999999985551\n",
      "411000 11.5 0.09999999999985551\n",
      "411500 15.2 0.09999999999985551\n",
      "412000 11.5 0.09999999999985551\n",
      "412500 13.5 0.09999999999985551\n",
      "413000 10.8 0.09999999999985551\n",
      "413500 12.7 0.09999999999985551\n",
      "414000 11.6 0.09999999999985551\n",
      "414500 11.7 0.09999999999985551\n",
      "415000 12.0 0.09999999999985551\n",
      "415500 13.5 0.09999999999985551\n",
      "416000 13.5 0.09999999999985551\n",
      "416500 16.3 0.09999999999985551\n",
      "417000 13.9 0.09999999999985551\n",
      "417500 11.8 0.09999999999985551\n",
      "418000 13.7 0.09999999999985551\n",
      "418500 13.8 0.09999999999985551\n",
      "419000 13.0 0.09999999999985551\n",
      "419500 10.8 0.09999999999985551\n",
      "420000 13.6 0.09999999999985551\n",
      "420500 13.0 0.09999999999985551\n",
      "421000 13.0 0.09999999999985551\n",
      "421500 13.8 0.09999999999985551\n",
      "422000 11.7 0.09999999999985551\n",
      "422500 12.1 0.09999999999985551\n",
      "423000 14.3 0.09999999999985551\n",
      "423500 10.6 0.09999999999985551\n",
      "424000 11.2 0.09999999999985551\n",
      "424500 11.0 0.09999999999985551\n",
      "425000 10.7 0.09999999999985551\n",
      "425500 12.8 0.09999999999985551\n",
      "426000 11.5 0.09999999999985551\n",
      "426500 14.7 0.09999999999985551\n",
      "427000 14.1 0.09999999999985551\n",
      "427500 13.8 0.09999999999985551\n",
      "428000 13.6 0.09999999999985551\n",
      "428500 14.2 0.09999999999985551\n",
      "429000 10.0 0.09999999999985551\n",
      "429500 14.7 0.09999999999985551\n",
      "430000 14.9 0.09999999999985551\n",
      "430500 16.3 0.09999999999985551\n",
      "431000 10.7 0.09999999999985551\n",
      "431500 11.2 0.09999999999985551\n",
      "432000 14.5 0.09999999999985551\n",
      "432500 13.3 0.09999999999985551\n",
      "433000 13.1 0.09999999999985551\n",
      "433500 13.6 0.09999999999985551\n",
      "434000 9.2 0.09999999999985551\n",
      "434500 17.2 0.09999999999985551\n",
      "435000 15.6 0.09999999999985551\n",
      "435500 13.0 0.09999999999985551\n",
      "436000 11.7 0.09999999999985551\n",
      "436500 11.3 0.09999999999985551\n",
      "437000 12.3 0.09999999999985551\n",
      "437500 11.9 0.09999999999985551\n",
      "438000 9.8 0.09999999999985551\n",
      "438500 13.5 0.09999999999985551\n",
      "439000 10.2 0.09999999999985551\n",
      "439500 12.6 0.09999999999985551\n",
      "440000 13.1 0.09999999999985551\n",
      "440500 12.0 0.09999999999985551\n",
      "441000 11.3 0.09999999999985551\n",
      "441500 12.9 0.09999999999985551\n",
      "442000 12.1 0.09999999999985551\n",
      "442500 14.6 0.09999999999985551\n",
      "443000 13.0 0.09999999999985551\n",
      "443500 12.1 0.09999999999985551\n",
      "444000 15.6 0.09999999999985551\n",
      "444500 14.4 0.09999999999985551\n",
      "445000 11.3 0.09999999999985551\n",
      "445500 12.3 0.09999999999985551\n",
      "446000 12.5 0.09999999999985551\n",
      "446500 12.7 0.09999999999985551\n",
      "447000 11.1 0.09999999999985551\n",
      "447500 14.4 0.09999999999985551\n",
      "448000 13.5 0.09999999999985551\n",
      "448500 13.7 0.09999999999985551\n",
      "449000 14.1 0.09999999999985551\n",
      "449500 9.8 0.09999999999985551\n",
      "450000 12.3 0.09999999999985551\n",
      "Saved Model\n",
      "450500 11.0 0.09999999999985551\n",
      "451000 17.7 0.09999999999985551\n",
      "451500 12.2 0.09999999999985551\n",
      "452000 11.9 0.09999999999985551\n",
      "452500 11.8 0.09999999999985551\n",
      "453000 11.8 0.09999999999985551\n",
      "453500 12.5 0.09999999999985551\n",
      "454000 12.2 0.09999999999985551\n",
      "454500 9.8 0.09999999999985551\n",
      "455000 11.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455500 15.8 0.09999999999985551\n",
      "456000 12.6 0.09999999999985551\n",
      "456500 11.7 0.09999999999985551\n",
      "457000 12.2 0.09999999999985551\n",
      "457500 11.2 0.09999999999985551\n",
      "458000 13.4 0.09999999999985551\n",
      "458500 15.0 0.09999999999985551\n",
      "459000 11.5 0.09999999999985551\n",
      "459500 11.4 0.09999999999985551\n",
      "460000 13.3 0.09999999999985551\n",
      "460500 12.7 0.09999999999985551\n",
      "461000 11.7 0.09999999999985551\n",
      "461500 13.7 0.09999999999985551\n",
      "462000 11.4 0.09999999999985551\n",
      "462500 9.7 0.09999999999985551\n",
      "463000 11.5 0.09999999999985551\n",
      "463500 12.3 0.09999999999985551\n",
      "464000 12.4 0.09999999999985551\n",
      "464500 15.8 0.09999999999985551\n",
      "465000 15.0 0.09999999999985551\n",
      "465500 15.1 0.09999999999985551\n",
      "466000 14.0 0.09999999999985551\n",
      "466500 13.3 0.09999999999985551\n",
      "467000 15.5 0.09999999999985551\n",
      "467500 14.7 0.09999999999985551\n",
      "468000 12.4 0.09999999999985551\n",
      "468500 13.5 0.09999999999985551\n",
      "469000 14.4 0.09999999999985551\n",
      "469500 14.8 0.09999999999985551\n",
      "470000 15.4 0.09999999999985551\n",
      "470500 14.2 0.09999999999985551\n",
      "471000 14.8 0.09999999999985551\n",
      "471500 11.3 0.09999999999985551\n",
      "472000 9.2 0.09999999999985551\n",
      "472500 10.1 0.09999999999985551\n",
      "473000 11.3 0.09999999999985551\n",
      "473500 12.0 0.09999999999985551\n",
      "474000 11.7 0.09999999999985551\n",
      "474500 15.0 0.09999999999985551\n",
      "475000 13.8 0.09999999999985551\n",
      "475500 15.2 0.09999999999985551\n",
      "476000 9.9 0.09999999999985551\n",
      "476500 14.0 0.09999999999985551\n",
      "477000 14.4 0.09999999999985551\n",
      "477500 11.6 0.09999999999985551\n",
      "478000 14.3 0.09999999999985551\n",
      "478500 13.1 0.09999999999985551\n",
      "479000 14.4 0.09999999999985551\n",
      "479500 14.3 0.09999999999985551\n",
      "480000 14.1 0.09999999999985551\n",
      "480500 11.7 0.09999999999985551\n",
      "481000 13.0 0.09999999999985551\n",
      "481500 13.6 0.09999999999985551\n",
      "482000 15.3 0.09999999999985551\n",
      "482500 12.5 0.09999999999985551\n",
      "483000 13.3 0.09999999999985551\n",
      "483500 14.1 0.09999999999985551\n",
      "484000 10.6 0.09999999999985551\n",
      "484500 15.8 0.09999999999985551\n",
      "485000 13.2 0.09999999999985551\n",
      "485500 9.9 0.09999999999985551\n",
      "486000 11.7 0.09999999999985551\n",
      "486500 14.7 0.09999999999985551\n",
      "487000 13.6 0.09999999999985551\n",
      "487500 14.5 0.09999999999985551\n",
      "488000 12.1 0.09999999999985551\n",
      "488500 10.1 0.09999999999985551\n",
      "489000 12.2 0.09999999999985551\n",
      "489500 14.3 0.09999999999985551\n",
      "490000 12.0 0.09999999999985551\n",
      "490500 11.9 0.09999999999985551\n",
      "491000 12.0 0.09999999999985551\n",
      "491500 13.7 0.09999999999985551\n",
      "492000 14.9 0.09999999999985551\n",
      "492500 11.4 0.09999999999985551\n",
      "493000 12.6 0.09999999999985551\n",
      "493500 11.8 0.09999999999985551\n",
      "494000 13.4 0.09999999999985551\n",
      "494500 13.1 0.09999999999985551\n",
      "495000 14.4 0.09999999999985551\n",
      "495500 12.1 0.09999999999985551\n",
      "496000 14.9 0.09999999999985551\n",
      "496500 15.6 0.09999999999985551\n",
      "497000 12.8 0.09999999999985551\n",
      "497500 14.8 0.09999999999985551\n",
      "498000 12.4 0.09999999999985551\n",
      "498500 10.0 0.09999999999985551\n",
      "499000 12.5 0.09999999999985551\n",
      "499500 11.7 0.09999999999985551\n",
      "500000 15.4 0.09999999999985551\n",
      "Percent of succesful episodes: 12.0777%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb343575a90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

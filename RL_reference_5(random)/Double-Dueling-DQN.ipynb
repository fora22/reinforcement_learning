{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45dd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45dd30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45dd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45dd30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbc45d978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbc987eb8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbba48080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbba48080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbba48080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbba48080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90dda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90d860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90d860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90d860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90d860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90da20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90da20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90da20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f7cbb90da20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90db00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90db00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90db00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90db00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90dda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90dda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f7cbb90dda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 -1.0 1\n",
      "1000 -1.9 1\n",
      "1500 -0.2 1\n",
      "2000 0.1 1\n",
      "2500 0.8 1\n",
      "3000 1.9 1\n",
      "3500 0.5 1\n",
      "4000 0.0 1\n",
      "4500 0.4 1\n",
      "5000 0.4 1\n",
      "5500 0.0 1\n",
      "6000 -0.1 1\n",
      "6500 0.3 1\n",
      "7000 0.3 1\n",
      "7500 -0.7 1\n",
      "8000 0.1 1\n",
      "8500 1.1 1\n",
      "9000 0.2 1\n",
      "9500 -1.3 1\n",
      "10000 -0.5 1\n",
      "10500 0.4 0.9549999999999828\n",
      "11000 -1.0 0.9099999999999655\n",
      "11500 -0.3 0.8649999999999483\n",
      "12000 0.4 0.819999999999931\n",
      "12500 -0.1 0.7749999999999138\n",
      "13000 0.0 0.7299999999998965\n",
      "13500 -0.5 0.6849999999998793\n",
      "14000 0.4 0.639999999999862\n",
      "14500 0.5 0.5949999999998448\n",
      "15000 0.6 0.5499999999998275\n",
      "15500 0.5 0.5049999999998103\n",
      "16000 1.0 0.4599999999998177\n",
      "16500 0.6 0.41499999999982823\n",
      "17000 -0.2 0.36999999999983874\n",
      "17500 0.3 0.32499999999984924\n",
      "18000 -0.8 0.27999999999985975\n",
      "18500 -0.1 0.23499999999986562\n",
      "19000 0.2 0.18999999999986225\n",
      "19500 0.5 0.14499999999985888\n",
      "20000 -1.0 0.09999999999985551\n",
      "20500 -0.7 0.09999999999985551\n",
      "21000 -0.2 0.09999999999985551\n",
      "21500 -0.2 0.09999999999985551\n",
      "22000 0.1 0.09999999999985551\n",
      "22500 -0.2 0.09999999999985551\n",
      "23000 0.1 0.09999999999985551\n",
      "23500 0.2 0.09999999999985551\n",
      "24000 -0.3 0.09999999999985551\n",
      "24500 0.1 0.09999999999985551\n",
      "25000 0.2 0.09999999999985551\n",
      "25500 0.0 0.09999999999985551\n",
      "26000 0.6 0.09999999999985551\n",
      "26500 0.4 0.09999999999985551\n",
      "27000 0.3 0.09999999999985551\n",
      "27500 -0.2 0.09999999999985551\n",
      "28000 0.0 0.09999999999985551\n",
      "28500 0.3 0.09999999999985551\n",
      "29000 0.6 0.09999999999985551\n",
      "29500 -0.5 0.09999999999985551\n",
      "30000 0.1 0.09999999999985551\n",
      "30500 0.3 0.09999999999985551\n",
      "31000 0.5 0.09999999999985551\n",
      "31500 0.6 0.09999999999985551\n",
      "32000 0.6 0.09999999999985551\n",
      "32500 0.4 0.09999999999985551\n",
      "33000 0.9 0.09999999999985551\n",
      "33500 0.4 0.09999999999985551\n",
      "34000 0.4 0.09999999999985551\n",
      "34500 0.0 0.09999999999985551\n",
      "35000 0.2 0.09999999999985551\n",
      "35500 0.7 0.09999999999985551\n",
      "36000 0.8 0.09999999999985551\n",
      "36500 0.7 0.09999999999985551\n",
      "37000 0.4 0.09999999999985551\n",
      "37500 0.1 0.09999999999985551\n",
      "38000 1.0 0.09999999999985551\n",
      "38500 0.1 0.09999999999985551\n",
      "39000 0.5 0.09999999999985551\n",
      "39500 1.1 0.09999999999985551\n",
      "40000 -0.1 0.09999999999985551\n",
      "40500 0.7 0.09999999999985551\n",
      "41000 0.8 0.09999999999985551\n",
      "41500 0.7 0.09999999999985551\n",
      "42000 1.0 0.09999999999985551\n",
      "42500 0.2 0.09999999999985551\n",
      "43000 0.2 0.09999999999985551\n",
      "43500 0.6 0.09999999999985551\n",
      "44000 0.5 0.09999999999985551\n",
      "44500 0.7 0.09999999999985551\n",
      "45000 0.5 0.09999999999985551\n",
      "45500 0.7 0.09999999999985551\n",
      "46000 0.7 0.09999999999985551\n",
      "46500 0.0 0.09999999999985551\n",
      "47000 0.5 0.09999999999985551\n",
      "47500 0.3 0.09999999999985551\n",
      "48000 0.8 0.09999999999985551\n",
      "48500 0.6 0.09999999999985551\n",
      "49000 0.3 0.09999999999985551\n",
      "49500 0.3 0.09999999999985551\n",
      "50000 1.0 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.8 0.09999999999985551\n",
      "51000 0.5 0.09999999999985551\n",
      "51500 1.0 0.09999999999985551\n",
      "52000 0.3 0.09999999999985551\n",
      "52500 0.0 0.09999999999985551\n",
      "53000 1.3 0.09999999999985551\n",
      "53500 0.3 0.09999999999985551\n",
      "54000 0.0 0.09999999999985551\n",
      "54500 1.1 0.09999999999985551\n",
      "55000 0.1 0.09999999999985551\n",
      "55500 0.6 0.09999999999985551\n",
      "56000 0.3 0.09999999999985551\n",
      "56500 1.2 0.09999999999985551\n",
      "57000 0.4 0.09999999999985551\n",
      "57500 2.3 0.09999999999985551\n",
      "58000 1.8 0.09999999999985551\n",
      "58500 1.6 0.09999999999985551\n",
      "59000 0.8 0.09999999999985551\n",
      "59500 1.3 0.09999999999985551\n",
      "60000 0.6 0.09999999999985551\n",
      "60500 2.0 0.09999999999985551\n",
      "61000 2.0 0.09999999999985551\n",
      "61500 1.1 0.09999999999985551\n",
      "62000 0.6 0.09999999999985551\n",
      "62500 1.5 0.09999999999985551\n",
      "63000 2.9 0.09999999999985551\n",
      "63500 1.8 0.09999999999985551\n",
      "64000 1.3 0.09999999999985551\n",
      "64500 2.1 0.09999999999985551\n",
      "65000 2.3 0.09999999999985551\n",
      "65500 1.4 0.09999999999985551\n",
      "66000 0.6 0.09999999999985551\n",
      "66500 1.3 0.09999999999985551\n",
      "67000 1.0 0.09999999999985551\n",
      "67500 2.2 0.09999999999985551\n",
      "68000 1.2 0.09999999999985551\n",
      "68500 2.2 0.09999999999985551\n",
      "69000 1.3 0.09999999999985551\n",
      "69500 0.7 0.09999999999985551\n",
      "70000 1.2 0.09999999999985551\n",
      "70500 1.5 0.09999999999985551\n",
      "71000 2.9 0.09999999999985551\n",
      "71500 1.9 0.09999999999985551\n",
      "72000 2.3 0.09999999999985551\n",
      "72500 1.2 0.09999999999985551\n",
      "73000 5.4 0.09999999999985551\n",
      "73500 2.4 0.09999999999985551\n",
      "74000 1.4 0.09999999999985551\n",
      "74500 2.7 0.09999999999985551\n",
      "75000 2.8 0.09999999999985551\n",
      "75500 0.3 0.09999999999985551\n",
      "76000 2.4 0.09999999999985551\n",
      "76500 3.1 0.09999999999985551\n",
      "77000 2.2 0.09999999999985551\n",
      "77500 1.6 0.09999999999985551\n",
      "78000 2.0 0.09999999999985551\n",
      "78500 1.7 0.09999999999985551\n",
      "79000 1.8 0.09999999999985551\n",
      "79500 3.4 0.09999999999985551\n",
      "80000 2.1 0.09999999999985551\n",
      "80500 1.7 0.09999999999985551\n",
      "81000 3.3 0.09999999999985551\n",
      "81500 3.9 0.09999999999985551\n",
      "82000 3.8 0.09999999999985551\n",
      "82500 2.7 0.09999999999985551\n",
      "83000 2.6 0.09999999999985551\n",
      "83500 4.0 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84000 3.8 0.09999999999985551\n",
      "84500 1.8 0.09999999999985551\n",
      "85000 3.4 0.09999999999985551\n",
      "85500 1.7 0.09999999999985551\n",
      "86000 5.8 0.09999999999985551\n",
      "86500 4.2 0.09999999999985551\n",
      "87000 6.2 0.09999999999985551\n",
      "87500 5.2 0.09999999999985551\n",
      "88000 3.8 0.09999999999985551\n",
      "88500 3.5 0.09999999999985551\n",
      "89000 4.7 0.09999999999985551\n",
      "89500 5.5 0.09999999999985551\n",
      "90000 3.1 0.09999999999985551\n",
      "90500 4.5 0.09999999999985551\n",
      "91000 2.3 0.09999999999985551\n",
      "91500 5.6 0.09999999999985551\n",
      "92000 7.8 0.09999999999985551\n",
      "92500 8.4 0.09999999999985551\n",
      "93000 3.3 0.09999999999985551\n",
      "93500 5.2 0.09999999999985551\n",
      "94000 3.7 0.09999999999985551\n",
      "94500 4.9 0.09999999999985551\n",
      "95000 6.0 0.09999999999985551\n",
      "95500 6.4 0.09999999999985551\n",
      "96000 6.5 0.09999999999985551\n",
      "96500 5.5 0.09999999999985551\n",
      "97000 8.5 0.09999999999985551\n",
      "97500 6.1 0.09999999999985551\n",
      "98000 6.8 0.09999999999985551\n",
      "98500 4.9 0.09999999999985551\n",
      "99000 5.5 0.09999999999985551\n",
      "99500 7.7 0.09999999999985551\n",
      "100000 8.1 0.09999999999985551\n",
      "Saved Model\n",
      "100500 6.7 0.09999999999985551\n",
      "101000 8.2 0.09999999999985551\n",
      "101500 7.0 0.09999999999985551\n",
      "102000 8.0 0.09999999999985551\n",
      "102500 5.7 0.09999999999985551\n",
      "103000 6.6 0.09999999999985551\n",
      "103500 4.9 0.09999999999985551\n",
      "104000 8.9 0.09999999999985551\n",
      "104500 6.1 0.09999999999985551\n",
      "105000 6.3 0.09999999999985551\n",
      "105500 5.4 0.09999999999985551\n",
      "106000 8.5 0.09999999999985551\n",
      "106500 7.2 0.09999999999985551\n",
      "107000 4.7 0.09999999999985551\n",
      "107500 6.0 0.09999999999985551\n",
      "108000 7.6 0.09999999999985551\n",
      "108500 7.1 0.09999999999985551\n",
      "109000 7.1 0.09999999999985551\n",
      "109500 6.6 0.09999999999985551\n",
      "110000 8.6 0.09999999999985551\n",
      "110500 8.3 0.09999999999985551\n",
      "111000 7.0 0.09999999999985551\n",
      "111500 5.0 0.09999999999985551\n",
      "112000 3.6 0.09999999999985551\n",
      "112500 7.1 0.09999999999985551\n",
      "113000 6.8 0.09999999999985551\n",
      "113500 7.6 0.09999999999985551\n",
      "114000 7.9 0.09999999999985551\n",
      "114500 6.0 0.09999999999985551\n",
      "115000 9.0 0.09999999999985551\n",
      "115500 8.8 0.09999999999985551\n",
      "116000 7.9 0.09999999999985551\n",
      "116500 7.9 0.09999999999985551\n",
      "117000 9.3 0.09999999999985551\n",
      "117500 8.1 0.09999999999985551\n",
      "118000 7.5 0.09999999999985551\n",
      "118500 6.6 0.09999999999985551\n",
      "119000 6.9 0.09999999999985551\n",
      "119500 8.8 0.09999999999985551\n",
      "120000 8.0 0.09999999999985551\n",
      "120500 6.7 0.09999999999985551\n",
      "121000 5.7 0.09999999999985551\n",
      "121500 6.5 0.09999999999985551\n",
      "122000 5.1 0.09999999999985551\n",
      "122500 6.5 0.09999999999985551\n",
      "123000 10.2 0.09999999999985551\n",
      "123500 9.5 0.09999999999985551\n",
      "124000 8.7 0.09999999999985551\n",
      "124500 7.4 0.09999999999985551\n",
      "125000 10.1 0.09999999999985551\n",
      "125500 6.3 0.09999999999985551\n",
      "126000 5.1 0.09999999999985551\n",
      "126500 7.2 0.09999999999985551\n",
      "127000 7.9 0.09999999999985551\n",
      "127500 7.2 0.09999999999985551\n",
      "128000 10.0 0.09999999999985551\n",
      "128500 9.3 0.09999999999985551\n",
      "129000 6.3 0.09999999999985551\n",
      "129500 11.7 0.09999999999985551\n",
      "130000 7.9 0.09999999999985551\n",
      "130500 8.4 0.09999999999985551\n",
      "131000 7.1 0.09999999999985551\n",
      "131500 7.4 0.09999999999985551\n",
      "132000 5.2 0.09999999999985551\n",
      "132500 7.4 0.09999999999985551\n",
      "133000 11.0 0.09999999999985551\n",
      "133500 11.3 0.09999999999985551\n",
      "134000 5.6 0.09999999999985551\n",
      "134500 6.9 0.09999999999985551\n",
      "135000 8.0 0.09999999999985551\n",
      "135500 9.0 0.09999999999985551\n",
      "136000 6.7 0.09999999999985551\n",
      "136500 9.6 0.09999999999985551\n",
      "137000 7.2 0.09999999999985551\n",
      "137500 8.4 0.09999999999985551\n",
      "138000 9.5 0.09999999999985551\n",
      "138500 7.4 0.09999999999985551\n",
      "139000 9.9 0.09999999999985551\n",
      "139500 10.3 0.09999999999985551\n",
      "140000 13.2 0.09999999999985551\n",
      "140500 8.8 0.09999999999985551\n",
      "141000 9.5 0.09999999999985551\n",
      "141500 7.0 0.09999999999985551\n",
      "142000 7.4 0.09999999999985551\n",
      "142500 10.4 0.09999999999985551\n",
      "143000 11.2 0.09999999999985551\n",
      "143500 9.8 0.09999999999985551\n",
      "144000 7.5 0.09999999999985551\n",
      "144500 8.3 0.09999999999985551\n",
      "145000 6.3 0.09999999999985551\n",
      "145500 10.9 0.09999999999985551\n",
      "146000 10.0 0.09999999999985551\n",
      "146500 9.3 0.09999999999985551\n",
      "147000 6.2 0.09999999999985551\n",
      "147500 10.6 0.09999999999985551\n",
      "148000 8.5 0.09999999999985551\n",
      "148500 9.8 0.09999999999985551\n",
      "149000 7.3 0.09999999999985551\n",
      "149500 9.6 0.09999999999985551\n",
      "150000 6.9 0.09999999999985551\n",
      "Saved Model\n",
      "150500 10.3 0.09999999999985551\n",
      "151000 6.8 0.09999999999985551\n",
      "151500 7.3 0.09999999999985551\n",
      "152000 10.0 0.09999999999985551\n",
      "152500 10.5 0.09999999999985551\n",
      "153000 7.1 0.09999999999985551\n",
      "153500 8.4 0.09999999999985551\n",
      "154000 7.9 0.09999999999985551\n",
      "154500 8.4 0.09999999999985551\n",
      "155000 9.8 0.09999999999985551\n",
      "155500 8.4 0.09999999999985551\n",
      "156000 10.3 0.09999999999985551\n",
      "156500 9.6 0.09999999999985551\n",
      "157000 7.6 0.09999999999985551\n",
      "157500 9.0 0.09999999999985551\n",
      "158000 10.5 0.09999999999985551\n",
      "158500 8.7 0.09999999999985551\n",
      "159000 9.5 0.09999999999985551\n",
      "159500 9.6 0.09999999999985551\n",
      "160000 8.7 0.09999999999985551\n",
      "160500 6.4 0.09999999999985551\n",
      "161000 6.6 0.09999999999985551\n",
      "161500 10.2 0.09999999999985551\n",
      "162000 8.4 0.09999999999985551\n",
      "162500 11.1 0.09999999999985551\n",
      "163000 10.3 0.09999999999985551\n",
      "163500 11.5 0.09999999999985551\n",
      "164000 10.4 0.09999999999985551\n",
      "164500 7.0 0.09999999999985551\n",
      "165000 11.1 0.09999999999985551\n",
      "165500 8.0 0.09999999999985551\n",
      "166000 4.4 0.09999999999985551\n",
      "166500 10.4 0.09999999999985551\n",
      "167000 11.0 0.09999999999985551\n",
      "167500 8.1 0.09999999999985551\n",
      "168000 12.3 0.09999999999985551\n",
      "168500 9.4 0.09999999999985551\n",
      "169000 8.6 0.09999999999985551\n",
      "169500 10.0 0.09999999999985551\n",
      "170000 6.4 0.09999999999985551\n",
      "170500 12.2 0.09999999999985551\n",
      "171000 9.3 0.09999999999985551\n",
      "171500 7.2 0.09999999999985551\n",
      "172000 9.0 0.09999999999985551\n",
      "172500 11.9 0.09999999999985551\n",
      "173000 8.5 0.09999999999985551\n",
      "173500 11.2 0.09999999999985551\n",
      "174000 9.3 0.09999999999985551\n",
      "174500 9.8 0.09999999999985551\n",
      "175000 6.9 0.09999999999985551\n",
      "175500 6.0 0.09999999999985551\n",
      "176000 11.6 0.09999999999985551\n",
      "176500 8.3 0.09999999999985551\n",
      "177000 13.0 0.09999999999985551\n",
      "177500 9.1 0.09999999999985551\n",
      "178000 8.2 0.09999999999985551\n",
      "178500 12.1 0.09999999999985551\n",
      "179000 7.0 0.09999999999985551\n",
      "179500 8.7 0.09999999999985551\n",
      "180000 9.5 0.09999999999985551\n",
      "180500 9.4 0.09999999999985551\n",
      "181000 9.8 0.09999999999985551\n",
      "181500 6.5 0.09999999999985551\n",
      "182000 8.2 0.09999999999985551\n",
      "182500 9.1 0.09999999999985551\n",
      "183000 9.8 0.09999999999985551\n",
      "183500 10.3 0.09999999999985551\n",
      "184000 10.9 0.09999999999985551\n",
      "184500 7.2 0.09999999999985551\n",
      "185000 9.3 0.09999999999985551\n",
      "185500 11.2 0.09999999999985551\n",
      "186000 9.4 0.09999999999985551\n",
      "186500 13.5 0.09999999999985551\n",
      "187000 8.0 0.09999999999985551\n",
      "187500 9.4 0.09999999999985551\n",
      "188000 8.5 0.09999999999985551\n",
      "188500 4.8 0.09999999999985551\n",
      "189000 8.1 0.09999999999985551\n",
      "189500 9.8 0.09999999999985551\n",
      "190000 8.1 0.09999999999985551\n",
      "190500 10.6 0.09999999999985551\n",
      "191000 9.1 0.09999999999985551\n",
      "191500 4.6 0.09999999999985551\n",
      "192000 9.4 0.09999999999985551\n",
      "192500 13.8 0.09999999999985551\n",
      "193000 7.1 0.09999999999985551\n",
      "193500 11.8 0.09999999999985551\n",
      "194000 13.2 0.09999999999985551\n",
      "194500 13.7 0.09999999999985551\n",
      "195000 8.4 0.09999999999985551\n",
      "195500 9.0 0.09999999999985551\n",
      "196000 11.2 0.09999999999985551\n",
      "196500 7.6 0.09999999999985551\n",
      "197000 10.7 0.09999999999985551\n",
      "197500 11.1 0.09999999999985551\n",
      "198000 8.3 0.09999999999985551\n",
      "198500 10.9 0.09999999999985551\n",
      "199000 10.9 0.09999999999985551\n",
      "199500 9.0 0.09999999999985551\n",
      "200000 13.0 0.09999999999985551\n",
      "Saved Model\n",
      "200500 12.0 0.09999999999985551\n",
      "201000 7.3 0.09999999999985551\n",
      "201500 5.4 0.09999999999985551\n",
      "202000 6.7 0.09999999999985551\n",
      "202500 9.7 0.09999999999985551\n",
      "203000 8.5 0.09999999999985551\n",
      "203500 7.3 0.09999999999985551\n",
      "204000 7.7 0.09999999999985551\n",
      "204500 7.0 0.09999999999985551\n",
      "205000 11.5 0.09999999999985551\n",
      "205500 9.5 0.09999999999985551\n",
      "206000 6.3 0.09999999999985551\n",
      "206500 9.4 0.09999999999985551\n",
      "207000 9.9 0.09999999999985551\n",
      "207500 8.8 0.09999999999985551\n",
      "208000 9.7 0.09999999999985551\n",
      "208500 11.1 0.09999999999985551\n",
      "209000 10.7 0.09999999999985551\n",
      "209500 7.8 0.09999999999985551\n",
      "210000 7.8 0.09999999999985551\n",
      "210500 8.7 0.09999999999985551\n",
      "211000 10.9 0.09999999999985551\n",
      "211500 10.4 0.09999999999985551\n",
      "212000 12.3 0.09999999999985551\n",
      "212500 10.2 0.09999999999985551\n",
      "213000 9.6 0.09999999999985551\n",
      "213500 10.5 0.09999999999985551\n",
      "214000 8.1 0.09999999999985551\n",
      "214500 10.0 0.09999999999985551\n",
      "215000 9.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215500 8.8 0.09999999999985551\n",
      "216000 9.9 0.09999999999985551\n",
      "216500 12.4 0.09999999999985551\n",
      "217000 6.6 0.09999999999985551\n",
      "217500 13.9 0.09999999999985551\n",
      "218000 7.0 0.09999999999985551\n",
      "218500 9.7 0.09999999999985551\n",
      "219000 8.4 0.09999999999985551\n",
      "219500 9.5 0.09999999999985551\n",
      "220000 9.8 0.09999999999985551\n",
      "220500 11.4 0.09999999999985551\n",
      "221000 10.8 0.09999999999985551\n",
      "221500 8.8 0.09999999999985551\n",
      "222000 6.4 0.09999999999985551\n",
      "222500 6.0 0.09999999999985551\n",
      "223000 12.4 0.09999999999985551\n",
      "223500 11.9 0.09999999999985551\n",
      "224000 9.3 0.09999999999985551\n",
      "224500 11.5 0.09999999999985551\n",
      "225000 8.8 0.09999999999985551\n",
      "225500 12.1 0.09999999999985551\n",
      "226000 12.3 0.09999999999985551\n",
      "226500 9.1 0.09999999999985551\n",
      "227000 8.7 0.09999999999985551\n",
      "227500 7.0 0.09999999999985551\n",
      "228000 7.0 0.09999999999985551\n",
      "228500 12.8 0.09999999999985551\n",
      "229000 11.3 0.09999999999985551\n",
      "229500 9.8 0.09999999999985551\n",
      "230000 11.7 0.09999999999985551\n",
      "230500 11.7 0.09999999999985551\n",
      "231000 8.5 0.09999999999985551\n",
      "231500 10.3 0.09999999999985551\n",
      "232000 11.5 0.09999999999985551\n",
      "232500 8.5 0.09999999999985551\n",
      "233000 12.6 0.09999999999985551\n",
      "233500 9.2 0.09999999999985551\n",
      "234000 9.2 0.09999999999985551\n",
      "234500 11.5 0.09999999999985551\n",
      "235000 10.5 0.09999999999985551\n",
      "235500 10.2 0.09999999999985551\n",
      "236000 11.7 0.09999999999985551\n",
      "236500 8.8 0.09999999999985551\n",
      "237000 7.5 0.09999999999985551\n",
      "237500 12.3 0.09999999999985551\n",
      "238000 11.0 0.09999999999985551\n",
      "238500 9.1 0.09999999999985551\n",
      "239000 8.6 0.09999999999985551\n",
      "239500 10.8 0.09999999999985551\n",
      "240000 13.4 0.09999999999985551\n",
      "240500 7.0 0.09999999999985551\n",
      "241000 9.0 0.09999999999985551\n",
      "241500 10.6 0.09999999999985551\n",
      "242000 11.0 0.09999999999985551\n",
      "242500 10.0 0.09999999999985551\n",
      "243000 10.0 0.09999999999985551\n",
      "243500 8.2 0.09999999999985551\n",
      "244000 9.1 0.09999999999985551\n",
      "244500 10.9 0.09999999999985551\n",
      "245000 10.0 0.09999999999985551\n",
      "245500 10.8 0.09999999999985551\n",
      "246000 12.2 0.09999999999985551\n",
      "246500 10.8 0.09999999999985551\n",
      "247000 11.0 0.09999999999985551\n",
      "247500 7.0 0.09999999999985551\n",
      "248000 13.4 0.09999999999985551\n",
      "248500 9.0 0.09999999999985551\n",
      "249000 10.1 0.09999999999985551\n",
      "249500 8.7 0.09999999999985551\n",
      "250000 10.8 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 7.1 0.09999999999985551\n",
      "251000 9.8 0.09999999999985551\n",
      "251500 7.5 0.09999999999985551\n",
      "252000 9.0 0.09999999999985551\n",
      "252500 9.7 0.09999999999985551\n",
      "253000 9.7 0.09999999999985551\n",
      "253500 11.3 0.09999999999985551\n",
      "254000 9.4 0.09999999999985551\n",
      "254500 10.7 0.09999999999985551\n",
      "255000 13.5 0.09999999999985551\n",
      "255500 10.5 0.09999999999985551\n",
      "256000 9.0 0.09999999999985551\n",
      "256500 11.6 0.09999999999985551\n",
      "257000 10.0 0.09999999999985551\n",
      "257500 10.2 0.09999999999985551\n",
      "258000 9.3 0.09999999999985551\n",
      "258500 10.9 0.09999999999985551\n",
      "259000 9.0 0.09999999999985551\n",
      "259500 11.9 0.09999999999985551\n",
      "260000 14.0 0.09999999999985551\n",
      "260500 10.9 0.09999999999985551\n",
      "261000 11.2 0.09999999999985551\n",
      "261500 10.9 0.09999999999985551\n",
      "262000 10.6 0.09999999999985551\n",
      "262500 9.6 0.09999999999985551\n",
      "263000 9.6 0.09999999999985551\n",
      "263500 11.6 0.09999999999985551\n",
      "264000 13.6 0.09999999999985551\n",
      "264500 10.5 0.09999999999985551\n",
      "265000 13.2 0.09999999999985551\n",
      "265500 10.0 0.09999999999985551\n",
      "266000 13.5 0.09999999999985551\n",
      "266500 8.5 0.09999999999985551\n",
      "267000 7.6 0.09999999999985551\n",
      "267500 10.9 0.09999999999985551\n",
      "268000 10.3 0.09999999999985551\n",
      "268500 9.6 0.09999999999985551\n",
      "269000 7.0 0.09999999999985551\n",
      "269500 8.4 0.09999999999985551\n",
      "270000 5.3 0.09999999999985551\n",
      "270500 11.3 0.09999999999985551\n",
      "271000 10.0 0.09999999999985551\n",
      "271500 9.5 0.09999999999985551\n",
      "272000 9.9 0.09999999999985551\n",
      "272500 8.2 0.09999999999985551\n",
      "273000 9.2 0.09999999999985551\n",
      "273500 6.0 0.09999999999985551\n",
      "274000 12.4 0.09999999999985551\n",
      "274500 10.2 0.09999999999985551\n",
      "275000 11.3 0.09999999999985551\n",
      "275500 10.8 0.09999999999985551\n",
      "276000 12.1 0.09999999999985551\n",
      "276500 8.0 0.09999999999985551\n",
      "277000 11.3 0.09999999999985551\n",
      "277500 12.3 0.09999999999985551\n",
      "278000 11.5 0.09999999999985551\n",
      "278500 10.4 0.09999999999985551\n",
      "279000 9.6 0.09999999999985551\n",
      "279500 12.4 0.09999999999985551\n",
      "280000 10.4 0.09999999999985551\n",
      "280500 9.0 0.09999999999985551\n",
      "281000 15.0 0.09999999999985551\n",
      "281500 9.3 0.09999999999985551\n",
      "282000 10.7 0.09999999999985551\n",
      "282500 13.8 0.09999999999985551\n",
      "283000 10.9 0.09999999999985551\n",
      "283500 10.1 0.09999999999985551\n",
      "284000 12.2 0.09999999999985551\n",
      "284500 6.8 0.09999999999985551\n",
      "285000 7.4 0.09999999999985551\n",
      "285500 5.1 0.09999999999985551\n",
      "286000 11.6 0.09999999999985551\n",
      "286500 9.7 0.09999999999985551\n",
      "287000 8.4 0.09999999999985551\n",
      "287500 10.4 0.09999999999985551\n",
      "288000 10.8 0.09999999999985551\n",
      "288500 11.2 0.09999999999985551\n",
      "289000 11.6 0.09999999999985551\n",
      "289500 10.6 0.09999999999985551\n",
      "290000 10.7 0.09999999999985551\n",
      "290500 9.7 0.09999999999985551\n",
      "291000 11.2 0.09999999999985551\n",
      "291500 8.6 0.09999999999985551\n",
      "292000 10.3 0.09999999999985551\n",
      "292500 10.3 0.09999999999985551\n",
      "293000 9.3 0.09999999999985551\n",
      "293500 11.0 0.09999999999985551\n",
      "294000 11.7 0.09999999999985551\n",
      "294500 9.5 0.09999999999985551\n",
      "295000 7.4 0.09999999999985551\n",
      "295500 10.3 0.09999999999985551\n",
      "296000 10.9 0.09999999999985551\n",
      "296500 8.9 0.09999999999985551\n",
      "297000 9.4 0.09999999999985551\n",
      "297500 9.5 0.09999999999985551\n",
      "298000 11.8 0.09999999999985551\n",
      "298500 9.5 0.09999999999985551\n",
      "299000 11.5 0.09999999999985551\n",
      "299500 12.0 0.09999999999985551\n",
      "300000 10.6 0.09999999999985551\n",
      "Saved Model\n",
      "300500 8.3 0.09999999999985551\n",
      "301000 9.7 0.09999999999985551\n",
      "301500 9.4 0.09999999999985551\n",
      "302000 9.9 0.09999999999985551\n",
      "302500 11.1 0.09999999999985551\n",
      "303000 8.4 0.09999999999985551\n",
      "303500 8.6 0.09999999999985551\n",
      "304000 11.0 0.09999999999985551\n",
      "304500 11.6 0.09999999999985551\n",
      "305000 8.6 0.09999999999985551\n",
      "305500 14.2 0.09999999999985551\n",
      "306000 11.4 0.09999999999985551\n",
      "306500 7.7 0.09999999999985551\n",
      "307000 11.8 0.09999999999985551\n",
      "307500 9.3 0.09999999999985551\n",
      "308000 8.2 0.09999999999985551\n",
      "308500 9.9 0.09999999999985551\n",
      "309000 10.2 0.09999999999985551\n",
      "309500 11.4 0.09999999999985551\n",
      "310000 7.6 0.09999999999985551\n",
      "310500 9.3 0.09999999999985551\n",
      "311000 9.9 0.09999999999985551\n",
      "311500 10.6 0.09999999999985551\n",
      "312000 12.9 0.09999999999985551\n",
      "312500 10.2 0.09999999999985551\n",
      "313000 7.5 0.09999999999985551\n",
      "313500 13.0 0.09999999999985551\n",
      "314000 10.4 0.09999999999985551\n",
      "314500 11.1 0.09999999999985551\n",
      "315000 10.7 0.09999999999985551\n",
      "315500 10.2 0.09999999999985551\n",
      "316000 9.2 0.09999999999985551\n",
      "316500 8.1 0.09999999999985551\n",
      "317000 8.8 0.09999999999985551\n",
      "317500 11.0 0.09999999999985551\n",
      "318000 10.0 0.09999999999985551\n",
      "318500 11.7 0.09999999999985551\n",
      "319000 12.7 0.09999999999985551\n",
      "319500 14.9 0.09999999999985551\n",
      "320000 8.0 0.09999999999985551\n",
      "320500 11.2 0.09999999999985551\n",
      "321000 9.7 0.09999999999985551\n",
      "321500 13.6 0.09999999999985551\n",
      "322000 11.8 0.09999999999985551\n",
      "322500 10.9 0.09999999999985551\n",
      "323000 11.0 0.09999999999985551\n",
      "323500 13.4 0.09999999999985551\n",
      "324000 10.6 0.09999999999985551\n",
      "324500 13.1 0.09999999999985551\n",
      "325000 11.4 0.09999999999985551\n",
      "325500 8.9 0.09999999999985551\n",
      "326000 8.6 0.09999999999985551\n",
      "326500 12.0 0.09999999999985551\n",
      "327000 8.4 0.09999999999985551\n",
      "327500 14.3 0.09999999999985551\n",
      "328000 8.8 0.09999999999985551\n",
      "328500 9.3 0.09999999999985551\n",
      "329000 8.4 0.09999999999985551\n",
      "329500 13.2 0.09999999999985551\n",
      "330000 11.8 0.09999999999985551\n",
      "330500 12.8 0.09999999999985551\n",
      "331000 7.4 0.09999999999985551\n",
      "331500 7.6 0.09999999999985551\n",
      "332000 7.7 0.09999999999985551\n",
      "332500 8.3 0.09999999999985551\n",
      "333000 13.5 0.09999999999985551\n",
      "333500 14.1 0.09999999999985551\n",
      "334000 10.1 0.09999999999985551\n",
      "334500 12.5 0.09999999999985551\n",
      "335000 8.1 0.09999999999985551\n",
      "335500 11.3 0.09999999999985551\n",
      "336000 14.1 0.09999999999985551\n",
      "336500 9.7 0.09999999999985551\n",
      "337000 11.4 0.09999999999985551\n",
      "337500 9.6 0.09999999999985551\n",
      "338000 10.3 0.09999999999985551\n",
      "338500 8.5 0.09999999999985551\n",
      "339000 10.9 0.09999999999985551\n",
      "339500 10.1 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340000 8.0 0.09999999999985551\n",
      "340500 11.9 0.09999999999985551\n",
      "341000 7.1 0.09999999999985551\n",
      "341500 10.7 0.09999999999985551\n",
      "342000 13.2 0.09999999999985551\n",
      "342500 10.3 0.09999999999985551\n",
      "343000 12.2 0.09999999999985551\n",
      "343500 13.7 0.09999999999985551\n",
      "344000 9.6 0.09999999999985551\n",
      "344500 10.7 0.09999999999985551\n",
      "345000 8.3 0.09999999999985551\n",
      "345500 12.3 0.09999999999985551\n",
      "346000 9.7 0.09999999999985551\n",
      "346500 6.7 0.09999999999985551\n",
      "347000 9.9 0.09999999999985551\n",
      "347500 8.4 0.09999999999985551\n",
      "348000 10.1 0.09999999999985551\n",
      "348500 10.5 0.09999999999985551\n",
      "349000 11.0 0.09999999999985551\n",
      "349500 9.3 0.09999999999985551\n",
      "350000 7.9 0.09999999999985551\n",
      "Saved Model\n",
      "350500 12.4 0.09999999999985551\n",
      "351000 9.9 0.09999999999985551\n",
      "351500 8.1 0.09999999999985551\n",
      "352000 10.4 0.09999999999985551\n",
      "352500 9.5 0.09999999999985551\n",
      "353000 11.2 0.09999999999985551\n",
      "353500 11.7 0.09999999999985551\n",
      "354000 9.1 0.09999999999985551\n",
      "354500 10.1 0.09999999999985551\n",
      "355000 9.4 0.09999999999985551\n",
      "355500 10.9 0.09999999999985551\n",
      "356000 11.8 0.09999999999985551\n",
      "356500 10.9 0.09999999999985551\n",
      "357000 9.9 0.09999999999985551\n",
      "357500 12.7 0.09999999999985551\n",
      "358000 11.7 0.09999999999985551\n",
      "358500 8.7 0.09999999999985551\n",
      "359000 10.4 0.09999999999985551\n",
      "359500 10.3 0.09999999999985551\n",
      "360000 10.7 0.09999999999985551\n",
      "360500 11.8 0.09999999999985551\n",
      "361000 9.3 0.09999999999985551\n",
      "361500 7.3 0.09999999999985551\n",
      "362000 10.7 0.09999999999985551\n",
      "362500 6.4 0.09999999999985551\n",
      "363000 11.7 0.09999999999985551\n",
      "363500 11.9 0.09999999999985551\n",
      "364000 12.1 0.09999999999985551\n",
      "364500 11.9 0.09999999999985551\n",
      "365000 9.4 0.09999999999985551\n",
      "365500 11.9 0.09999999999985551\n",
      "366000 11.0 0.09999999999985551\n",
      "366500 11.5 0.09999999999985551\n",
      "367000 12.8 0.09999999999985551\n",
      "367500 10.1 0.09999999999985551\n",
      "368000 13.8 0.09999999999985551\n",
      "368500 12.2 0.09999999999985551\n",
      "369000 12.1 0.09999999999985551\n",
      "369500 10.4 0.09999999999985551\n",
      "370000 10.1 0.09999999999985551\n",
      "370500 12.2 0.09999999999985551\n",
      "371000 10.6 0.09999999999985551\n",
      "371500 10.5 0.09999999999985551\n",
      "372000 12.5 0.09999999999985551\n",
      "372500 11.5 0.09999999999985551\n",
      "373000 10.6 0.09999999999985551\n",
      "373500 13.2 0.09999999999985551\n",
      "374000 11.6 0.09999999999985551\n",
      "374500 9.3 0.09999999999985551\n",
      "375000 12.7 0.09999999999985551\n",
      "375500 11.0 0.09999999999985551\n",
      "376000 9.6 0.09999999999985551\n",
      "376500 10.8 0.09999999999985551\n",
      "377000 13.5 0.09999999999985551\n",
      "377500 11.3 0.09999999999985551\n",
      "378000 8.4 0.09999999999985551\n",
      "378500 11.3 0.09999999999985551\n",
      "379000 10.6 0.09999999999985551\n",
      "379500 8.7 0.09999999999985551\n",
      "380000 7.5 0.09999999999985551\n",
      "380500 14.2 0.09999999999985551\n",
      "381000 9.3 0.09999999999985551\n",
      "381500 12.9 0.09999999999985551\n",
      "382000 10.5 0.09999999999985551\n",
      "382500 11.2 0.09999999999985551\n",
      "383000 9.6 0.09999999999985551\n",
      "383500 11.7 0.09999999999985551\n",
      "384000 13.4 0.09999999999985551\n",
      "384500 12.8 0.09999999999985551\n",
      "385000 14.0 0.09999999999985551\n",
      "385500 14.7 0.09999999999985551\n",
      "386000 10.7 0.09999999999985551\n",
      "386500 12.5 0.09999999999985551\n",
      "387000 12.2 0.09999999999985551\n",
      "387500 10.8 0.09999999999985551\n",
      "388000 10.4 0.09999999999985551\n",
      "388500 7.8 0.09999999999985551\n",
      "389000 9.3 0.09999999999985551\n",
      "389500 12.6 0.09999999999985551\n",
      "390000 11.6 0.09999999999985551\n",
      "390500 7.1 0.09999999999985551\n",
      "391000 10.8 0.09999999999985551\n",
      "391500 8.3 0.09999999999985551\n",
      "392000 10.7 0.09999999999985551\n",
      "392500 15.8 0.09999999999985551\n",
      "393000 13.0 0.09999999999985551\n",
      "393500 9.9 0.09999999999985551\n",
      "394000 11.2 0.09999999999985551\n",
      "394500 10.1 0.09999999999985551\n",
      "395000 9.7 0.09999999999985551\n",
      "395500 10.4 0.09999999999985551\n",
      "396000 11.8 0.09999999999985551\n",
      "396500 12.2 0.09999999999985551\n",
      "397000 7.1 0.09999999999985551\n",
      "397500 11.4 0.09999999999985551\n",
      "398000 10.9 0.09999999999985551\n",
      "398500 10.2 0.09999999999985551\n",
      "399000 11.9 0.09999999999985551\n",
      "399500 8.3 0.09999999999985551\n",
      "400000 11.6 0.09999999999985551\n",
      "Saved Model\n",
      "400500 8.7 0.09999999999985551\n",
      "401000 8.7 0.09999999999985551\n",
      "401500 12.8 0.09999999999985551\n",
      "402000 11.9 0.09999999999985551\n",
      "402500 10.0 0.09999999999985551\n",
      "403000 13.9 0.09999999999985551\n",
      "403500 12.7 0.09999999999985551\n",
      "404000 8.2 0.09999999999985551\n",
      "404500 12.9 0.09999999999985551\n",
      "405000 10.7 0.09999999999985551\n",
      "405500 11.3 0.09999999999985551\n",
      "406000 11.3 0.09999999999985551\n",
      "406500 10.6 0.09999999999985551\n",
      "407000 13.4 0.09999999999985551\n",
      "407500 11.6 0.09999999999985551\n",
      "408000 12.2 0.09999999999985551\n",
      "408500 13.3 0.09999999999985551\n",
      "409000 8.3 0.09999999999985551\n",
      "409500 12.2 0.09999999999985551\n",
      "410000 12.1 0.09999999999985551\n",
      "410500 13.1 0.09999999999985551\n",
      "411000 9.3 0.09999999999985551\n",
      "411500 10.5 0.09999999999985551\n",
      "412000 7.4 0.09999999999985551\n",
      "412500 9.3 0.09999999999985551\n",
      "413000 10.2 0.09999999999985551\n",
      "413500 12.6 0.09999999999985551\n",
      "414000 11.6 0.09999999999985551\n",
      "414500 13.5 0.09999999999985551\n",
      "415000 8.0 0.09999999999985551\n",
      "415500 11.8 0.09999999999985551\n",
      "416000 12.3 0.09999999999985551\n",
      "416500 10.4 0.09999999999985551\n",
      "417000 10.7 0.09999999999985551\n",
      "417500 12.4 0.09999999999985551\n",
      "418000 11.0 0.09999999999985551\n",
      "418500 12.1 0.09999999999985551\n",
      "419000 10.1 0.09999999999985551\n",
      "419500 11.7 0.09999999999985551\n",
      "420000 10.6 0.09999999999985551\n",
      "420500 11.1 0.09999999999985551\n",
      "421000 7.0 0.09999999999985551\n",
      "421500 7.7 0.09999999999985551\n",
      "422000 10.3 0.09999999999985551\n",
      "422500 10.1 0.09999999999985551\n",
      "423000 9.4 0.09999999999985551\n",
      "423500 9.4 0.09999999999985551\n",
      "424000 12.3 0.09999999999985551\n",
      "424500 11.0 0.09999999999985551\n",
      "425000 9.6 0.09999999999985551\n",
      "425500 12.3 0.09999999999985551\n",
      "426000 12.6 0.09999999999985551\n",
      "426500 11.3 0.09999999999985551\n",
      "427000 11.3 0.09999999999985551\n",
      "427500 7.9 0.09999999999985551\n",
      "428000 11.9 0.09999999999985551\n",
      "428500 13.4 0.09999999999985551\n",
      "429000 10.9 0.09999999999985551\n",
      "429500 12.5 0.09999999999985551\n",
      "430000 12.5 0.09999999999985551\n",
      "430500 9.9 0.09999999999985551\n",
      "431000 10.7 0.09999999999985551\n",
      "431500 9.6 0.09999999999985551\n",
      "432000 11.7 0.09999999999985551\n",
      "432500 9.9 0.09999999999985551\n",
      "433000 13.5 0.09999999999985551\n",
      "433500 11.8 0.09999999999985551\n",
      "434000 11.1 0.09999999999985551\n",
      "434500 12.9 0.09999999999985551\n",
      "435000 15.0 0.09999999999985551\n",
      "435500 10.5 0.09999999999985551\n",
      "436000 8.8 0.09999999999985551\n",
      "436500 7.6 0.09999999999985551\n",
      "437000 10.5 0.09999999999985551\n",
      "437500 10.2 0.09999999999985551\n",
      "438000 11.6 0.09999999999985551\n",
      "438500 8.4 0.09999999999985551\n",
      "439000 7.7 0.09999999999985551\n",
      "439500 11.6 0.09999999999985551\n",
      "440000 10.7 0.09999999999985551\n",
      "440500 11.7 0.09999999999985551\n",
      "441000 10.6 0.09999999999985551\n",
      "441500 13.6 0.09999999999985551\n",
      "442000 13.1 0.09999999999985551\n",
      "442500 9.3 0.09999999999985551\n",
      "443000 9.9 0.09999999999985551\n",
      "443500 9.8 0.09999999999985551\n",
      "444000 12.2 0.09999999999985551\n",
      "444500 10.5 0.09999999999985551\n",
      "445000 11.5 0.09999999999985551\n",
      "445500 11.0 0.09999999999985551\n",
      "446000 9.6 0.09999999999985551\n",
      "446500 16.1 0.09999999999985551\n",
      "447000 11.1 0.09999999999985551\n",
      "447500 11.1 0.09999999999985551\n",
      "448000 7.7 0.09999999999985551\n",
      "448500 10.9 0.09999999999985551\n",
      "449000 8.2 0.09999999999985551\n",
      "449500 10.9 0.09999999999985551\n",
      "450000 8.5 0.09999999999985551\n",
      "Saved Model\n",
      "450500 9.6 0.09999999999985551\n",
      "451000 11.2 0.09999999999985551\n",
      "451500 9.8 0.09999999999985551\n",
      "452000 9.8 0.09999999999985551\n",
      "452500 6.6 0.09999999999985551\n",
      "453000 13.8 0.09999999999985551\n",
      "453500 9.5 0.09999999999985551\n",
      "454000 10.2 0.09999999999985551\n",
      "454500 10.6 0.09999999999985551\n",
      "455000 12.4 0.09999999999985551\n",
      "455500 10.9 0.09999999999985551\n",
      "456000 12.1 0.09999999999985551\n",
      "456500 10.8 0.09999999999985551\n",
      "457000 11.6 0.09999999999985551\n",
      "457500 11.7 0.09999999999985551\n",
      "458000 11.6 0.09999999999985551\n",
      "458500 13.7 0.09999999999985551\n",
      "459000 11.6 0.09999999999985551\n",
      "459500 10.5 0.09999999999985551\n",
      "460000 8.2 0.09999999999985551\n",
      "460500 9.2 0.09999999999985551\n",
      "461000 11.4 0.09999999999985551\n",
      "461500 12.1 0.09999999999985551\n",
      "462000 13.0 0.09999999999985551\n",
      "462500 5.1 0.09999999999985551\n",
      "463000 8.8 0.09999999999985551\n",
      "463500 13.1 0.09999999999985551\n",
      "464000 11.2 0.09999999999985551\n",
      "464500 8.9 0.09999999999985551\n",
      "465000 10.7 0.09999999999985551\n",
      "465500 12.7 0.09999999999985551\n",
      "466000 9.7 0.09999999999985551\n",
      "466500 12.1 0.09999999999985551\n",
      "467000 13.0 0.09999999999985551\n",
      "467500 12.5 0.09999999999985551\n",
      "468000 10.4 0.09999999999985551\n",
      "468500 12.9 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469000 13.4 0.09999999999985551\n",
      "469500 10.3 0.09999999999985551\n",
      "470000 11.3 0.09999999999985551\n",
      "470500 12.6 0.09999999999985551\n",
      "471000 11.7 0.09999999999985551\n",
      "471500 13.4 0.09999999999985551\n",
      "472000 12.9 0.09999999999985551\n",
      "472500 10.4 0.09999999999985551\n",
      "473000 8.3 0.09999999999985551\n",
      "473500 12.5 0.09999999999985551\n",
      "474000 13.9 0.09999999999985551\n",
      "474500 10.8 0.09999999999985551\n",
      "475000 14.9 0.09999999999985551\n",
      "475500 10.8 0.09999999999985551\n",
      "476000 12.3 0.09999999999985551\n",
      "476500 9.5 0.09999999999985551\n",
      "477000 13.6 0.09999999999985551\n",
      "477500 9.5 0.09999999999985551\n",
      "478000 13.8 0.09999999999985551\n",
      "478500 12.1 0.09999999999985551\n",
      "479000 7.8 0.09999999999985551\n",
      "479500 13.0 0.09999999999985551\n",
      "480000 11.6 0.09999999999985551\n",
      "480500 13.6 0.09999999999985551\n",
      "481000 12.1 0.09999999999985551\n",
      "481500 12.8 0.09999999999985551\n",
      "482000 13.8 0.09999999999985551\n",
      "482500 10.1 0.09999999999985551\n",
      "483000 11.0 0.09999999999985551\n",
      "483500 12.5 0.09999999999985551\n",
      "484000 12.4 0.09999999999985551\n",
      "484500 10.1 0.09999999999985551\n",
      "485000 10.1 0.09999999999985551\n",
      "485500 10.7 0.09999999999985551\n",
      "486000 10.0 0.09999999999985551\n",
      "486500 11.2 0.09999999999985551\n",
      "487000 12.5 0.09999999999985551\n",
      "487500 12.6 0.09999999999985551\n",
      "488000 12.8 0.09999999999985551\n",
      "488500 13.8 0.09999999999985551\n",
      "489000 7.7 0.09999999999985551\n",
      "489500 12.1 0.09999999999985551\n",
      "490000 7.7 0.09999999999985551\n",
      "490500 13.8 0.09999999999985551\n",
      "491000 9.8 0.09999999999985551\n",
      "491500 11.8 0.09999999999985551\n",
      "492000 12.0 0.09999999999985551\n",
      "492500 12.3 0.09999999999985551\n",
      "493000 14.1 0.09999999999985551\n",
      "493500 9.4 0.09999999999985551\n",
      "494000 8.9 0.09999999999985551\n",
      "494500 12.5 0.09999999999985551\n",
      "495000 11.4 0.09999999999985551\n",
      "495500 11.0 0.09999999999985551\n",
      "496000 11.8 0.09999999999985551\n",
      "496500 10.5 0.09999999999985551\n",
      "497000 11.5 0.09999999999985551\n",
      "497500 12.3 0.09999999999985551\n",
      "498000 9.9 0.09999999999985551\n",
      "498500 8.6 0.09999999999985551\n",
      "499000 9.0 0.09999999999985551\n",
      "499500 12.5 0.09999999999985551\n",
      "500000 12.4 0.09999999999985551\n",
      "Percent of succesful episodes: 8.3728%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7cbc8f40f0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

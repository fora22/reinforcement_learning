{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = True #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de034e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de034e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de034e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de034e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06de03c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06de03748>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3e0080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3e0080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3e0080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3e0080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d323828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3239e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3239e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3239e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff06d3239e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff06d3237b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Loading Model...\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./dqn/model-9999.ckpt\n",
      "Saved Model\n",
      "500 -0.4 1\n",
      "1000 0.5 1\n",
      "1500 -0.7 1\n",
      "2000 0.2 1\n",
      "2500 0.3 1\n",
      "3000 0.7 1\n",
      "3500 0.9 1\n",
      "4000 -0.6 1\n",
      "4500 -0.8 1\n",
      "5000 -0.2 1\n",
      "5500 -1.2 1\n",
      "6000 -0.6 1\n",
      "6500 -0.3 1\n",
      "7000 0.9 1\n",
      "7500 -0.3 1\n",
      "8000 -0.1 1\n",
      "8500 0.2 1\n",
      "9000 -0.1 1\n",
      "9500 -0.6 1\n",
      "10000 0.3 1\n",
      "10500 -1.1 0.9549999999999828\n",
      "11000 -0.1 0.9099999999999655\n",
      "11500 1.6 0.8649999999999483\n",
      "12000 1.7 0.819999999999931\n",
      "12500 3.0 0.7749999999999138\n",
      "13000 2.0 0.7299999999998965\n",
      "13500 2.9 0.6849999999998793\n",
      "14000 5.0 0.639999999999862\n",
      "14500 4.2 0.5949999999998448\n",
      "15000 5.9 0.5499999999998275\n",
      "15500 6.5 0.5049999999998103\n",
      "16000 5.4 0.4599999999998177\n",
      "16500 6.2 0.41499999999982823\n",
      "17000 8.2 0.36999999999983874\n",
      "17500 7.4 0.32499999999984924\n",
      "18000 9.7 0.27999999999985975\n",
      "18500 8.5 0.23499999999986562\n",
      "19000 11.0 0.18999999999986225\n",
      "19500 13.1 0.14499999999985888\n",
      "20000 10.4 0.09999999999985551\n",
      "20500 11.5 0.09999999999985551\n",
      "21000 11.7 0.09999999999985551\n",
      "21500 11.7 0.09999999999985551\n",
      "22000 9.9 0.09999999999985551\n",
      "22500 10.4 0.09999999999985551\n",
      "23000 12.5 0.09999999999985551\n",
      "23500 11.3 0.09999999999985551\n",
      "24000 12.2 0.09999999999985551\n",
      "24500 8.4 0.09999999999985551\n",
      "25000 13.6 0.09999999999985551\n",
      "25500 9.0 0.09999999999985551\n",
      "26000 10.1 0.09999999999985551\n",
      "26500 9.0 0.09999999999985551\n",
      "27000 13.4 0.09999999999985551\n",
      "27500 13.3 0.09999999999985551\n",
      "28000 11.2 0.09999999999985551\n",
      "28500 12.7 0.09999999999985551\n",
      "29000 10.3 0.09999999999985551\n",
      "29500 10.6 0.09999999999985551\n",
      "30000 11.6 0.09999999999985551\n",
      "30500 10.7 0.09999999999985551\n",
      "31000 11.5 0.09999999999985551\n",
      "31500 13.2 0.09999999999985551\n",
      "32000 9.7 0.09999999999985551\n",
      "32500 13.9 0.09999999999985551\n",
      "33000 10.1 0.09999999999985551\n",
      "33500 10.5 0.09999999999985551\n",
      "34000 12.5 0.09999999999985551\n",
      "34500 10.1 0.09999999999985551\n",
      "35000 12.7 0.09999999999985551\n",
      "35500 10.9 0.09999999999985551\n",
      "36000 11.0 0.09999999999985551\n",
      "36500 11.8 0.09999999999985551\n",
      "37000 8.7 0.09999999999985551\n",
      "37500 11.1 0.09999999999985551\n",
      "38000 10.5 0.09999999999985551\n",
      "38500 9.3 0.09999999999985551\n",
      "39000 13.0 0.09999999999985551\n",
      "39500 12.0 0.09999999999985551\n",
      "40000 10.1 0.09999999999985551\n",
      "40500 14.0 0.09999999999985551\n",
      "41000 11.1 0.09999999999985551\n",
      "41500 9.9 0.09999999999985551\n",
      "42000 11.5 0.09999999999985551\n",
      "42500 13.5 0.09999999999985551\n",
      "43000 11.2 0.09999999999985551\n",
      "43500 10.6 0.09999999999985551\n",
      "44000 12.1 0.09999999999985551\n",
      "44500 10.6 0.09999999999985551\n",
      "45000 8.5 0.09999999999985551\n",
      "45500 12.5 0.09999999999985551\n",
      "46000 11.7 0.09999999999985551\n",
      "46500 9.5 0.09999999999985551\n",
      "47000 12.2 0.09999999999985551\n",
      "47500 11.8 0.09999999999985551\n",
      "48000 11.6 0.09999999999985551\n",
      "48500 12.5 0.09999999999985551\n",
      "49000 12.4 0.09999999999985551\n",
      "49500 10.7 0.09999999999985551\n",
      "50000 12.6 0.09999999999985551\n",
      "Saved Model\n",
      "50500 13.2 0.09999999999985551\n",
      "51000 8.6 0.09999999999985551\n",
      "51500 10.8 0.09999999999985551\n",
      "52000 10.4 0.09999999999985551\n",
      "52500 10.3 0.09999999999985551\n",
      "53000 12.7 0.09999999999985551\n",
      "53500 13.8 0.09999999999985551\n",
      "54000 9.4 0.09999999999985551\n",
      "54500 9.0 0.09999999999985551\n",
      "55000 9.9 0.09999999999985551\n",
      "55500 10.2 0.09999999999985551\n",
      "56000 12.2 0.09999999999985551\n",
      "56500 11.7 0.09999999999985551\n",
      "57000 13.3 0.09999999999985551\n",
      "57500 10.9 0.09999999999985551\n",
      "58000 11.5 0.09999999999985551\n",
      "58500 8.1 0.09999999999985551\n",
      "59000 12.9 0.09999999999985551\n",
      "59500 10.8 0.09999999999985551\n",
      "60000 9.4 0.09999999999985551\n",
      "60500 10.8 0.09999999999985551\n",
      "61000 10.8 0.09999999999985551\n",
      "61500 12.5 0.09999999999985551\n",
      "62000 12.0 0.09999999999985551\n",
      "62500 10.0 0.09999999999985551\n",
      "63000 10.5 0.09999999999985551\n",
      "63500 10.2 0.09999999999985551\n",
      "64000 12.2 0.09999999999985551\n",
      "64500 11.9 0.09999999999985551\n",
      "65000 12.0 0.09999999999985551\n",
      "65500 12.0 0.09999999999985551\n",
      "66000 13.3 0.09999999999985551\n",
      "66500 11.5 0.09999999999985551\n",
      "67000 9.4 0.09999999999985551\n",
      "67500 11.3 0.09999999999985551\n",
      "68000 11.2 0.09999999999985551\n",
      "68500 11.2 0.09999999999985551\n",
      "69000 10.2 0.09999999999985551\n",
      "69500 11.3 0.09999999999985551\n",
      "70000 11.9 0.09999999999985551\n",
      "70500 10.2 0.09999999999985551\n",
      "71000 10.9 0.09999999999985551\n",
      "71500 10.8 0.09999999999985551\n",
      "72000 12.0 0.09999999999985551\n",
      "72500 9.5 0.09999999999985551\n",
      "73000 12.9 0.09999999999985551\n",
      "73500 12.0 0.09999999999985551\n",
      "74000 9.0 0.09999999999985551\n",
      "74500 10.9 0.09999999999985551\n",
      "75000 12.3 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75500 9.9 0.09999999999985551\n",
      "76000 10.4 0.09999999999985551\n",
      "76500 8.9 0.09999999999985551\n",
      "77000 8.9 0.09999999999985551\n",
      "77500 11.5 0.09999999999985551\n",
      "78000 11.4 0.09999999999985551\n",
      "78500 13.0 0.09999999999985551\n",
      "79000 10.8 0.09999999999985551\n",
      "79500 10.7 0.09999999999985551\n",
      "80000 12.3 0.09999999999985551\n",
      "80500 12.1 0.09999999999985551\n",
      "81000 10.8 0.09999999999985551\n",
      "81500 12.0 0.09999999999985551\n",
      "82000 11.6 0.09999999999985551\n",
      "82500 12.3 0.09999999999985551\n",
      "83000 10.2 0.09999999999985551\n",
      "83500 12.8 0.09999999999985551\n",
      "84000 13.3 0.09999999999985551\n",
      "84500 12.8 0.09999999999985551\n",
      "85000 8.9 0.09999999999985551\n",
      "85500 9.2 0.09999999999985551\n",
      "86000 11.0 0.09999999999985551\n",
      "86500 9.7 0.09999999999985551\n",
      "87000 11.7 0.09999999999985551\n",
      "87500 11.1 0.09999999999985551\n",
      "88000 9.9 0.09999999999985551\n",
      "88500 11.9 0.09999999999985551\n",
      "89000 10.9 0.09999999999985551\n",
      "89500 10.9 0.09999999999985551\n",
      "90000 9.0 0.09999999999985551\n",
      "90500 9.8 0.09999999999985551\n",
      "91000 11.7 0.09999999999985551\n",
      "91500 9.3 0.09999999999985551\n",
      "92000 10.8 0.09999999999985551\n",
      "92500 10.3 0.09999999999985551\n",
      "93000 12.8 0.09999999999985551\n",
      "93500 10.5 0.09999999999985551\n",
      "94000 11.0 0.09999999999985551\n",
      "94500 11.0 0.09999999999985551\n",
      "95000 11.2 0.09999999999985551\n",
      "95500 13.8 0.09999999999985551\n",
      "96000 10.4 0.09999999999985551\n",
      "96500 11.1 0.09999999999985551\n",
      "97000 9.9 0.09999999999985551\n",
      "97500 11.6 0.09999999999985551\n",
      "98000 12.1 0.09999999999985551\n",
      "98500 12.1 0.09999999999985551\n",
      "99000 11.6 0.09999999999985551\n",
      "99500 11.4 0.09999999999985551\n",
      "100000 13.5 0.09999999999985551\n",
      "Saved Model\n",
      "100500 9.4 0.09999999999985551\n",
      "101000 9.7 0.09999999999985551\n",
      "101500 10.4 0.09999999999985551\n",
      "102000 11.6 0.09999999999985551\n",
      "102500 11.0 0.09999999999985551\n",
      "103000 14.1 0.09999999999985551\n",
      "103500 8.6 0.09999999999985551\n",
      "104000 10.3 0.09999999999985551\n",
      "104500 10.9 0.09999999999985551\n",
      "105000 13.2 0.09999999999985551\n",
      "105500 10.5 0.09999999999985551\n",
      "106000 10.2 0.09999999999985551\n",
      "106500 11.3 0.09999999999985551\n",
      "107000 10.0 0.09999999999985551\n",
      "107500 8.4 0.09999999999985551\n",
      "108000 14.2 0.09999999999985551\n",
      "108500 11.5 0.09999999999985551\n",
      "109000 11.4 0.09999999999985551\n",
      "109500 10.3 0.09999999999985551\n",
      "110000 12.4 0.09999999999985551\n",
      "110500 12.7 0.09999999999985551\n",
      "111000 11.1 0.09999999999985551\n",
      "111500 9.5 0.09999999999985551\n",
      "112000 11.1 0.09999999999985551\n",
      "112500 11.8 0.09999999999985551\n",
      "113000 13.1 0.09999999999985551\n",
      "113500 14.8 0.09999999999985551\n",
      "114000 11.6 0.09999999999985551\n",
      "114500 10.9 0.09999999999985551\n",
      "115000 12.1 0.09999999999985551\n",
      "115500 12.1 0.09999999999985551\n",
      "116000 12.1 0.09999999999985551\n",
      "116500 13.9 0.09999999999985551\n",
      "117000 13.9 0.09999999999985551\n",
      "117500 10.6 0.09999999999985551\n",
      "118000 11.6 0.09999999999985551\n",
      "118500 13.1 0.09999999999985551\n",
      "119000 12.0 0.09999999999985551\n",
      "119500 12.9 0.09999999999985551\n",
      "120000 11.5 0.09999999999985551\n",
      "120500 11.2 0.09999999999985551\n",
      "121000 8.7 0.09999999999985551\n",
      "121500 11.3 0.09999999999985551\n",
      "122000 11.0 0.09999999999985551\n",
      "122500 10.7 0.09999999999985551\n",
      "123000 13.4 0.09999999999985551\n",
      "123500 12.8 0.09999999999985551\n",
      "124000 13.6 0.09999999999985551\n",
      "124500 12.2 0.09999999999985551\n",
      "125000 11.7 0.09999999999985551\n",
      "125500 10.5 0.09999999999985551\n",
      "126000 12.2 0.09999999999985551\n",
      "126500 11.8 0.09999999999985551\n",
      "127000 11.1 0.09999999999985551\n",
      "127500 11.2 0.09999999999985551\n",
      "128000 13.9 0.09999999999985551\n",
      "128500 10.9 0.09999999999985551\n",
      "129000 7.8 0.09999999999985551\n",
      "129500 11.8 0.09999999999985551\n",
      "130000 11.7 0.09999999999985551\n",
      "130500 12.2 0.09999999999985551\n",
      "131000 10.9 0.09999999999985551\n",
      "131500 12.4 0.09999999999985551\n",
      "132000 13.2 0.09999999999985551\n",
      "132500 14.0 0.09999999999985551\n",
      "133000 11.5 0.09999999999985551\n",
      "133500 11.4 0.09999999999985551\n",
      "134000 10.6 0.09999999999985551\n",
      "134500 13.6 0.09999999999985551\n",
      "135000 12.2 0.09999999999985551\n",
      "135500 9.5 0.09999999999985551\n",
      "136000 11.2 0.09999999999985551\n",
      "136500 10.9 0.09999999999985551\n",
      "137000 11.1 0.09999999999985551\n",
      "137500 13.2 0.09999999999985551\n",
      "138000 12.5 0.09999999999985551\n",
      "138500 12.0 0.09999999999985551\n",
      "139000 12.5 0.09999999999985551\n",
      "139500 11.3 0.09999999999985551\n",
      "140000 11.6 0.09999999999985551\n",
      "140500 11.6 0.09999999999985551\n",
      "141000 11.9 0.09999999999985551\n",
      "141500 13.0 0.09999999999985551\n",
      "142000 9.6 0.09999999999985551\n",
      "142500 13.0 0.09999999999985551\n",
      "143000 12.7 0.09999999999985551\n",
      "143500 12.2 0.09999999999985551\n",
      "144000 11.2 0.09999999999985551\n",
      "144500 12.7 0.09999999999985551\n",
      "145000 11.1 0.09999999999985551\n",
      "145500 10.0 0.09999999999985551\n",
      "146000 13.9 0.09999999999985551\n",
      "146500 10.7 0.09999999999985551\n",
      "147000 10.7 0.09999999999985551\n",
      "147500 13.6 0.09999999999985551\n",
      "148000 8.4 0.09999999999985551\n",
      "148500 11.5 0.09999999999985551\n",
      "149000 12.1 0.09999999999985551\n",
      "149500 14.7 0.09999999999985551\n",
      "150000 14.1 0.09999999999985551\n",
      "Saved Model\n",
      "150500 10.1 0.09999999999985551\n",
      "151000 13.5 0.09999999999985551\n",
      "151500 10.7 0.09999999999985551\n",
      "152000 10.2 0.09999999999985551\n",
      "152500 8.8 0.09999999999985551\n",
      "153000 10.1 0.09999999999985551\n",
      "153500 11.3 0.09999999999985551\n",
      "154000 13.4 0.09999999999985551\n",
      "154500 11.6 0.09999999999985551\n",
      "155000 12.4 0.09999999999985551\n",
      "155500 10.6 0.09999999999985551\n",
      "156000 10.3 0.09999999999985551\n",
      "156500 10.5 0.09999999999985551\n",
      "157000 11.3 0.09999999999985551\n",
      "157500 9.9 0.09999999999985551\n",
      "158000 13.2 0.09999999999985551\n",
      "158500 10.8 0.09999999999985551\n",
      "159000 11.8 0.09999999999985551\n",
      "159500 12.0 0.09999999999985551\n",
      "160000 12.1 0.09999999999985551\n",
      "160500 11.0 0.09999999999985551\n",
      "161000 10.2 0.09999999999985551\n",
      "161500 11.4 0.09999999999985551\n",
      "162000 11.4 0.09999999999985551\n",
      "162500 11.5 0.09999999999985551\n",
      "163000 14.1 0.09999999999985551\n",
      "163500 12.2 0.09999999999985551\n",
      "164000 12.8 0.09999999999985551\n",
      "164500 10.6 0.09999999999985551\n",
      "165000 12.8 0.09999999999985551\n",
      "165500 11.4 0.09999999999985551\n",
      "166000 10.9 0.09999999999985551\n",
      "166500 10.2 0.09999999999985551\n",
      "167000 11.2 0.09999999999985551\n",
      "167500 9.1 0.09999999999985551\n",
      "168000 11.5 0.09999999999985551\n",
      "168500 10.5 0.09999999999985551\n",
      "169000 12.5 0.09999999999985551\n",
      "169500 11.6 0.09999999999985551\n",
      "170000 14.0 0.09999999999985551\n",
      "170500 10.9 0.09999999999985551\n",
      "171000 12.1 0.09999999999985551\n",
      "171500 9.7 0.09999999999985551\n",
      "172000 13.9 0.09999999999985551\n",
      "172500 12.5 0.09999999999985551\n",
      "173000 12.8 0.09999999999985551\n",
      "173500 10.3 0.09999999999985551\n",
      "174000 10.0 0.09999999999985551\n",
      "174500 10.2 0.09999999999985551\n",
      "175000 11.7 0.09999999999985551\n",
      "175500 12.9 0.09999999999985551\n",
      "176000 11.4 0.09999999999985551\n",
      "176500 11.7 0.09999999999985551\n",
      "177000 15.2 0.09999999999985551\n",
      "177500 11.5 0.09999999999985551\n",
      "178000 9.3 0.09999999999985551\n",
      "178500 11.8 0.09999999999985551\n",
      "179000 12.6 0.09999999999985551\n",
      "179500 10.9 0.09999999999985551\n",
      "180000 12.5 0.09999999999985551\n",
      "180500 9.6 0.09999999999985551\n",
      "181000 12.4 0.09999999999985551\n",
      "181500 12.4 0.09999999999985551\n",
      "182000 10.5 0.09999999999985551\n",
      "182500 13.7 0.09999999999985551\n",
      "183000 10.5 0.09999999999985551\n",
      "183500 14.2 0.09999999999985551\n",
      "184000 13.6 0.09999999999985551\n",
      "184500 12.0 0.09999999999985551\n",
      "185000 11.7 0.09999999999985551\n",
      "185500 10.2 0.09999999999985551\n",
      "186000 12.3 0.09999999999985551\n",
      "186500 10.8 0.09999999999985551\n",
      "187000 11.4 0.09999999999985551\n",
      "187500 9.3 0.09999999999985551\n",
      "188000 12.9 0.09999999999985551\n",
      "188500 11.8 0.09999999999985551\n",
      "189000 9.5 0.09999999999985551\n",
      "189500 10.8 0.09999999999985551\n",
      "190000 10.7 0.09999999999985551\n",
      "190500 11.3 0.09999999999985551\n",
      "191000 12.1 0.09999999999985551\n",
      "191500 11.8 0.09999999999985551\n",
      "192000 9.2 0.09999999999985551\n",
      "192500 13.1 0.09999999999985551\n",
      "193000 11.5 0.09999999999985551\n",
      "193500 11.4 0.09999999999985551\n",
      "194000 11.1 0.09999999999985551\n",
      "194500 14.4 0.09999999999985551\n",
      "195000 11.6 0.09999999999985551\n",
      "195500 10.6 0.09999999999985551\n",
      "196000 12.0 0.09999999999985551\n",
      "196500 10.2 0.09999999999985551\n",
      "197000 12.7 0.09999999999985551\n",
      "197500 12.6 0.09999999999985551\n",
      "198000 11.0 0.09999999999985551\n",
      "198500 9.3 0.09999999999985551\n",
      "199000 10.8 0.09999999999985551\n",
      "199500 14.1 0.09999999999985551\n",
      "200000 11.1 0.09999999999985551\n",
      "Saved Model\n",
      "200500 14.9 0.09999999999985551\n",
      "201000 11.4 0.09999999999985551\n",
      "201500 11.9 0.09999999999985551\n",
      "202000 10.7 0.09999999999985551\n",
      "202500 11.1 0.09999999999985551\n",
      "203000 12.4 0.09999999999985551\n",
      "203500 11.1 0.09999999999985551\n",
      "204000 10.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204500 12.7 0.09999999999985551\n",
      "205000 10.8 0.09999999999985551\n",
      "205500 10.7 0.09999999999985551\n",
      "206000 10.0 0.09999999999985551\n",
      "206500 11.8 0.09999999999985551\n",
      "207000 12.5 0.09999999999985551\n",
      "207500 12.1 0.09999999999985551\n",
      "208000 11.4 0.09999999999985551\n",
      "208500 13.6 0.09999999999985551\n",
      "209000 12.1 0.09999999999985551\n",
      "209500 12.9 0.09999999999985551\n",
      "210000 10.6 0.09999999999985551\n",
      "210500 13.0 0.09999999999985551\n",
      "211000 11.8 0.09999999999985551\n",
      "211500 14.0 0.09999999999985551\n",
      "212000 11.4 0.09999999999985551\n",
      "212500 9.2 0.09999999999985551\n",
      "213000 10.2 0.09999999999985551\n",
      "213500 12.2 0.09999999999985551\n",
      "214000 12.3 0.09999999999985551\n",
      "214500 10.6 0.09999999999985551\n",
      "215000 11.4 0.09999999999985551\n",
      "215500 11.7 0.09999999999985551\n",
      "216000 12.5 0.09999999999985551\n",
      "216500 12.3 0.09999999999985551\n",
      "217000 9.5 0.09999999999985551\n",
      "217500 10.1 0.09999999999985551\n",
      "218000 13.0 0.09999999999985551\n",
      "218500 9.4 0.09999999999985551\n",
      "219000 10.7 0.09999999999985551\n",
      "219500 13.4 0.09999999999985551\n",
      "220000 11.0 0.09999999999985551\n",
      "220500 10.8 0.09999999999985551\n",
      "221000 13.3 0.09999999999985551\n",
      "221500 10.8 0.09999999999985551\n",
      "222000 11.6 0.09999999999985551\n",
      "222500 11.2 0.09999999999985551\n",
      "223000 11.7 0.09999999999985551\n",
      "223500 10.1 0.09999999999985551\n",
      "224000 12.9 0.09999999999985551\n",
      "224500 9.6 0.09999999999985551\n",
      "225000 11.5 0.09999999999985551\n",
      "225500 9.8 0.09999999999985551\n",
      "226000 12.6 0.09999999999985551\n",
      "226500 11.6 0.09999999999985551\n",
      "227000 12.5 0.09999999999985551\n",
      "227500 13.2 0.09999999999985551\n",
      "228000 10.5 0.09999999999985551\n",
      "228500 13.4 0.09999999999985551\n",
      "229000 12.7 0.09999999999985551\n",
      "229500 11.4 0.09999999999985551\n",
      "230000 13.1 0.09999999999985551\n",
      "230500 13.4 0.09999999999985551\n",
      "231000 12.1 0.09999999999985551\n",
      "231500 11.9 0.09999999999985551\n",
      "232000 9.2 0.09999999999985551\n",
      "232500 12.6 0.09999999999985551\n",
      "233000 12.5 0.09999999999985551\n",
      "233500 10.7 0.09999999999985551\n",
      "234000 11.5 0.09999999999985551\n",
      "234500 11.7 0.09999999999985551\n",
      "235000 11.4 0.09999999999985551\n",
      "235500 10.5 0.09999999999985551\n",
      "236000 11.4 0.09999999999985551\n",
      "236500 9.6 0.09999999999985551\n",
      "237000 10.6 0.09999999999985551\n",
      "237500 12.2 0.09999999999985551\n",
      "238000 13.6 0.09999999999985551\n",
      "238500 8.7 0.09999999999985551\n",
      "239000 10.0 0.09999999999985551\n",
      "239500 9.6 0.09999999999985551\n",
      "240000 11.4 0.09999999999985551\n",
      "240500 11.7 0.09999999999985551\n",
      "241000 11.1 0.09999999999985551\n",
      "241500 14.4 0.09999999999985551\n",
      "242000 12.4 0.09999999999985551\n",
      "242500 9.6 0.09999999999985551\n",
      "243000 12.6 0.09999999999985551\n",
      "243500 13.2 0.09999999999985551\n",
      "244000 9.5 0.09999999999985551\n",
      "244500 12.9 0.09999999999985551\n",
      "245000 12.6 0.09999999999985551\n",
      "245500 13.2 0.09999999999985551\n",
      "246000 11.9 0.09999999999985551\n",
      "246500 10.3 0.09999999999985551\n",
      "247000 11.9 0.09999999999985551\n",
      "247500 11.2 0.09999999999985551\n",
      "248000 11.7 0.09999999999985551\n",
      "248500 12.2 0.09999999999985551\n",
      "249000 11.5 0.09999999999985551\n",
      "249500 12.9 0.09999999999985551\n",
      "250000 11.6 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 10.9 0.09999999999985551\n",
      "251000 12.6 0.09999999999985551\n",
      "251500 12.9 0.09999999999985551\n",
      "252000 13.5 0.09999999999985551\n",
      "252500 12.4 0.09999999999985551\n",
      "253000 9.3 0.09999999999985551\n",
      "253500 13.8 0.09999999999985551\n",
      "254000 10.9 0.09999999999985551\n",
      "254500 14.9 0.09999999999985551\n",
      "255000 11.3 0.09999999999985551\n",
      "255500 14.0 0.09999999999985551\n",
      "256000 11.3 0.09999999999985551\n",
      "256500 12.1 0.09999999999985551\n",
      "257000 10.8 0.09999999999985551\n",
      "257500 11.4 0.09999999999985551\n",
      "258000 13.8 0.09999999999985551\n",
      "258500 11.9 0.09999999999985551\n",
      "259000 12.9 0.09999999999985551\n",
      "259500 14.5 0.09999999999985551\n",
      "260000 10.9 0.09999999999985551\n",
      "260500 13.0 0.09999999999985551\n",
      "261000 9.9 0.09999999999985551\n",
      "261500 14.2 0.09999999999985551\n",
      "262000 11.5 0.09999999999985551\n",
      "262500 9.1 0.09999999999985551\n",
      "263000 11.0 0.09999999999985551\n",
      "263500 11.8 0.09999999999985551\n",
      "264000 12.2 0.09999999999985551\n",
      "264500 12.8 0.09999999999985551\n",
      "265000 9.5 0.09999999999985551\n",
      "265500 13.4 0.09999999999985551\n",
      "266000 11.6 0.09999999999985551\n",
      "266500 12.4 0.09999999999985551\n",
      "267000 11.3 0.09999999999985551\n",
      "267500 12.8 0.09999999999985551\n",
      "268000 8.3 0.09999999999985551\n",
      "268500 11.7 0.09999999999985551\n",
      "269000 12.4 0.09999999999985551\n",
      "269500 13.1 0.09999999999985551\n",
      "270000 12.0 0.09999999999985551\n",
      "270500 10.1 0.09999999999985551\n",
      "271000 10.7 0.09999999999985551\n",
      "271500 12.7 0.09999999999985551\n",
      "272000 10.3 0.09999999999985551\n",
      "272500 11.0 0.09999999999985551\n",
      "273000 12.0 0.09999999999985551\n",
      "273500 13.2 0.09999999999985551\n",
      "274000 10.6 0.09999999999985551\n",
      "274500 13.0 0.09999999999985551\n",
      "275000 13.7 0.09999999999985551\n",
      "275500 12.1 0.09999999999985551\n",
      "276000 10.1 0.09999999999985551\n",
      "276500 13.0 0.09999999999985551\n",
      "277000 11.4 0.09999999999985551\n",
      "277500 12.6 0.09999999999985551\n",
      "278000 10.8 0.09999999999985551\n",
      "278500 11.7 0.09999999999985551\n",
      "279000 12.4 0.09999999999985551\n",
      "279500 10.9 0.09999999999985551\n",
      "280000 12.1 0.09999999999985551\n",
      "280500 13.7 0.09999999999985551\n",
      "281000 12.8 0.09999999999985551\n",
      "281500 12.4 0.09999999999985551\n",
      "282000 12.3 0.09999999999985551\n",
      "282500 13.1 0.09999999999985551\n",
      "283000 10.4 0.09999999999985551\n",
      "283500 13.9 0.09999999999985551\n",
      "284000 9.8 0.09999999999985551\n",
      "284500 11.6 0.09999999999985551\n",
      "285000 10.5 0.09999999999985551\n",
      "285500 11.2 0.09999999999985551\n",
      "286000 11.7 0.09999999999985551\n",
      "286500 13.7 0.09999999999985551\n",
      "287000 12.8 0.09999999999985551\n",
      "287500 12.2 0.09999999999985551\n",
      "288000 13.1 0.09999999999985551\n",
      "288500 12.2 0.09999999999985551\n",
      "289000 13.0 0.09999999999985551\n",
      "289500 11.8 0.09999999999985551\n",
      "290000 12.5 0.09999999999985551\n",
      "290500 11.6 0.09999999999985551\n",
      "291000 13.1 0.09999999999985551\n",
      "291500 14.2 0.09999999999985551\n",
      "292000 11.3 0.09999999999985551\n",
      "292500 11.5 0.09999999999985551\n",
      "293000 13.2 0.09999999999985551\n",
      "293500 9.7 0.09999999999985551\n",
      "294000 13.5 0.09999999999985551\n",
      "294500 11.6 0.09999999999985551\n",
      "295000 13.6 0.09999999999985551\n",
      "295500 10.2 0.09999999999985551\n",
      "296000 10.1 0.09999999999985551\n",
      "296500 11.5 0.09999999999985551\n",
      "297000 9.6 0.09999999999985551\n",
      "297500 11.6 0.09999999999985551\n",
      "298000 11.4 0.09999999999985551\n",
      "298500 15.5 0.09999999999985551\n",
      "299000 11.1 0.09999999999985551\n",
      "299500 11.0 0.09999999999985551\n",
      "300000 12.9 0.09999999999985551\n",
      "Saved Model\n",
      "300500 9.3 0.09999999999985551\n",
      "301000 10.4 0.09999999999985551\n",
      "301500 14.5 0.09999999999985551\n",
      "302000 10.6 0.09999999999985551\n",
      "302500 11.8 0.09999999999985551\n",
      "303000 10.6 0.09999999999985551\n",
      "303500 13.0 0.09999999999985551\n",
      "304000 10.9 0.09999999999985551\n",
      "304500 11.4 0.09999999999985551\n",
      "305000 11.2 0.09999999999985551\n",
      "305500 11.0 0.09999999999985551\n",
      "306000 11.8 0.09999999999985551\n",
      "306500 12.3 0.09999999999985551\n",
      "307000 13.9 0.09999999999985551\n",
      "307500 13.7 0.09999999999985551\n",
      "308000 11.5 0.09999999999985551\n",
      "308500 15.3 0.09999999999985551\n",
      "309000 12.9 0.09999999999985551\n",
      "309500 13.7 0.09999999999985551\n",
      "310000 11.6 0.09999999999985551\n",
      "310500 11.9 0.09999999999985551\n",
      "311000 12.8 0.09999999999985551\n",
      "311500 13.0 0.09999999999985551\n",
      "312000 11.9 0.09999999999985551\n",
      "312500 7.9 0.09999999999985551\n",
      "313000 11.9 0.09999999999985551\n",
      "313500 12.4 0.09999999999985551\n",
      "314000 10.3 0.09999999999985551\n",
      "314500 12.8 0.09999999999985551\n",
      "315000 9.7 0.09999999999985551\n",
      "315500 10.6 0.09999999999985551\n",
      "316000 9.4 0.09999999999985551\n",
      "316500 14.1 0.09999999999985551\n",
      "317000 13.1 0.09999999999985551\n",
      "317500 10.8 0.09999999999985551\n",
      "318000 10.5 0.09999999999985551\n",
      "318500 13.0 0.09999999999985551\n",
      "319000 12.9 0.09999999999985551\n",
      "319500 13.4 0.09999999999985551\n",
      "320000 12.7 0.09999999999985551\n",
      "320500 10.0 0.09999999999985551\n",
      "321000 10.0 0.09999999999985551\n",
      "321500 10.8 0.09999999999985551\n",
      "322000 13.2 0.09999999999985551\n",
      "322500 12.3 0.09999999999985551\n",
      "323000 12.1 0.09999999999985551\n",
      "323500 10.3 0.09999999999985551\n",
      "324000 13.3 0.09999999999985551\n",
      "324500 13.1 0.09999999999985551\n",
      "325000 12.1 0.09999999999985551\n",
      "325500 8.4 0.09999999999985551\n",
      "326000 10.9 0.09999999999985551\n",
      "326500 8.9 0.09999999999985551\n",
      "327000 13.9 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327500 12.2 0.09999999999985551\n",
      "328000 11.1 0.09999999999985551\n",
      "328500 10.5 0.09999999999985551\n",
      "329000 13.0 0.09999999999985551\n",
      "329500 12.2 0.09999999999985551\n",
      "330000 11.0 0.09999999999985551\n",
      "330500 11.6 0.09999999999985551\n",
      "331000 12.3 0.09999999999985551\n",
      "331500 8.9 0.09999999999985551\n",
      "332000 10.3 0.09999999999985551\n",
      "332500 12.1 0.09999999999985551\n",
      "333000 11.0 0.09999999999985551\n",
      "333500 11.5 0.09999999999985551\n",
      "334000 12.5 0.09999999999985551\n",
      "334500 12.5 0.09999999999985551\n",
      "335000 11.1 0.09999999999985551\n",
      "335500 11.7 0.09999999999985551\n",
      "336000 9.3 0.09999999999985551\n",
      "336500 11.9 0.09999999999985551\n",
      "337000 12.2 0.09999999999985551\n",
      "337500 11.0 0.09999999999985551\n",
      "338000 11.9 0.09999999999985551\n",
      "338500 8.8 0.09999999999985551\n",
      "339000 10.8 0.09999999999985551\n",
      "339500 11.5 0.09999999999985551\n",
      "340000 10.5 0.09999999999985551\n",
      "340500 12.8 0.09999999999985551\n",
      "341000 14.0 0.09999999999985551\n",
      "341500 11.2 0.09999999999985551\n",
      "342000 12.0 0.09999999999985551\n",
      "342500 12.9 0.09999999999985551\n",
      "343000 13.6 0.09999999999985551\n",
      "343500 13.1 0.09999999999985551\n",
      "344000 14.4 0.09999999999985551\n",
      "344500 10.4 0.09999999999985551\n",
      "345000 11.3 0.09999999999985551\n",
      "345500 10.4 0.09999999999985551\n",
      "346000 12.4 0.09999999999985551\n",
      "346500 12.7 0.09999999999985551\n",
      "347000 12.8 0.09999999999985551\n",
      "347500 12.8 0.09999999999985551\n",
      "348000 13.4 0.09999999999985551\n",
      "348500 12.8 0.09999999999985551\n",
      "349000 11.9 0.09999999999985551\n",
      "349500 12.8 0.09999999999985551\n",
      "350000 11.8 0.09999999999985551\n",
      "Saved Model\n",
      "350500 12.5 0.09999999999985551\n",
      "351000 11.6 0.09999999999985551\n",
      "351500 13.7 0.09999999999985551\n",
      "352000 13.2 0.09999999999985551\n",
      "352500 11.0 0.09999999999985551\n",
      "353000 13.4 0.09999999999985551\n",
      "353500 11.0 0.09999999999985551\n",
      "354000 11.4 0.09999999999985551\n",
      "354500 9.7 0.09999999999985551\n",
      "355000 12.8 0.09999999999985551\n",
      "355500 11.7 0.09999999999985551\n",
      "356000 12.2 0.09999999999985551\n",
      "356500 10.2 0.09999999999985551\n",
      "357000 11.2 0.09999999999985551\n",
      "357500 10.7 0.09999999999985551\n",
      "358000 11.6 0.09999999999985551\n",
      "358500 10.7 0.09999999999985551\n",
      "359000 10.5 0.09999999999985551\n",
      "359500 11.0 0.09999999999985551\n",
      "360000 11.4 0.09999999999985551\n",
      "360500 11.6 0.09999999999985551\n",
      "361000 11.4 0.09999999999985551\n",
      "361500 11.8 0.09999999999985551\n",
      "362000 14.6 0.09999999999985551\n",
      "362500 12.4 0.09999999999985551\n",
      "363000 10.8 0.09999999999985551\n",
      "363500 15.3 0.09999999999985551\n",
      "364000 10.0 0.09999999999985551\n",
      "364500 10.8 0.09999999999985551\n",
      "365000 14.1 0.09999999999985551\n",
      "365500 13.1 0.09999999999985551\n",
      "366000 12.6 0.09999999999985551\n",
      "366500 13.3 0.09999999999985551\n",
      "367000 12.0 0.09999999999985551\n",
      "367500 10.6 0.09999999999985551\n",
      "368000 12.6 0.09999999999985551\n",
      "368500 12.4 0.09999999999985551\n",
      "369000 13.1 0.09999999999985551\n",
      "369500 13.3 0.09999999999985551\n",
      "370000 12.4 0.09999999999985551\n",
      "370500 12.3 0.09999999999985551\n",
      "371000 10.3 0.09999999999985551\n",
      "371500 11.0 0.09999999999985551\n",
      "372000 13.0 0.09999999999985551\n",
      "372500 13.4 0.09999999999985551\n",
      "373000 13.5 0.09999999999985551\n",
      "373500 10.8 0.09999999999985551\n",
      "374000 10.5 0.09999999999985551\n",
      "374500 13.0 0.09999999999985551\n",
      "375000 9.3 0.09999999999985551\n",
      "375500 11.4 0.09999999999985551\n",
      "376000 12.2 0.09999999999985551\n",
      "376500 11.7 0.09999999999985551\n",
      "377000 14.0 0.09999999999985551\n",
      "377500 13.0 0.09999999999985551\n",
      "378000 12.5 0.09999999999985551\n",
      "378500 11.8 0.09999999999985551\n",
      "379000 11.8 0.09999999999985551\n",
      "379500 9.8 0.09999999999985551\n",
      "380000 13.6 0.09999999999985551\n",
      "380500 12.6 0.09999999999985551\n",
      "381000 12.1 0.09999999999985551\n",
      "381500 12.2 0.09999999999985551\n",
      "382000 11.4 0.09999999999985551\n",
      "382500 12.3 0.09999999999985551\n",
      "383000 13.2 0.09999999999985551\n",
      "383500 12.9 0.09999999999985551\n",
      "384000 11.6 0.09999999999985551\n",
      "384500 13.2 0.09999999999985551\n",
      "385000 12.0 0.09999999999985551\n",
      "385500 12.5 0.09999999999985551\n",
      "386000 10.8 0.09999999999985551\n",
      "386500 12.5 0.09999999999985551\n",
      "387000 11.6 0.09999999999985551\n",
      "387500 11.7 0.09999999999985551\n",
      "388000 9.5 0.09999999999985551\n",
      "388500 12.3 0.09999999999985551\n",
      "389000 11.2 0.09999999999985551\n",
      "389500 12.7 0.09999999999985551\n",
      "390000 12.1 0.09999999999985551\n",
      "390500 13.3 0.09999999999985551\n",
      "391000 10.5 0.09999999999985551\n",
      "391500 12.7 0.09999999999985551\n",
      "392000 12.2 0.09999999999985551\n",
      "392500 11.2 0.09999999999985551\n",
      "393000 13.3 0.09999999999985551\n",
      "393500 11.3 0.09999999999985551\n",
      "394000 12.6 0.09999999999985551\n",
      "394500 12.9 0.09999999999985551\n",
      "395000 12.4 0.09999999999985551\n",
      "395500 13.0 0.09999999999985551\n",
      "396000 11.7 0.09999999999985551\n",
      "396500 11.5 0.09999999999985551\n",
      "397000 14.9 0.09999999999985551\n",
      "397500 12.6 0.09999999999985551\n",
      "398000 11.8 0.09999999999985551\n",
      "398500 11.5 0.09999999999985551\n",
      "399000 12.9 0.09999999999985551\n",
      "399500 13.2 0.09999999999985551\n",
      "400000 14.3 0.09999999999985551\n",
      "Saved Model\n",
      "400500 13.9 0.09999999999985551\n",
      "401000 13.4 0.09999999999985551\n",
      "401500 10.1 0.09999999999985551\n",
      "402000 15.0 0.09999999999985551\n",
      "402500 13.1 0.09999999999985551\n",
      "403000 12.9 0.09999999999985551\n",
      "403500 12.3 0.09999999999985551\n",
      "404000 12.9 0.09999999999985551\n",
      "404500 12.5 0.09999999999985551\n",
      "405000 12.0 0.09999999999985551\n",
      "405500 10.8 0.09999999999985551\n",
      "406000 10.3 0.09999999999985551\n",
      "406500 10.2 0.09999999999985551\n",
      "407000 12.8 0.09999999999985551\n",
      "407500 13.6 0.09999999999985551\n",
      "408000 13.0 0.09999999999985551\n",
      "408500 11.2 0.09999999999985551\n",
      "409000 12.0 0.09999999999985551\n",
      "409500 14.8 0.09999999999985551\n",
      "410000 12.0 0.09999999999985551\n",
      "410500 12.6 0.09999999999985551\n",
      "411000 13.2 0.09999999999985551\n",
      "411500 13.1 0.09999999999985551\n",
      "412000 11.4 0.09999999999985551\n",
      "412500 13.0 0.09999999999985551\n",
      "413000 11.2 0.09999999999985551\n",
      "413500 11.3 0.09999999999985551\n",
      "414000 11.6 0.09999999999985551\n",
      "414500 11.6 0.09999999999985551\n",
      "415000 11.6 0.09999999999985551\n",
      "415500 10.3 0.09999999999985551\n",
      "416000 10.5 0.09999999999985551\n",
      "416500 12.7 0.09999999999985551\n",
      "417000 12.7 0.09999999999985551\n",
      "417500 13.5 0.09999999999985551\n",
      "418000 13.8 0.09999999999985551\n",
      "418500 12.9 0.09999999999985551\n",
      "419000 11.8 0.09999999999985551\n",
      "419500 13.2 0.09999999999985551\n",
      "420000 13.2 0.09999999999985551\n",
      "420500 12.3 0.09999999999985551\n",
      "421000 10.2 0.09999999999985551\n",
      "421500 11.8 0.09999999999985551\n",
      "422000 14.0 0.09999999999985551\n",
      "422500 13.3 0.09999999999985551\n",
      "423000 12.1 0.09999999999985551\n",
      "423500 12.0 0.09999999999985551\n",
      "424000 11.7 0.09999999999985551\n",
      "424500 13.8 0.09999999999985551\n",
      "425000 11.8 0.09999999999985551\n",
      "425500 11.8 0.09999999999985551\n",
      "426000 13.0 0.09999999999985551\n",
      "426500 13.0 0.09999999999985551\n",
      "427000 10.5 0.09999999999985551\n",
      "427500 11.7 0.09999999999985551\n",
      "428000 11.3 0.09999999999985551\n",
      "428500 11.5 0.09999999999985551\n",
      "429000 13.0 0.09999999999985551\n",
      "429500 13.8 0.09999999999985551\n",
      "430000 13.5 0.09999999999985551\n",
      "430500 9.2 0.09999999999985551\n",
      "431000 12.2 0.09999999999985551\n",
      "431500 15.1 0.09999999999985551\n",
      "432000 14.1 0.09999999999985551\n",
      "432500 11.8 0.09999999999985551\n",
      "433000 8.9 0.09999999999985551\n",
      "433500 13.1 0.09999999999985551\n",
      "434000 9.6 0.09999999999985551\n",
      "434500 15.0 0.09999999999985551\n",
      "435000 14.0 0.09999999999985551\n",
      "435500 12.8 0.09999999999985551\n",
      "436000 11.0 0.09999999999985551\n",
      "436500 11.2 0.09999999999985551\n",
      "437000 13.1 0.09999999999985551\n",
      "437500 12.4 0.09999999999985551\n",
      "438000 12.3 0.09999999999985551\n",
      "438500 11.2 0.09999999999985551\n",
      "439000 11.7 0.09999999999985551\n",
      "439500 10.3 0.09999999999985551\n",
      "440000 12.7 0.09999999999985551\n",
      "440500 12.6 0.09999999999985551\n",
      "441000 9.9 0.09999999999985551\n",
      "441500 12.8 0.09999999999985551\n",
      "442000 12.2 0.09999999999985551\n",
      "442500 11.5 0.09999999999985551\n",
      "443000 12.6 0.09999999999985551\n",
      "443500 12.5 0.09999999999985551\n",
      "444000 11.3 0.09999999999985551\n",
      "444500 10.3 0.09999999999985551\n",
      "445000 11.9 0.09999999999985551\n",
      "445500 12.0 0.09999999999985551\n",
      "446000 12.9 0.09999999999985551\n",
      "446500 12.6 0.09999999999985551\n",
      "447000 12.2 0.09999999999985551\n",
      "447500 12.3 0.09999999999985551\n",
      "448000 11.6 0.09999999999985551\n",
      "448500 11.8 0.09999999999985551\n",
      "449000 11.2 0.09999999999985551\n",
      "449500 13.3 0.09999999999985551\n",
      "450000 11.2 0.09999999999985551\n",
      "Saved Model\n",
      "450500 13.1 0.09999999999985551\n",
      "451000 13.4 0.09999999999985551\n",
      "451500 10.5 0.09999999999985551\n",
      "452000 11.7 0.09999999999985551\n",
      "452500 12.8 0.09999999999985551\n",
      "453000 11.1 0.09999999999985551\n",
      "453500 11.1 0.09999999999985551\n",
      "454000 11.0 0.09999999999985551\n",
      "454500 14.9 0.09999999999985551\n",
      "455000 10.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455500 14.8 0.09999999999985551\n",
      "456000 12.2 0.09999999999985551\n",
      "456500 12.5 0.09999999999985551\n",
      "457000 12.6 0.09999999999985551\n",
      "457500 11.4 0.09999999999985551\n",
      "458000 13.8 0.09999999999985551\n",
      "458500 10.0 0.09999999999985551\n",
      "459000 11.1 0.09999999999985551\n",
      "459500 10.9 0.09999999999985551\n",
      "460000 8.3 0.09999999999985551\n",
      "460500 13.6 0.09999999999985551\n",
      "461000 11.1 0.09999999999985551\n",
      "461500 11.5 0.09999999999985551\n",
      "462000 11.4 0.09999999999985551\n",
      "462500 13.3 0.09999999999985551\n",
      "463000 12.2 0.09999999999985551\n",
      "463500 11.9 0.09999999999985551\n",
      "464000 10.8 0.09999999999985551\n",
      "464500 13.1 0.09999999999985551\n",
      "465000 10.3 0.09999999999985551\n",
      "465500 13.4 0.09999999999985551\n",
      "466000 12.2 0.09999999999985551\n",
      "466500 12.5 0.09999999999985551\n",
      "467000 13.8 0.09999999999985551\n",
      "467500 12.4 0.09999999999985551\n",
      "468000 11.1 0.09999999999985551\n",
      "468500 13.2 0.09999999999985551\n",
      "469000 13.5 0.09999999999985551\n",
      "469500 12.4 0.09999999999985551\n",
      "470000 9.1 0.09999999999985551\n",
      "470500 14.5 0.09999999999985551\n",
      "471000 14.8 0.09999999999985551\n",
      "471500 13.4 0.09999999999985551\n",
      "472000 12.2 0.09999999999985551\n",
      "472500 11.5 0.09999999999985551\n",
      "473000 13.6 0.09999999999985551\n",
      "473500 11.6 0.09999999999985551\n",
      "474000 11.5 0.09999999999985551\n",
      "474500 11.3 0.09999999999985551\n",
      "475000 12.5 0.09999999999985551\n",
      "475500 12.8 0.09999999999985551\n",
      "476000 11.0 0.09999999999985551\n",
      "476500 10.6 0.09999999999985551\n",
      "477000 13.3 0.09999999999985551\n",
      "477500 13.5 0.09999999999985551\n",
      "478000 12.3 0.09999999999985551\n",
      "478500 11.7 0.09999999999985551\n",
      "479000 10.3 0.09999999999985551\n",
      "479500 13.9 0.09999999999985551\n",
      "480000 11.1 0.09999999999985551\n",
      "480500 10.3 0.09999999999985551\n",
      "481000 12.1 0.09999999999985551\n",
      "481500 12.1 0.09999999999985551\n",
      "482000 11.4 0.09999999999985551\n",
      "482500 12.4 0.09999999999985551\n",
      "483000 11.5 0.09999999999985551\n",
      "483500 9.7 0.09999999999985551\n",
      "484000 10.8 0.09999999999985551\n",
      "484500 10.2 0.09999999999985551\n",
      "485000 11.6 0.09999999999985551\n",
      "485500 11.9 0.09999999999985551\n",
      "486000 12.1 0.09999999999985551\n",
      "486500 13.3 0.09999999999985551\n",
      "487000 13.4 0.09999999999985551\n",
      "487500 12.6 0.09999999999985551\n",
      "488000 13.8 0.09999999999985551\n",
      "488500 10.8 0.09999999999985551\n",
      "489000 11.8 0.09999999999985551\n",
      "489500 14.0 0.09999999999985551\n",
      "490000 14.0 0.09999999999985551\n",
      "490500 12.9 0.09999999999985551\n",
      "491000 12.1 0.09999999999985551\n",
      "491500 11.8 0.09999999999985551\n",
      "492000 12.7 0.09999999999985551\n",
      "492500 12.0 0.09999999999985551\n",
      "493000 11.8 0.09999999999985551\n",
      "493500 11.8 0.09999999999985551\n",
      "494000 11.1 0.09999999999985551\n",
      "494500 11.2 0.09999999999985551\n",
      "495000 12.1 0.09999999999985551\n",
      "495500 13.8 0.09999999999985551\n",
      "496000 13.7 0.09999999999985551\n",
      "496500 11.3 0.09999999999985551\n",
      "497000 12.7 0.09999999999985551\n",
      "497500 11.2 0.09999999999985551\n",
      "498000 12.3 0.09999999999985551\n",
      "498500 12.6 0.09999999999985551\n",
      "499000 11.5 0.09999999999985551\n",
      "499500 13.8 0.09999999999985551\n",
      "500000 12.0 0.09999999999985551\n",
      "Percent of succesful episodes: 11.3988%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff06d5450b8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

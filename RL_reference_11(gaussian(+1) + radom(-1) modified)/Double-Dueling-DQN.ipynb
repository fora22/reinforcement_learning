{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adf932278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adf932fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adef25780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adef25780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adef25780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adef25780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee697f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee697f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee697f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee697f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3adee69d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3adee69780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 1.2 1\n",
      "1000 -0.1 1\n",
      "1500 -0.1 1\n",
      "2000 -0.1 1\n",
      "2500 -1.4 1\n",
      "3000 -0.1 1\n",
      "3500 -0.3 1\n",
      "4000 -1.5 1\n",
      "4500 -1.8 1\n",
      "5000 -0.1 1\n",
      "5500 0.1 1\n",
      "6000 -0.2 1\n",
      "6500 -0.6 1\n",
      "7000 0.4 1\n",
      "7500 0.2 1\n",
      "8000 0.0 1\n",
      "8500 -0.5 1\n",
      "9000 0.4 1\n",
      "9500 -0.1 1\n",
      "10000 0.4 1\n",
      "10500 -1.3 0.9549999999999828\n",
      "11000 -0.6 0.9099999999999655\n",
      "11500 -0.4 0.8649999999999483\n",
      "12000 -0.7 0.819999999999931\n",
      "12500 0.6 0.7749999999999138\n",
      "13000 0.2 0.7299999999998965\n",
      "13500 0.2 0.6849999999998793\n",
      "14000 -1.4 0.639999999999862\n",
      "14500 -0.5 0.5949999999998448\n",
      "15000 -0.1 0.5499999999998275\n",
      "15500 -0.2 0.5049999999998103\n",
      "16000 0.1 0.4599999999998177\n",
      "16500 -0.4 0.41499999999982823\n",
      "17000 -1.1 0.36999999999983874\n",
      "17500 -0.5 0.32499999999984924\n",
      "18000 0.7 0.27999999999985975\n",
      "18500 -0.3 0.23499999999986562\n",
      "19000 -0.1 0.18999999999986225\n",
      "19500 -0.2 0.14499999999985888\n",
      "20000 -0.5 0.09999999999985551\n",
      "20500 0.1 0.09999999999985551\n",
      "21000 -0.3 0.09999999999985551\n",
      "21500 0.2 0.09999999999985551\n",
      "22000 -0.5 0.09999999999985551\n",
      "22500 0.0 0.09999999999985551\n",
      "23000 0.3 0.09999999999985551\n",
      "23500 0.0 0.09999999999985551\n",
      "24000 -0.3 0.09999999999985551\n",
      "24500 0.5 0.09999999999985551\n",
      "25000 -0.1 0.09999999999985551\n",
      "25500 0.3 0.09999999999985551\n",
      "26000 -0.3 0.09999999999985551\n",
      "26500 -0.1 0.09999999999985551\n",
      "27000 -0.2 0.09999999999985551\n",
      "27500 -0.3 0.09999999999985551\n",
      "28000 0.9 0.09999999999985551\n",
      "28500 -0.3 0.09999999999985551\n",
      "29000 0.2 0.09999999999985551\n",
      "29500 0.1 0.09999999999985551\n",
      "30000 0.7 0.09999999999985551\n",
      "30500 -0.6 0.09999999999985551\n",
      "31000 0.0 0.09999999999985551\n",
      "31500 0.7 0.09999999999985551\n",
      "32000 0.6 0.09999999999985551\n",
      "32500 -0.1 0.09999999999985551\n",
      "33000 0.0 0.09999999999985551\n",
      "33500 -0.1 0.09999999999985551\n",
      "34000 -0.1 0.09999999999985551\n",
      "34500 -0.4 0.09999999999985551\n",
      "35000 -0.4 0.09999999999985551\n",
      "35500 0.4 0.09999999999985551\n",
      "36000 0.2 0.09999999999985551\n",
      "36500 0.2 0.09999999999985551\n",
      "37000 0.2 0.09999999999985551\n",
      "37500 0.1 0.09999999999985551\n",
      "38000 -0.5 0.09999999999985551\n",
      "38500 -0.3 0.09999999999985551\n",
      "39000 -0.2 0.09999999999985551\n",
      "39500 -0.3 0.09999999999985551\n",
      "40000 0.3 0.09999999999985551\n",
      "40500 -0.1 0.09999999999985551\n",
      "41000 0.4 0.09999999999985551\n",
      "41500 0.1 0.09999999999985551\n",
      "42000 0.4 0.09999999999985551\n",
      "42500 -0.3 0.09999999999985551\n",
      "43000 0.1 0.09999999999985551\n",
      "43500 0.9 0.09999999999985551\n",
      "44000 0.3 0.09999999999985551\n",
      "44500 0.7 0.09999999999985551\n",
      "45000 0.4 0.09999999999985551\n",
      "45500 0.7 0.09999999999985551\n",
      "46000 0.0 0.09999999999985551\n",
      "46500 0.9 0.09999999999985551\n",
      "47000 0.3 0.09999999999985551\n",
      "47500 0.3 0.09999999999985551\n",
      "48000 -0.1 0.09999999999985551\n",
      "48500 -0.3 0.09999999999985551\n",
      "49000 -0.3 0.09999999999985551\n",
      "49500 0.2 0.09999999999985551\n",
      "50000 -0.1 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.0 0.09999999999985551\n",
      "51000 0.2 0.09999999999985551\n",
      "51500 0.0 0.09999999999985551\n",
      "52000 0.5 0.09999999999985551\n",
      "52500 0.2 0.09999999999985551\n",
      "53000 0.3 0.09999999999985551\n",
      "53500 0.4 0.09999999999985551\n",
      "54000 0.4 0.09999999999985551\n",
      "54500 0.0 0.09999999999985551\n",
      "55000 0.4 0.09999999999985551\n",
      "55500 0.5 0.09999999999985551\n",
      "56000 0.2 0.09999999999985551\n",
      "56500 0.7 0.09999999999985551\n",
      "57000 0.6 0.09999999999985551\n",
      "57500 0.3 0.09999999999985551\n",
      "58000 1.1 0.09999999999985551\n",
      "58500 0.4 0.09999999999985551\n",
      "59000 1.4 0.09999999999985551\n",
      "59500 1.0 0.09999999999985551\n",
      "60000 1.0 0.09999999999985551\n",
      "60500 1.1 0.09999999999985551\n",
      "61000 0.7 0.09999999999985551\n",
      "61500 0.4 0.09999999999985551\n",
      "62000 1.0 0.09999999999985551\n",
      "62500 0.0 0.09999999999985551\n",
      "63000 1.1 0.09999999999985551\n",
      "63500 0.7 0.09999999999985551\n",
      "64000 0.7 0.09999999999985551\n",
      "64500 1.3 0.09999999999985551\n",
      "65000 1.9 0.09999999999985551\n",
      "65500 1.9 0.09999999999985551\n",
      "66000 0.1 0.09999999999985551\n",
      "66500 1.2 0.09999999999985551\n",
      "67000 1.2 0.09999999999985551\n",
      "67500 0.6 0.09999999999985551\n",
      "68000 1.6 0.09999999999985551\n",
      "68500 0.2 0.09999999999985551\n",
      "69000 1.3 0.09999999999985551\n",
      "69500 0.4 0.09999999999985551\n",
      "70000 1.0 0.09999999999985551\n",
      "70500 2.5 0.09999999999985551\n",
      "71000 1.4 0.09999999999985551\n",
      "71500 0.7 0.09999999999985551\n",
      "72000 1.0 0.09999999999985551\n",
      "72500 1.3 0.09999999999985551\n",
      "73000 1.8 0.09999999999985551\n",
      "73500 1.3 0.09999999999985551\n",
      "74000 1.2 0.09999999999985551\n",
      "74500 1.2 0.09999999999985551\n",
      "75000 1.4 0.09999999999985551\n",
      "75500 1.9 0.09999999999985551\n",
      "76000 2.1 0.09999999999985551\n",
      "76500 1.7 0.09999999999985551\n",
      "77000 2.5 0.09999999999985551\n",
      "77500 1.1 0.09999999999985551\n",
      "78000 1.5 0.09999999999985551\n",
      "78500 2.0 0.09999999999985551\n",
      "79000 1.8 0.09999999999985551\n",
      "79500 2.1 0.09999999999985551\n",
      "80000 2.9 0.09999999999985551\n",
      "80500 1.7 0.09999999999985551\n",
      "81000 1.2 0.09999999999985551\n",
      "81500 2.8 0.09999999999985551\n",
      "82000 1.1 0.09999999999985551\n",
      "82500 2.8 0.09999999999985551\n",
      "83000 3.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83500 4.2 0.09999999999985551\n",
      "84000 2.5 0.09999999999985551\n",
      "84500 1.9 0.09999999999985551\n",
      "85000 1.9 0.09999999999985551\n",
      "85500 3.3 0.09999999999985551\n",
      "86000 2.7 0.09999999999985551\n",
      "86500 3.0 0.09999999999985551\n",
      "87000 5.0 0.09999999999985551\n",
      "87500 3.7 0.09999999999985551\n",
      "88000 2.0 0.09999999999985551\n",
      "88500 4.0 0.09999999999985551\n",
      "89000 1.9 0.09999999999985551\n",
      "89500 2.8 0.09999999999985551\n",
      "90000 2.6 0.09999999999985551\n",
      "90500 4.2 0.09999999999985551\n",
      "91000 4.6 0.09999999999985551\n",
      "91500 3.5 0.09999999999985551\n",
      "92000 4.4 0.09999999999985551\n",
      "92500 4.5 0.09999999999985551\n",
      "93000 2.0 0.09999999999985551\n",
      "93500 4.4 0.09999999999985551\n",
      "94000 2.0 0.09999999999985551\n",
      "94500 7.2 0.09999999999985551\n",
      "95000 6.7 0.09999999999985551\n",
      "95500 3.6 0.09999999999985551\n",
      "96000 2.2 0.09999999999985551\n",
      "96500 3.5 0.09999999999985551\n",
      "97000 6.0 0.09999999999985551\n",
      "97500 3.5 0.09999999999985551\n",
      "98000 3.8 0.09999999999985551\n",
      "98500 6.8 0.09999999999985551\n",
      "99000 4.8 0.09999999999985551\n",
      "99500 4.2 0.09999999999985551\n",
      "100000 9.0 0.09999999999985551\n",
      "Saved Model\n",
      "100500 4.9 0.09999999999985551\n",
      "101000 7.3 0.09999999999985551\n",
      "101500 4.3 0.09999999999985551\n",
      "102000 6.6 0.09999999999985551\n",
      "102500 5.5 0.09999999999985551\n",
      "103000 5.6 0.09999999999985551\n",
      "103500 6.7 0.09999999999985551\n",
      "104000 7.5 0.09999999999985551\n",
      "104500 8.3 0.09999999999985551\n",
      "105000 6.1 0.09999999999985551\n",
      "105500 6.0 0.09999999999985551\n",
      "106000 9.7 0.09999999999985551\n",
      "106500 4.7 0.09999999999985551\n",
      "107000 6.5 0.09999999999985551\n",
      "107500 7.2 0.09999999999985551\n",
      "108000 6.1 0.09999999999985551\n",
      "108500 4.2 0.09999999999985551\n",
      "109000 8.4 0.09999999999985551\n",
      "109500 8.0 0.09999999999985551\n",
      "110000 6.1 0.09999999999985551\n",
      "110500 6.0 0.09999999999985551\n",
      "111000 8.0 0.09999999999985551\n",
      "111500 5.7 0.09999999999985551\n",
      "112000 8.4 0.09999999999985551\n",
      "112500 8.2 0.09999999999985551\n",
      "113000 6.9 0.09999999999985551\n",
      "113500 6.2 0.09999999999985551\n",
      "114000 9.4 0.09999999999985551\n",
      "114500 8.7 0.09999999999985551\n",
      "115000 7.3 0.09999999999985551\n",
      "115500 5.6 0.09999999999985551\n",
      "116000 6.7 0.09999999999985551\n",
      "116500 8.6 0.09999999999985551\n",
      "117000 7.9 0.09999999999985551\n",
      "117500 8.4 0.09999999999985551\n",
      "118000 7.1 0.09999999999985551\n",
      "118500 6.8 0.09999999999985551\n",
      "119000 7.2 0.09999999999985551\n",
      "119500 5.7 0.09999999999985551\n",
      "120000 7.9 0.09999999999985551\n",
      "120500 9.4 0.09999999999985551\n",
      "121000 8.6 0.09999999999985551\n",
      "121500 8.1 0.09999999999985551\n",
      "122000 9.1 0.09999999999985551\n",
      "122500 8.9 0.09999999999985551\n",
      "123000 9.4 0.09999999999985551\n",
      "123500 6.7 0.09999999999985551\n",
      "124000 8.2 0.09999999999985551\n",
      "124500 8.6 0.09999999999985551\n",
      "125000 6.6 0.09999999999985551\n",
      "125500 6.1 0.09999999999985551\n",
      "126000 10.2 0.09999999999985551\n",
      "126500 9.7 0.09999999999985551\n",
      "127000 7.5 0.09999999999985551\n",
      "127500 8.7 0.09999999999985551\n",
      "128000 7.0 0.09999999999985551\n",
      "128500 11.0 0.09999999999985551\n",
      "129000 5.7 0.09999999999985551\n",
      "129500 6.3 0.09999999999985551\n",
      "130000 7.4 0.09999999999985551\n",
      "130500 9.6 0.09999999999985551\n",
      "131000 8.9 0.09999999999985551\n",
      "131500 10.6 0.09999999999985551\n",
      "132000 9.2 0.09999999999985551\n",
      "132500 9.8 0.09999999999985551\n",
      "133000 7.3 0.09999999999985551\n",
      "133500 9.1 0.09999999999985551\n",
      "134000 7.8 0.09999999999985551\n",
      "134500 7.5 0.09999999999985551\n",
      "135000 6.3 0.09999999999985551\n",
      "135500 8.6 0.09999999999985551\n",
      "136000 11.0 0.09999999999985551\n",
      "136500 4.5 0.09999999999985551\n",
      "137000 9.1 0.09999999999985551\n",
      "137500 10.8 0.09999999999985551\n",
      "138000 9.4 0.09999999999985551\n",
      "138500 8.9 0.09999999999985551\n",
      "139000 7.5 0.09999999999985551\n",
      "139500 10.3 0.09999999999985551\n",
      "140000 7.5 0.09999999999985551\n",
      "140500 7.6 0.09999999999985551\n",
      "141000 7.2 0.09999999999985551\n",
      "141500 9.6 0.09999999999985551\n",
      "142000 8.2 0.09999999999985551\n",
      "142500 6.2 0.09999999999985551\n",
      "143000 6.9 0.09999999999985551\n",
      "143500 9.0 0.09999999999985551\n",
      "144000 8.2 0.09999999999985551\n",
      "144500 7.0 0.09999999999985551\n",
      "145000 9.0 0.09999999999985551\n",
      "145500 9.2 0.09999999999985551\n",
      "146000 7.5 0.09999999999985551\n",
      "146500 8.6 0.09999999999985551\n",
      "147000 8.6 0.09999999999985551\n",
      "147500 8.6 0.09999999999985551\n",
      "148000 9.5 0.09999999999985551\n",
      "148500 8.6 0.09999999999985551\n",
      "149000 5.7 0.09999999999985551\n",
      "149500 8.7 0.09999999999985551\n",
      "150000 12.0 0.09999999999985551\n",
      "Saved Model\n",
      "150500 9.9 0.09999999999985551\n",
      "151000 7.0 0.09999999999985551\n",
      "151500 8.4 0.09999999999985551\n",
      "152000 8.8 0.09999999999985551\n",
      "152500 7.5 0.09999999999985551\n",
      "153000 11.0 0.09999999999985551\n",
      "153500 8.6 0.09999999999985551\n",
      "154000 7.7 0.09999999999985551\n",
      "154500 9.5 0.09999999999985551\n",
      "155000 5.8 0.09999999999985551\n",
      "155500 8.4 0.09999999999985551\n",
      "156000 10.0 0.09999999999985551\n",
      "156500 10.1 0.09999999999985551\n",
      "157000 6.5 0.09999999999985551\n",
      "157500 7.8 0.09999999999985551\n",
      "158000 9.3 0.09999999999985551\n",
      "158500 7.7 0.09999999999985551\n",
      "159000 11.3 0.09999999999985551\n",
      "159500 9.2 0.09999999999985551\n",
      "160000 8.4 0.09999999999985551\n",
      "160500 10.0 0.09999999999985551\n",
      "161000 10.7 0.09999999999985551\n",
      "161500 9.6 0.09999999999985551\n",
      "162000 8.8 0.09999999999985551\n",
      "162500 9.8 0.09999999999985551\n",
      "163000 9.3 0.09999999999985551\n",
      "163500 7.9 0.09999999999985551\n",
      "164000 10.0 0.09999999999985551\n",
      "164500 9.1 0.09999999999985551\n",
      "165000 10.1 0.09999999999985551\n",
      "165500 6.4 0.09999999999985551\n",
      "166000 9.7 0.09999999999985551\n",
      "166500 8.9 0.09999999999985551\n",
      "167000 8.5 0.09999999999985551\n",
      "167500 9.7 0.09999999999985551\n",
      "168000 8.2 0.09999999999985551\n",
      "168500 7.4 0.09999999999985551\n",
      "169000 8.5 0.09999999999985551\n",
      "169500 6.1 0.09999999999985551\n",
      "170000 10.2 0.09999999999985551\n",
      "170500 8.4 0.09999999999985551\n",
      "171000 8.6 0.09999999999985551\n",
      "171500 11.0 0.09999999999985551\n",
      "172000 10.5 0.09999999999985551\n",
      "172500 9.4 0.09999999999985551\n",
      "173000 8.9 0.09999999999985551\n",
      "173500 9.3 0.09999999999985551\n",
      "174000 11.0 0.09999999999985551\n",
      "174500 7.1 0.09999999999985551\n",
      "175000 7.8 0.09999999999985551\n",
      "175500 9.2 0.09999999999985551\n",
      "176000 9.5 0.09999999999985551\n",
      "176500 8.5 0.09999999999985551\n",
      "177000 7.5 0.09999999999985551\n",
      "177500 6.4 0.09999999999985551\n",
      "178000 10.4 0.09999999999985551\n",
      "178500 9.4 0.09999999999985551\n",
      "179000 9.5 0.09999999999985551\n",
      "179500 11.5 0.09999999999985551\n",
      "180000 8.8 0.09999999999985551\n",
      "180500 9.8 0.09999999999985551\n",
      "181000 8.7 0.09999999999985551\n",
      "181500 7.6 0.09999999999985551\n",
      "182000 8.5 0.09999999999985551\n",
      "182500 7.7 0.09999999999985551\n",
      "183000 8.6 0.09999999999985551\n",
      "183500 7.8 0.09999999999985551\n",
      "184000 9.1 0.09999999999985551\n",
      "184500 6.6 0.09999999999985551\n",
      "185000 9.3 0.09999999999985551\n",
      "185500 8.8 0.09999999999985551\n",
      "186000 9.5 0.09999999999985551\n",
      "186500 6.1 0.09999999999985551\n",
      "187000 9.8 0.09999999999985551\n",
      "187500 7.4 0.09999999999985551\n",
      "188000 9.5 0.09999999999985551\n",
      "188500 8.9 0.09999999999985551\n",
      "189000 9.1 0.09999999999985551\n",
      "189500 10.2 0.09999999999985551\n",
      "190000 8.4 0.09999999999985551\n",
      "190500 9.0 0.09999999999985551\n",
      "191000 11.8 0.09999999999985551\n",
      "191500 7.1 0.09999999999985551\n",
      "192000 11.3 0.09999999999985551\n",
      "192500 9.5 0.09999999999985551\n",
      "193000 7.5 0.09999999999985551\n",
      "193500 10.9 0.09999999999985551\n",
      "194000 8.7 0.09999999999985551\n",
      "194500 8.5 0.09999999999985551\n",
      "195000 10.3 0.09999999999985551\n",
      "195500 8.2 0.09999999999985551\n",
      "196000 7.4 0.09999999999985551\n",
      "196500 11.1 0.09999999999985551\n",
      "197000 9.1 0.09999999999985551\n",
      "197500 9.7 0.09999999999985551\n",
      "198000 8.7 0.09999999999985551\n",
      "198500 9.4 0.09999999999985551\n",
      "199000 9.4 0.09999999999985551\n",
      "199500 12.3 0.09999999999985551\n",
      "200000 7.9 0.09999999999985551\n",
      "Saved Model\n",
      "200500 10.9 0.09999999999985551\n",
      "201000 10.9 0.09999999999985551\n",
      "201500 8.8 0.09999999999985551\n",
      "202000 8.4 0.09999999999985551\n",
      "202500 10.7 0.09999999999985551\n",
      "203000 9.5 0.09999999999985551\n",
      "203500 9.8 0.09999999999985551\n",
      "204000 6.8 0.09999999999985551\n",
      "204500 8.7 0.09999999999985551\n",
      "205000 10.3 0.09999999999985551\n",
      "205500 10.0 0.09999999999985551\n",
      "206000 9.9 0.09999999999985551\n",
      "206500 11.2 0.09999999999985551\n",
      "207000 11.3 0.09999999999985551\n",
      "207500 10.5 0.09999999999985551\n",
      "208000 8.3 0.09999999999985551\n",
      "208500 10.3 0.09999999999985551\n",
      "209000 7.5 0.09999999999985551\n",
      "209500 9.4 0.09999999999985551\n",
      "210000 6.5 0.09999999999985551\n",
      "210500 7.5 0.09999999999985551\n",
      "211000 8.7 0.09999999999985551\n",
      "211500 7.6 0.09999999999985551\n",
      "212000 10.1 0.09999999999985551\n",
      "212500 6.6 0.09999999999985551\n",
      "213000 7.6 0.09999999999985551\n",
      "213500 8.9 0.09999999999985551\n",
      "214000 8.8 0.09999999999985551\n",
      "214500 8.4 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215000 6.9 0.09999999999985551\n",
      "215500 8.9 0.09999999999985551\n",
      "216000 8.7 0.09999999999985551\n",
      "216500 8.0 0.09999999999985551\n",
      "217000 7.4 0.09999999999985551\n",
      "217500 8.1 0.09999999999985551\n",
      "218000 10.2 0.09999999999985551\n",
      "218500 10.3 0.09999999999985551\n",
      "219000 8.0 0.09999999999985551\n",
      "219500 8.7 0.09999999999985551\n",
      "220000 8.1 0.09999999999985551\n",
      "220500 9.6 0.09999999999985551\n",
      "221000 5.7 0.09999999999985551\n",
      "221500 12.0 0.09999999999985551\n",
      "222000 8.2 0.09999999999985551\n",
      "222500 9.4 0.09999999999985551\n",
      "223000 9.4 0.09999999999985551\n",
      "223500 8.6 0.09999999999985551\n",
      "224000 9.6 0.09999999999985551\n",
      "224500 9.5 0.09999999999985551\n",
      "225000 7.8 0.09999999999985551\n",
      "225500 8.0 0.09999999999985551\n",
      "226000 9.0 0.09999999999985551\n",
      "226500 9.4 0.09999999999985551\n",
      "227000 9.1 0.09999999999985551\n",
      "227500 6.8 0.09999999999985551\n",
      "228000 9.3 0.09999999999985551\n",
      "228500 9.4 0.09999999999985551\n",
      "229000 7.5 0.09999999999985551\n",
      "229500 8.7 0.09999999999985551\n",
      "230000 9.7 0.09999999999985551\n",
      "230500 10.4 0.09999999999985551\n",
      "231000 11.2 0.09999999999985551\n",
      "231500 8.2 0.09999999999985551\n",
      "232000 8.0 0.09999999999985551\n",
      "232500 8.4 0.09999999999985551\n",
      "233000 10.1 0.09999999999985551\n",
      "233500 6.7 0.09999999999985551\n",
      "234000 4.5 0.09999999999985551\n",
      "234500 9.7 0.09999999999985551\n",
      "235000 6.9 0.09999999999985551\n",
      "235500 8.5 0.09999999999985551\n",
      "236000 8.4 0.09999999999985551\n",
      "236500 10.3 0.09999999999985551\n",
      "237000 8.9 0.09999999999985551\n",
      "237500 8.0 0.09999999999985551\n",
      "238000 9.8 0.09999999999985551\n",
      "238500 11.3 0.09999999999985551\n",
      "239000 7.7 0.09999999999985551\n",
      "239500 9.3 0.09999999999985551\n",
      "240000 7.5 0.09999999999985551\n",
      "240500 9.4 0.09999999999985551\n",
      "241000 11.6 0.09999999999985551\n",
      "241500 9.6 0.09999999999985551\n",
      "242000 7.8 0.09999999999985551\n",
      "242500 10.3 0.09999999999985551\n",
      "243000 11.1 0.09999999999985551\n",
      "243500 8.9 0.09999999999985551\n",
      "244000 7.1 0.09999999999985551\n",
      "244500 8.5 0.09999999999985551\n",
      "245000 9.9 0.09999999999985551\n",
      "245500 7.7 0.09999999999985551\n",
      "246000 10.1 0.09999999999985551\n",
      "246500 9.9 0.09999999999985551\n",
      "247000 10.9 0.09999999999985551\n",
      "247500 10.4 0.09999999999985551\n",
      "248000 9.8 0.09999999999985551\n",
      "248500 10.9 0.09999999999985551\n",
      "249000 7.8 0.09999999999985551\n",
      "249500 10.6 0.09999999999985551\n",
      "250000 7.4 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 9.1 0.09999999999985551\n",
      "251000 10.4 0.09999999999985551\n",
      "251500 9.3 0.09999999999985551\n",
      "252000 10.5 0.09999999999985551\n",
      "252500 9.9 0.09999999999985551\n",
      "253000 9.6 0.09999999999985551\n",
      "253500 10.4 0.09999999999985551\n",
      "254000 10.3 0.09999999999985551\n",
      "254500 12.0 0.09999999999985551\n",
      "255000 10.5 0.09999999999985551\n",
      "255500 10.4 0.09999999999985551\n",
      "256000 11.6 0.09999999999985551\n",
      "256500 10.1 0.09999999999985551\n",
      "257000 9.2 0.09999999999985551\n",
      "257500 10.9 0.09999999999985551\n",
      "258000 11.3 0.09999999999985551\n",
      "258500 7.7 0.09999999999985551\n",
      "259000 10.0 0.09999999999985551\n",
      "259500 12.0 0.09999999999985551\n",
      "260000 9.5 0.09999999999985551\n",
      "260500 8.3 0.09999999999985551\n",
      "261000 8.9 0.09999999999985551\n",
      "261500 10.9 0.09999999999985551\n",
      "262000 10.5 0.09999999999985551\n",
      "262500 7.2 0.09999999999985551\n",
      "263000 9.9 0.09999999999985551\n",
      "263500 10.2 0.09999999999985551\n",
      "264000 10.6 0.09999999999985551\n",
      "264500 7.3 0.09999999999985551\n",
      "265000 12.1 0.09999999999985551\n",
      "265500 11.7 0.09999999999985551\n",
      "266000 8.4 0.09999999999985551\n",
      "266500 9.7 0.09999999999985551\n",
      "267000 10.2 0.09999999999985551\n",
      "267500 9.5 0.09999999999985551\n",
      "268000 10.6 0.09999999999985551\n",
      "268500 7.7 0.09999999999985551\n",
      "269000 11.3 0.09999999999985551\n",
      "269500 9.3 0.09999999999985551\n",
      "270000 11.1 0.09999999999985551\n",
      "270500 6.3 0.09999999999985551\n",
      "271000 10.2 0.09999999999985551\n",
      "271500 8.6 0.09999999999985551\n",
      "272000 10.2 0.09999999999985551\n",
      "272500 9.3 0.09999999999985551\n",
      "273000 9.3 0.09999999999985551\n",
      "273500 7.0 0.09999999999985551\n",
      "274000 8.1 0.09999999999985551\n",
      "274500 9.3 0.09999999999985551\n",
      "275000 9.2 0.09999999999985551\n",
      "275500 10.7 0.09999999999985551\n",
      "276000 10.1 0.09999999999985551\n",
      "276500 10.0 0.09999999999985551\n",
      "277000 9.9 0.09999999999985551\n",
      "277500 10.9 0.09999999999985551\n",
      "278000 10.2 0.09999999999985551\n",
      "278500 7.5 0.09999999999985551\n",
      "279000 9.6 0.09999999999985551\n",
      "279500 9.3 0.09999999999985551\n",
      "280000 9.8 0.09999999999985551\n",
      "280500 9.1 0.09999999999985551\n",
      "281000 10.7 0.09999999999985551\n",
      "281500 9.3 0.09999999999985551\n",
      "282000 9.8 0.09999999999985551\n",
      "282500 8.1 0.09999999999985551\n",
      "283000 10.4 0.09999999999985551\n",
      "283500 7.7 0.09999999999985551\n",
      "284000 10.1 0.09999999999985551\n",
      "284500 10.6 0.09999999999985551\n",
      "285000 11.1 0.09999999999985551\n",
      "285500 9.2 0.09999999999985551\n",
      "286000 8.1 0.09999999999985551\n",
      "286500 10.5 0.09999999999985551\n",
      "287000 11.0 0.09999999999985551\n",
      "287500 11.4 0.09999999999985551\n",
      "288000 11.4 0.09999999999985551\n",
      "288500 9.2 0.09999999999985551\n",
      "289000 12.3 0.09999999999985551\n",
      "289500 10.7 0.09999999999985551\n",
      "290000 10.0 0.09999999999985551\n",
      "290500 10.9 0.09999999999985551\n",
      "291000 10.0 0.09999999999985551\n",
      "291500 8.5 0.09999999999985551\n",
      "292000 9.9 0.09999999999985551\n",
      "292500 9.4 0.09999999999985551\n",
      "293000 8.7 0.09999999999985551\n",
      "293500 6.4 0.09999999999985551\n",
      "294000 8.9 0.09999999999985551\n",
      "294500 10.3 0.09999999999985551\n",
      "295000 12.1 0.09999999999985551\n",
      "295500 10.2 0.09999999999985551\n",
      "296000 9.1 0.09999999999985551\n",
      "296500 9.6 0.09999999999985551\n",
      "297000 10.6 0.09999999999985551\n",
      "297500 8.9 0.09999999999985551\n",
      "298000 9.6 0.09999999999985551\n",
      "298500 10.4 0.09999999999985551\n",
      "299000 7.2 0.09999999999985551\n",
      "299500 9.0 0.09999999999985551\n",
      "300000 9.8 0.09999999999985551\n",
      "Saved Model\n",
      "300500 8.7 0.09999999999985551\n",
      "301000 10.5 0.09999999999985551\n",
      "301500 11.1 0.09999999999985551\n",
      "302000 9.2 0.09999999999985551\n",
      "302500 9.6 0.09999999999985551\n",
      "303000 8.9 0.09999999999985551\n",
      "303500 10.4 0.09999999999985551\n",
      "304000 10.0 0.09999999999985551\n",
      "304500 12.1 0.09999999999985551\n",
      "305000 10.7 0.09999999999985551\n",
      "305500 7.9 0.09999999999985551\n",
      "306000 10.8 0.09999999999985551\n",
      "306500 9.9 0.09999999999985551\n",
      "307000 10.7 0.09999999999985551\n",
      "307500 10.5 0.09999999999985551\n",
      "308000 8.7 0.09999999999985551\n",
      "308500 8.3 0.09999999999985551\n",
      "309000 10.6 0.09999999999985551\n",
      "309500 10.3 0.09999999999985551\n",
      "310000 7.2 0.09999999999985551\n",
      "310500 10.3 0.09999999999985551\n",
      "311000 9.1 0.09999999999985551\n",
      "311500 13.2 0.09999999999985551\n",
      "312000 9.7 0.09999999999985551\n",
      "312500 9.2 0.09999999999985551\n",
      "313000 8.2 0.09999999999985551\n",
      "313500 9.5 0.09999999999985551\n",
      "314000 8.5 0.09999999999985551\n",
      "314500 9.8 0.09999999999985551\n",
      "315000 10.5 0.09999999999985551\n",
      "315500 7.8 0.09999999999985551\n",
      "316000 8.9 0.09999999999985551\n",
      "316500 6.5 0.09999999999985551\n",
      "317000 11.4 0.09999999999985551\n",
      "317500 7.9 0.09999999999985551\n",
      "318000 9.6 0.09999999999985551\n",
      "318500 10.8 0.09999999999985551\n",
      "319000 11.6 0.09999999999985551\n",
      "319500 11.0 0.09999999999985551\n",
      "320000 10.8 0.09999999999985551\n",
      "320500 10.7 0.09999999999985551\n",
      "321000 11.3 0.09999999999985551\n",
      "321500 11.9 0.09999999999985551\n",
      "322000 10.7 0.09999999999985551\n",
      "322500 9.9 0.09999999999985551\n",
      "323000 9.2 0.09999999999985551\n",
      "323500 10.9 0.09999999999985551\n",
      "324000 10.1 0.09999999999985551\n",
      "324500 8.5 0.09999999999985551\n",
      "325000 10.5 0.09999999999985551\n",
      "325500 10.4 0.09999999999985551\n",
      "326000 8.7 0.09999999999985551\n",
      "326500 12.5 0.09999999999985551\n",
      "327000 8.5 0.09999999999985551\n",
      "327500 10.3 0.09999999999985551\n",
      "328000 8.0 0.09999999999985551\n",
      "328500 9.0 0.09999999999985551\n",
      "329000 10.1 0.09999999999985551\n",
      "329500 10.0 0.09999999999985551\n",
      "330000 9.5 0.09999999999985551\n",
      "330500 8.2 0.09999999999985551\n",
      "331000 9.8 0.09999999999985551\n",
      "331500 12.1 0.09999999999985551\n",
      "332000 10.5 0.09999999999985551\n",
      "332500 11.8 0.09999999999985551\n",
      "333000 7.7 0.09999999999985551\n",
      "333500 11.5 0.09999999999985551\n",
      "334000 9.6 0.09999999999985551\n",
      "334500 11.9 0.09999999999985551\n",
      "335000 9.7 0.09999999999985551\n",
      "335500 7.4 0.09999999999985551\n",
      "336000 8.1 0.09999999999985551\n",
      "336500 10.2 0.09999999999985551\n",
      "337000 11.9 0.09999999999985551\n",
      "337500 8.2 0.09999999999985551\n",
      "338000 9.8 0.09999999999985551\n",
      "338500 10.6 0.09999999999985551\n",
      "339000 9.4 0.09999999999985551\n",
      "339500 11.7 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340000 11.1 0.09999999999985551\n",
      "340500 9.1 0.09999999999985551\n",
      "341000 8.3 0.09999999999985551\n",
      "341500 8.3 0.09999999999985551\n",
      "342000 8.9 0.09999999999985551\n",
      "342500 10.1 0.09999999999985551\n",
      "343000 8.0 0.09999999999985551\n",
      "343500 10.7 0.09999999999985551\n",
      "344000 10.2 0.09999999999985551\n",
      "344500 8.6 0.09999999999985551\n",
      "345000 13.2 0.09999999999985551\n",
      "345500 7.8 0.09999999999985551\n",
      "346000 11.7 0.09999999999985551\n",
      "346500 10.2 0.09999999999985551\n",
      "347000 9.6 0.09999999999985551\n",
      "347500 7.7 0.09999999999985551\n",
      "348000 9.7 0.09999999999985551\n",
      "348500 9.2 0.09999999999985551\n",
      "349000 8.4 0.09999999999985551\n",
      "349500 9.4 0.09999999999985551\n",
      "350000 11.1 0.09999999999985551\n",
      "Saved Model\n",
      "350500 9.7 0.09999999999985551\n",
      "351000 8.7 0.09999999999985551\n",
      "351500 10.1 0.09999999999985551\n",
      "352000 12.3 0.09999999999985551\n",
      "352500 12.7 0.09999999999985551\n",
      "353000 7.8 0.09999999999985551\n",
      "353500 10.9 0.09999999999985551\n",
      "354000 9.4 0.09999999999985551\n",
      "354500 8.3 0.09999999999985551\n",
      "355000 10.0 0.09999999999985551\n",
      "355500 6.3 0.09999999999985551\n",
      "356000 12.3 0.09999999999985551\n",
      "356500 8.2 0.09999999999985551\n",
      "357000 9.7 0.09999999999985551\n",
      "357500 9.0 0.09999999999985551\n",
      "358000 12.4 0.09999999999985551\n",
      "358500 11.3 0.09999999999985551\n",
      "359000 12.1 0.09999999999985551\n",
      "359500 10.9 0.09999999999985551\n",
      "360000 9.3 0.09999999999985551\n",
      "360500 7.4 0.09999999999985551\n",
      "361000 11.5 0.09999999999985551\n",
      "361500 7.9 0.09999999999985551\n",
      "362000 10.5 0.09999999999985551\n",
      "362500 9.6 0.09999999999985551\n",
      "363000 10.9 0.09999999999985551\n",
      "363500 8.0 0.09999999999985551\n",
      "364000 11.9 0.09999999999985551\n",
      "364500 11.9 0.09999999999985551\n",
      "365000 8.8 0.09999999999985551\n",
      "365500 10.6 0.09999999999985551\n",
      "366000 7.4 0.09999999999985551\n",
      "366500 10.5 0.09999999999985551\n",
      "367000 8.4 0.09999999999985551\n",
      "367500 10.5 0.09999999999985551\n",
      "368000 11.2 0.09999999999985551\n",
      "368500 11.2 0.09999999999985551\n",
      "369000 11.9 0.09999999999985551\n",
      "369500 8.8 0.09999999999985551\n",
      "370000 9.4 0.09999999999985551\n",
      "370500 11.5 0.09999999999985551\n",
      "371000 11.3 0.09999999999985551\n",
      "371500 8.9 0.09999999999985551\n",
      "372000 9.3 0.09999999999985551\n",
      "372500 9.4 0.09999999999985551\n",
      "373000 12.4 0.09999999999985551\n",
      "373500 10.0 0.09999999999985551\n",
      "374000 10.4 0.09999999999985551\n",
      "374500 9.5 0.09999999999985551\n",
      "375000 11.5 0.09999999999985551\n",
      "375500 9.5 0.09999999999985551\n",
      "376000 10.8 0.09999999999985551\n",
      "376500 11.5 0.09999999999985551\n",
      "377000 11.1 0.09999999999985551\n",
      "377500 11.3 0.09999999999985551\n",
      "378000 12.8 0.09999999999985551\n",
      "378500 10.0 0.09999999999985551\n",
      "379000 9.9 0.09999999999985551\n",
      "379500 11.2 0.09999999999985551\n",
      "380000 12.7 0.09999999999985551\n",
      "380500 9.7 0.09999999999985551\n",
      "381000 9.2 0.09999999999985551\n",
      "381500 11.4 0.09999999999985551\n",
      "382000 11.5 0.09999999999985551\n",
      "382500 9.5 0.09999999999985551\n",
      "383000 11.3 0.09999999999985551\n",
      "383500 11.8 0.09999999999985551\n",
      "384000 11.0 0.09999999999985551\n",
      "384500 12.3 0.09999999999985551\n",
      "385000 10.8 0.09999999999985551\n",
      "385500 9.3 0.09999999999985551\n",
      "386000 11.9 0.09999999999985551\n",
      "386500 12.8 0.09999999999985551\n",
      "387000 10.9 0.09999999999985551\n",
      "387500 9.2 0.09999999999985551\n",
      "388000 10.9 0.09999999999985551\n",
      "388500 12.6 0.09999999999985551\n",
      "389000 10.1 0.09999999999985551\n",
      "389500 9.1 0.09999999999985551\n",
      "390000 11.5 0.09999999999985551\n",
      "390500 11.6 0.09999999999985551\n",
      "391000 9.1 0.09999999999985551\n",
      "391500 7.6 0.09999999999985551\n",
      "392000 10.6 0.09999999999985551\n",
      "392500 11.7 0.09999999999985551\n",
      "393000 10.2 0.09999999999985551\n",
      "393500 13.0 0.09999999999985551\n",
      "394000 10.9 0.09999999999985551\n",
      "394500 11.2 0.09999999999985551\n",
      "395000 10.1 0.09999999999985551\n",
      "395500 12.9 0.09999999999985551\n",
      "396000 10.5 0.09999999999985551\n",
      "396500 13.7 0.09999999999985551\n",
      "397000 11.5 0.09999999999985551\n",
      "397500 11.6 0.09999999999985551\n",
      "398000 8.9 0.09999999999985551\n",
      "398500 10.9 0.09999999999985551\n",
      "399000 10.2 0.09999999999985551\n",
      "399500 9.4 0.09999999999985551\n",
      "400000 10.0 0.09999999999985551\n",
      "Saved Model\n",
      "400500 12.0 0.09999999999985551\n",
      "401000 9.4 0.09999999999985551\n",
      "401500 10.4 0.09999999999985551\n",
      "402000 9.7 0.09999999999985551\n",
      "402500 9.3 0.09999999999985551\n",
      "403000 6.6 0.09999999999985551\n",
      "403500 11.5 0.09999999999985551\n",
      "404000 10.5 0.09999999999985551\n",
      "404500 11.6 0.09999999999985551\n",
      "405000 11.8 0.09999999999985551\n",
      "405500 12.4 0.09999999999985551\n",
      "406000 8.8 0.09999999999985551\n",
      "406500 11.6 0.09999999999985551\n",
      "407000 12.1 0.09999999999985551\n",
      "407500 13.3 0.09999999999985551\n",
      "408000 11.4 0.09999999999985551\n",
      "408500 12.1 0.09999999999985551\n",
      "409000 10.7 0.09999999999985551\n",
      "409500 7.1 0.09999999999985551\n",
      "410000 12.3 0.09999999999985551\n",
      "410500 11.6 0.09999999999985551\n",
      "411000 9.9 0.09999999999985551\n",
      "411500 10.8 0.09999999999985551\n",
      "412000 8.1 0.09999999999985551\n",
      "412500 11.0 0.09999999999985551\n",
      "413000 10.0 0.09999999999985551\n",
      "413500 9.6 0.09999999999985551\n",
      "414000 8.7 0.09999999999985551\n",
      "414500 11.9 0.09999999999985551\n",
      "415000 9.7 0.09999999999985551\n",
      "415500 7.8 0.09999999999985551\n",
      "416000 11.7 0.09999999999985551\n",
      "416500 10.6 0.09999999999985551\n",
      "417000 9.9 0.09999999999985551\n",
      "417500 9.1 0.09999999999985551\n",
      "418000 10.5 0.09999999999985551\n",
      "418500 10.1 0.09999999999985551\n",
      "419000 12.4 0.09999999999985551\n",
      "419500 10.4 0.09999999999985551\n",
      "420000 11.4 0.09999999999985551\n",
      "420500 9.5 0.09999999999985551\n",
      "421000 10.4 0.09999999999985551\n",
      "421500 9.8 0.09999999999985551\n",
      "422000 11.5 0.09999999999985551\n",
      "422500 12.9 0.09999999999985551\n",
      "423000 12.1 0.09999999999985551\n",
      "423500 11.6 0.09999999999985551\n",
      "424000 11.7 0.09999999999985551\n",
      "424500 9.8 0.09999999999985551\n",
      "425000 7.2 0.09999999999985551\n",
      "425500 10.7 0.09999999999985551\n",
      "426000 11.2 0.09999999999985551\n",
      "426500 7.1 0.09999999999985551\n",
      "427000 10.5 0.09999999999985551\n",
      "427500 9.5 0.09999999999985551\n",
      "428000 12.9 0.09999999999985551\n",
      "428500 12.9 0.09999999999985551\n",
      "429000 12.6 0.09999999999985551\n",
      "429500 8.8 0.09999999999985551\n",
      "430000 9.9 0.09999999999985551\n",
      "430500 13.3 0.09999999999985551\n",
      "431000 12.5 0.09999999999985551\n",
      "431500 11.9 0.09999999999985551\n",
      "432000 11.2 0.09999999999985551\n",
      "432500 8.7 0.09999999999985551\n",
      "433000 9.9 0.09999999999985551\n",
      "433500 9.3 0.09999999999985551\n",
      "434000 9.6 0.09999999999985551\n",
      "434500 10.7 0.09999999999985551\n",
      "435000 15.2 0.09999999999985551\n",
      "435500 10.6 0.09999999999985551\n",
      "436000 10.2 0.09999999999985551\n",
      "436500 6.8 0.09999999999985551\n",
      "437000 11.8 0.09999999999985551\n",
      "437500 12.4 0.09999999999985551\n",
      "438000 11.2 0.09999999999985551\n",
      "438500 10.0 0.09999999999985551\n",
      "439000 10.8 0.09999999999985551\n",
      "439500 9.8 0.09999999999985551\n",
      "440000 9.7 0.09999999999985551\n",
      "440500 9.5 0.09999999999985551\n",
      "441000 9.5 0.09999999999985551\n",
      "441500 12.2 0.09999999999985551\n",
      "442000 11.7 0.09999999999985551\n",
      "442500 12.1 0.09999999999985551\n",
      "443000 10.1 0.09999999999985551\n",
      "443500 9.8 0.09999999999985551\n",
      "444000 11.0 0.09999999999985551\n",
      "444500 12.0 0.09999999999985551\n",
      "445000 10.7 0.09999999999985551\n",
      "445500 13.4 0.09999999999985551\n",
      "446000 10.1 0.09999999999985551\n",
      "446500 11.9 0.09999999999985551\n",
      "447000 11.7 0.09999999999985551\n",
      "447500 9.8 0.09999999999985551\n",
      "448000 9.9 0.09999999999985551\n",
      "448500 11.3 0.09999999999985551\n",
      "449000 11.9 0.09999999999985551\n",
      "449500 9.2 0.09999999999985551\n",
      "450000 10.6 0.09999999999985551\n",
      "Saved Model\n",
      "450500 14.7 0.09999999999985551\n",
      "451000 8.1 0.09999999999985551\n",
      "451500 10.1 0.09999999999985551\n",
      "452000 11.4 0.09999999999985551\n",
      "452500 12.4 0.09999999999985551\n",
      "453000 11.7 0.09999999999985551\n",
      "453500 10.6 0.09999999999985551\n",
      "454000 13.4 0.09999999999985551\n",
      "454500 12.5 0.09999999999985551\n",
      "455000 9.3 0.09999999999985551\n",
      "455500 11.9 0.09999999999985551\n",
      "456000 11.9 0.09999999999985551\n",
      "456500 9.8 0.09999999999985551\n",
      "457000 13.2 0.09999999999985551\n",
      "457500 10.1 0.09999999999985551\n",
      "458000 11.2 0.09999999999985551\n",
      "458500 11.5 0.09999999999985551\n",
      "459000 9.6 0.09999999999985551\n",
      "459500 11.2 0.09999999999985551\n",
      "460000 11.6 0.09999999999985551\n",
      "460500 10.5 0.09999999999985551\n",
      "461000 12.4 0.09999999999985551\n",
      "461500 8.9 0.09999999999985551\n",
      "462000 12.2 0.09999999999985551\n",
      "462500 9.1 0.09999999999985551\n",
      "463000 9.9 0.09999999999985551\n",
      "463500 10.7 0.09999999999985551\n",
      "464000 10.9 0.09999999999985551\n",
      "464500 9.8 0.09999999999985551\n",
      "465000 12.4 0.09999999999985551\n",
      "465500 7.6 0.09999999999985551\n",
      "466000 9.8 0.09999999999985551\n",
      "466500 13.3 0.09999999999985551\n",
      "467000 12.7 0.09999999999985551\n",
      "467500 7.7 0.09999999999985551\n",
      "468000 10.4 0.09999999999985551\n",
      "468500 10.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469000 9.8 0.09999999999985551\n",
      "469500 10.0 0.09999999999985551\n",
      "470000 10.6 0.09999999999985551\n",
      "470500 8.9 0.09999999999985551\n",
      "471000 11.3 0.09999999999985551\n",
      "471500 12.3 0.09999999999985551\n",
      "472000 11.8 0.09999999999985551\n",
      "472500 9.5 0.09999999999985551\n",
      "473000 9.7 0.09999999999985551\n",
      "473500 12.5 0.09999999999985551\n",
      "474000 10.4 0.09999999999985551\n",
      "474500 11.1 0.09999999999985551\n",
      "475000 9.9 0.09999999999985551\n",
      "475500 12.2 0.09999999999985551\n",
      "476000 13.1 0.09999999999985551\n",
      "476500 8.0 0.09999999999985551\n",
      "477000 10.0 0.09999999999985551\n",
      "477500 11.3 0.09999999999985551\n",
      "478000 13.1 0.09999999999985551\n",
      "478500 11.7 0.09999999999985551\n",
      "479000 12.9 0.09999999999985551\n",
      "479500 9.1 0.09999999999985551\n",
      "480000 10.5 0.09999999999985551\n",
      "480500 8.6 0.09999999999985551\n",
      "481000 12.2 0.09999999999985551\n",
      "481500 10.2 0.09999999999985551\n",
      "482000 11.1 0.09999999999985551\n",
      "482500 8.1 0.09999999999985551\n",
      "483000 10.4 0.09999999999985551\n",
      "483500 10.3 0.09999999999985551\n",
      "484000 10.4 0.09999999999985551\n",
      "484500 9.8 0.09999999999985551\n",
      "485000 11.3 0.09999999999985551\n",
      "485500 10.3 0.09999999999985551\n",
      "486000 15.6 0.09999999999985551\n",
      "486500 9.7 0.09999999999985551\n",
      "487000 11.3 0.09999999999985551\n",
      "487500 11.2 0.09999999999985551\n",
      "488000 10.8 0.09999999999985551\n",
      "488500 8.9 0.09999999999985551\n",
      "489000 8.3 0.09999999999985551\n",
      "489500 10.2 0.09999999999985551\n",
      "490000 11.8 0.09999999999985551\n",
      "490500 10.9 0.09999999999985551\n",
      "491000 13.6 0.09999999999985551\n",
      "491500 12.7 0.09999999999985551\n",
      "492000 9.7 0.09999999999985551\n",
      "492500 7.5 0.09999999999985551\n",
      "493000 11.1 0.09999999999985551\n",
      "493500 9.5 0.09999999999985551\n",
      "494000 10.4 0.09999999999985551\n",
      "494500 11.2 0.09999999999985551\n",
      "495000 10.4 0.09999999999985551\n",
      "495500 9.5 0.09999999999985551\n",
      "496000 10.0 0.09999999999985551\n",
      "496500 9.4 0.09999999999985551\n",
      "497000 10.0 0.09999999999985551\n",
      "497500 9.5 0.09999999999985551\n",
      "498000 11.5 0.09999999999985551\n",
      "498500 8.7 0.09999999999985551\n",
      "499000 11.8 0.09999999999985551\n",
      "499500 11.8 0.09999999999985551\n",
      "500000 11.0 0.09999999999985551\n",
      "Percent of succesful episodes: 7.9188%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3adf0e25c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

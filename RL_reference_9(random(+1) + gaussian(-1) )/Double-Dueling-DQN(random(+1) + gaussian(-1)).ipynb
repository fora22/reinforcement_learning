{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
    "# \n",
    "# In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
    "# \n",
    "# For more reinforcment learning tutorials, see:\n",
    "# https://github.com/awjuliani/DeepRL-Agents\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "import os\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# ### Load the game environment\n",
    "\n",
    "# Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gridworld import gameEnv\n",
    "\n",
    "env = gameEnv(partial=False,size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self,h_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
    "        self.conv1 = slim.conv2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = slim.conv2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = slim.conv2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = slim.conv2d( \\\n",
    "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
    "        self.streamA = slim.flatten(self.streamAC)\n",
    "        self.streamV = slim.flatten(self.streamVC)\n",
    "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
    "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout,1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processState(states):\n",
    "    return np.reshape(states,[21168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars,tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf52101d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf52101d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf52101d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf52101d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf5210cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf52100b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf47f0f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf47f0f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf47f0f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf47f0f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf56f3e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf56f3e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf56f3e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf56f3e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f1cf4733a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf4733940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf4733940>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf4733940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf4733940>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf49ae0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf49ae0b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf49ae0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f1cf49ae0b8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Saved Model\n",
      "500 0.9 1\n",
      "1000 0.8 1\n",
      "1500 1.7 1\n",
      "2000 0.6 1\n",
      "2500 0.2 1\n",
      "3000 1.0 1\n",
      "3500 -0.4 1\n",
      "4000 0.9 1\n",
      "4500 -0.1 1\n",
      "5000 0.7 1\n",
      "5500 0.8 1\n",
      "6000 0.1 1\n",
      "6500 0.2 1\n",
      "7000 1.1 1\n",
      "7500 2.3 1\n",
      "8000 1.1 1\n",
      "8500 0.6 1\n",
      "9000 0.7 1\n",
      "9500 -0.2 1\n",
      "10000 0.8 1\n",
      "10500 1.5 0.9549999999999828\n",
      "11000 1.6 0.9099999999999655\n",
      "11500 0.8 0.8649999999999483\n",
      "12000 -0.1 0.819999999999931\n",
      "12500 0.9 0.7749999999999138\n",
      "13000 0.7 0.7299999999998965\n",
      "13500 1.1 0.6849999999998793\n",
      "14000 0.2 0.639999999999862\n",
      "14500 1.0 0.5949999999998448\n",
      "15000 1.5 0.5499999999998275\n",
      "15500 0.6 0.5049999999998103\n",
      "16000 0.8 0.4599999999998177\n",
      "16500 0.0 0.41499999999982823\n",
      "17000 1.1 0.36999999999983874\n",
      "17500 0.3 0.32499999999984924\n",
      "18000 0.6 0.27999999999985975\n",
      "18500 -0.4 0.23499999999986562\n",
      "19000 1.0 0.18999999999986225\n",
      "19500 0.6 0.14499999999985888\n",
      "20000 0.5 0.09999999999985551\n",
      "20500 1.3 0.09999999999985551\n",
      "21000 0.5 0.09999999999985551\n",
      "21500 0.0 0.09999999999985551\n",
      "22000 0.3 0.09999999999985551\n",
      "22500 0.8 0.09999999999985551\n",
      "23000 0.1 0.09999999999985551\n",
      "23500 0.8 0.09999999999985551\n",
      "24000 0.8 0.09999999999985551\n",
      "24500 0.3 0.09999999999985551\n",
      "25000 0.8 0.09999999999985551\n",
      "25500 0.8 0.09999999999985551\n",
      "26000 0.8 0.09999999999985551\n",
      "26500 0.2 0.09999999999985551\n",
      "27000 0.2 0.09999999999985551\n",
      "27500 0.4 0.09999999999985551\n",
      "28000 0.8 0.09999999999985551\n",
      "28500 0.4 0.09999999999985551\n",
      "29000 0.6 0.09999999999985551\n",
      "29500 0.2 0.09999999999985551\n",
      "30000 0.2 0.09999999999985551\n",
      "30500 0.4 0.09999999999985551\n",
      "31000 0.7 0.09999999999985551\n",
      "31500 0.5 0.09999999999985551\n",
      "32000 1.3 0.09999999999985551\n",
      "32500 0.6 0.09999999999985551\n",
      "33000 0.1 0.09999999999985551\n",
      "33500 0.3 0.09999999999985551\n",
      "34000 0.6 0.09999999999985551\n",
      "34500 0.1 0.09999999999985551\n",
      "35000 0.3 0.09999999999985551\n",
      "35500 0.7 0.09999999999985551\n",
      "36000 0.1 0.09999999999985551\n",
      "36500 0.3 0.09999999999985551\n",
      "37000 1.1 0.09999999999985551\n",
      "37500 0.5 0.09999999999985551\n",
      "38000 1.2 0.09999999999985551\n",
      "38500 0.5 0.09999999999985551\n",
      "39000 0.7 0.09999999999985551\n",
      "39500 0.7 0.09999999999985551\n",
      "40000 1.1 0.09999999999985551\n",
      "40500 0.8 0.09999999999985551\n",
      "41000 0.4 0.09999999999985551\n",
      "41500 0.4 0.09999999999985551\n",
      "42000 1.1 0.09999999999985551\n",
      "42500 0.2 0.09999999999985551\n",
      "43000 0.4 0.09999999999985551\n",
      "43500 0.3 0.09999999999985551\n",
      "44000 1.3 0.09999999999985551\n",
      "44500 1.0 0.09999999999985551\n",
      "45000 0.6 0.09999999999985551\n",
      "45500 0.7 0.09999999999985551\n",
      "46000 0.4 0.09999999999985551\n",
      "46500 2.0 0.09999999999985551\n",
      "47000 0.7 0.09999999999985551\n",
      "47500 0.7 0.09999999999985551\n",
      "48000 0.4 0.09999999999985551\n",
      "48500 1.2 0.09999999999985551\n",
      "49000 1.1 0.09999999999985551\n",
      "49500 1.9 0.09999999999985551\n",
      "50000 1.9 0.09999999999985551\n",
      "Saved Model\n",
      "50500 0.6 0.09999999999985551\n",
      "51000 1.4 0.09999999999985551\n",
      "51500 1.5 0.09999999999985551\n",
      "52000 0.9 0.09999999999985551\n",
      "52500 1.4 0.09999999999985551\n",
      "53000 1.1 0.09999999999985551\n",
      "53500 1.9 0.09999999999985551\n",
      "54000 1.6 0.09999999999985551\n",
      "54500 1.2 0.09999999999985551\n",
      "55000 1.7 0.09999999999985551\n",
      "55500 1.5 0.09999999999985551\n",
      "56000 1.9 0.09999999999985551\n",
      "56500 1.9 0.09999999999985551\n",
      "57000 2.3 0.09999999999985551\n",
      "57500 1.0 0.09999999999985551\n",
      "58000 1.1 0.09999999999985551\n",
      "58500 2.0 0.09999999999985551\n",
      "59000 0.4 0.09999999999985551\n",
      "59500 1.8 0.09999999999985551\n",
      "60000 1.6 0.09999999999985551\n",
      "60500 1.6 0.09999999999985551\n",
      "61000 1.9 0.09999999999985551\n",
      "61500 1.1 0.09999999999985551\n",
      "62000 2.2 0.09999999999985551\n",
      "62500 0.3 0.09999999999985551\n",
      "63000 2.8 0.09999999999985551\n",
      "63500 2.6 0.09999999999985551\n",
      "64000 0.7 0.09999999999985551\n",
      "64500 3.2 0.09999999999985551\n",
      "65000 2.5 0.09999999999985551\n",
      "65500 2.6 0.09999999999985551\n",
      "66000 2.7 0.09999999999985551\n",
      "66500 3.3 0.09999999999985551\n",
      "67000 2.8 0.09999999999985551\n",
      "67500 2.7 0.09999999999985551\n",
      "68000 2.7 0.09999999999985551\n",
      "68500 2.8 0.09999999999985551\n",
      "69000 2.7 0.09999999999985551\n",
      "69500 2.5 0.09999999999985551\n",
      "70000 2.0 0.09999999999985551\n",
      "70500 3.0 0.09999999999985551\n",
      "71000 4.1 0.09999999999985551\n",
      "71500 2.7 0.09999999999985551\n",
      "72000 3.3 0.09999999999985551\n",
      "72500 3.6 0.09999999999985551\n",
      "73000 3.3 0.09999999999985551\n",
      "73500 1.3 0.09999999999985551\n",
      "74000 2.7 0.09999999999985551\n",
      "74500 3.7 0.09999999999985551\n",
      "75000 3.0 0.09999999999985551\n",
      "75500 2.4 0.09999999999985551\n",
      "76000 4.0 0.09999999999985551\n",
      "76500 3.3 0.09999999999985551\n",
      "77000 3.7 0.09999999999985551\n",
      "77500 3.3 0.09999999999985551\n",
      "78000 4.5 0.09999999999985551\n",
      "78500 5.4 0.09999999999985551\n",
      "79000 5.8 0.09999999999985551\n",
      "79500 6.1 0.09999999999985551\n",
      "80000 3.1 0.09999999999985551\n",
      "80500 2.9 0.09999999999985551\n",
      "81000 6.3 0.09999999999985551\n",
      "81500 4.0 0.09999999999985551\n",
      "82000 4.3 0.09999999999985551\n",
      "82500 6.8 0.09999999999985551\n",
      "83000 5.1 0.09999999999985551\n",
      "83500 5.5 0.09999999999985551\n",
      "84000 4.9 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84500 4.3 0.09999999999985551\n",
      "85000 7.5 0.09999999999985551\n",
      "85500 7.8 0.09999999999985551\n",
      "86000 7.5 0.09999999999985551\n",
      "86500 7.9 0.09999999999985551\n",
      "87000 6.1 0.09999999999985551\n",
      "87500 6.8 0.09999999999985551\n",
      "88000 6.4 0.09999999999985551\n",
      "88500 9.3 0.09999999999985551\n",
      "89000 7.2 0.09999999999985551\n",
      "89500 5.0 0.09999999999985551\n",
      "90000 10.0 0.09999999999985551\n",
      "90500 4.7 0.09999999999985551\n",
      "91000 9.2 0.09999999999985551\n",
      "91500 8.5 0.09999999999985551\n",
      "92000 6.8 0.09999999999985551\n",
      "92500 7.6 0.09999999999985551\n",
      "93000 6.2 0.09999999999985551\n",
      "93500 6.4 0.09999999999985551\n",
      "94000 9.3 0.09999999999985551\n",
      "94500 7.0 0.09999999999985551\n",
      "95000 6.6 0.09999999999985551\n",
      "95500 5.8 0.09999999999985551\n",
      "96000 7.9 0.09999999999985551\n",
      "96500 8.1 0.09999999999985551\n",
      "97000 9.4 0.09999999999985551\n",
      "97500 7.8 0.09999999999985551\n",
      "98000 9.6 0.09999999999985551\n",
      "98500 6.9 0.09999999999985551\n",
      "99000 9.5 0.09999999999985551\n",
      "99500 7.8 0.09999999999985551\n",
      "100000 7.4 0.09999999999985551\n",
      "Saved Model\n",
      "100500 7.3 0.09999999999985551\n",
      "101000 10.4 0.09999999999985551\n",
      "101500 9.3 0.09999999999985551\n",
      "102000 9.4 0.09999999999985551\n",
      "102500 7.6 0.09999999999985551\n",
      "103000 7.7 0.09999999999985551\n",
      "103500 8.0 0.09999999999985551\n",
      "104000 8.7 0.09999999999985551\n",
      "104500 8.8 0.09999999999985551\n",
      "105000 7.7 0.09999999999985551\n",
      "105500 10.4 0.09999999999985551\n",
      "106000 10.3 0.09999999999985551\n",
      "106500 6.5 0.09999999999985551\n",
      "107000 10.6 0.09999999999985551\n",
      "107500 9.9 0.09999999999985551\n",
      "108000 12.5 0.09999999999985551\n",
      "108500 10.2 0.09999999999985551\n",
      "109000 8.3 0.09999999999985551\n",
      "109500 8.9 0.09999999999985551\n",
      "110000 9.0 0.09999999999985551\n",
      "110500 10.5 0.09999999999985551\n",
      "111000 8.3 0.09999999999985551\n",
      "111500 9.2 0.09999999999985551\n",
      "112000 7.6 0.09999999999985551\n",
      "112500 7.2 0.09999999999985551\n",
      "113000 9.6 0.09999999999985551\n",
      "113500 7.0 0.09999999999985551\n",
      "114000 10.1 0.09999999999985551\n",
      "114500 10.8 0.09999999999985551\n",
      "115000 11.5 0.09999999999985551\n",
      "115500 11.7 0.09999999999985551\n",
      "116000 7.6 0.09999999999985551\n",
      "116500 12.2 0.09999999999985551\n",
      "117000 10.1 0.09999999999985551\n",
      "117500 8.0 0.09999999999985551\n",
      "118000 11.7 0.09999999999985551\n",
      "118500 11.2 0.09999999999985551\n",
      "119000 10.6 0.09999999999985551\n",
      "119500 7.7 0.09999999999985551\n",
      "120000 10.4 0.09999999999985551\n",
      "120500 9.9 0.09999999999985551\n",
      "121000 9.4 0.09999999999985551\n",
      "121500 8.8 0.09999999999985551\n",
      "122000 8.0 0.09999999999985551\n",
      "122500 11.1 0.09999999999985551\n",
      "123000 10.7 0.09999999999985551\n",
      "123500 7.8 0.09999999999985551\n",
      "124000 11.2 0.09999999999985551\n",
      "124500 8.7 0.09999999999985551\n",
      "125000 9.9 0.09999999999985551\n",
      "125500 9.4 0.09999999999985551\n",
      "126000 7.0 0.09999999999985551\n",
      "126500 6.5 0.09999999999985551\n",
      "127000 7.8 0.09999999999985551\n",
      "127500 7.4 0.09999999999985551\n",
      "128000 7.6 0.09999999999985551\n",
      "128500 11.9 0.09999999999985551\n",
      "129000 8.1 0.09999999999985551\n",
      "129500 11.3 0.09999999999985551\n",
      "130000 11.0 0.09999999999985551\n",
      "130500 10.1 0.09999999999985551\n",
      "131000 11.2 0.09999999999985551\n",
      "131500 8.2 0.09999999999985551\n",
      "132000 10.7 0.09999999999985551\n",
      "132500 8.9 0.09999999999985551\n",
      "133000 9.9 0.09999999999985551\n",
      "133500 11.3 0.09999999999985551\n",
      "134000 9.3 0.09999999999985551\n",
      "134500 7.6 0.09999999999985551\n",
      "135000 11.9 0.09999999999985551\n",
      "135500 11.4 0.09999999999985551\n",
      "136000 9.6 0.09999999999985551\n",
      "136500 10.2 0.09999999999985551\n",
      "137000 10.6 0.09999999999985551\n",
      "137500 7.4 0.09999999999985551\n",
      "138000 10.3 0.09999999999985551\n",
      "138500 9.5 0.09999999999985551\n",
      "139000 10.6 0.09999999999985551\n",
      "139500 10.2 0.09999999999985551\n",
      "140000 10.6 0.09999999999985551\n",
      "140500 9.6 0.09999999999985551\n",
      "141000 8.1 0.09999999999985551\n",
      "141500 9.4 0.09999999999985551\n",
      "142000 11.9 0.09999999999985551\n",
      "142500 12.0 0.09999999999985551\n",
      "143000 7.9 0.09999999999985551\n",
      "143500 11.6 0.09999999999985551\n",
      "144000 12.0 0.09999999999985551\n",
      "144500 12.8 0.09999999999985551\n",
      "145000 11.0 0.09999999999985551\n",
      "145500 10.9 0.09999999999985551\n",
      "146000 11.6 0.09999999999985551\n",
      "146500 13.6 0.09999999999985551\n",
      "147000 11.3 0.09999999999985551\n",
      "147500 12.2 0.09999999999985551\n",
      "148000 10.5 0.09999999999985551\n",
      "148500 11.6 0.09999999999985551\n",
      "149000 10.9 0.09999999999985551\n",
      "149500 13.2 0.09999999999985551\n",
      "150000 10.8 0.09999999999985551\n",
      "Saved Model\n",
      "150500 11.3 0.09999999999985551\n",
      "151000 10.3 0.09999999999985551\n",
      "151500 8.5 0.09999999999985551\n",
      "152000 9.2 0.09999999999985551\n",
      "152500 9.0 0.09999999999985551\n",
      "153000 10.8 0.09999999999985551\n",
      "153500 13.8 0.09999999999985551\n",
      "154000 12.7 0.09999999999985551\n",
      "154500 9.4 0.09999999999985551\n",
      "155000 8.3 0.09999999999985551\n",
      "155500 9.1 0.09999999999985551\n",
      "156000 9.8 0.09999999999985551\n",
      "156500 7.6 0.09999999999985551\n",
      "157000 13.2 0.09999999999985551\n",
      "157500 10.3 0.09999999999985551\n",
      "158000 12.9 0.09999999999985551\n",
      "158500 12.5 0.09999999999985551\n",
      "159000 11.5 0.09999999999985551\n",
      "159500 9.9 0.09999999999985551\n",
      "160000 11.4 0.09999999999985551\n",
      "160500 11.8 0.09999999999985551\n",
      "161000 11.5 0.09999999999985551\n",
      "161500 12.7 0.09999999999985551\n",
      "162000 13.4 0.09999999999985551\n",
      "162500 12.4 0.09999999999985551\n",
      "163000 15.4 0.09999999999985551\n",
      "163500 12.6 0.09999999999985551\n",
      "164000 7.9 0.09999999999985551\n",
      "164500 13.1 0.09999999999985551\n",
      "165000 10.4 0.09999999999985551\n",
      "165500 9.5 0.09999999999985551\n",
      "166000 13.0 0.09999999999985551\n",
      "166500 12.5 0.09999999999985551\n",
      "167000 13.1 0.09999999999985551\n",
      "167500 10.9 0.09999999999985551\n",
      "168000 14.0 0.09999999999985551\n",
      "168500 12.2 0.09999999999985551\n",
      "169000 10.7 0.09999999999985551\n",
      "169500 10.7 0.09999999999985551\n",
      "170000 10.1 0.09999999999985551\n",
      "170500 11.4 0.09999999999985551\n",
      "171000 13.3 0.09999999999985551\n",
      "171500 11.5 0.09999999999985551\n",
      "172000 9.8 0.09999999999985551\n",
      "172500 7.8 0.09999999999985551\n",
      "173000 11.9 0.09999999999985551\n",
      "173500 12.9 0.09999999999985551\n",
      "174000 13.5 0.09999999999985551\n",
      "174500 14.2 0.09999999999985551\n",
      "175000 10.5 0.09999999999985551\n",
      "175500 14.4 0.09999999999985551\n",
      "176000 10.1 0.09999999999985551\n",
      "176500 12.8 0.09999999999985551\n",
      "177000 12.9 0.09999999999985551\n",
      "177500 9.4 0.09999999999985551\n",
      "178000 11.0 0.09999999999985551\n",
      "178500 10.0 0.09999999999985551\n",
      "179000 10.2 0.09999999999985551\n",
      "179500 12.1 0.09999999999985551\n",
      "180000 9.3 0.09999999999985551\n",
      "180500 11.7 0.09999999999985551\n",
      "181000 14.7 0.09999999999985551\n",
      "181500 10.3 0.09999999999985551\n",
      "182000 9.6 0.09999999999985551\n",
      "182500 9.8 0.09999999999985551\n",
      "183000 11.6 0.09999999999985551\n",
      "183500 13.3 0.09999999999985551\n",
      "184000 13.1 0.09999999999985551\n",
      "184500 12.7 0.09999999999985551\n",
      "185000 9.8 0.09999999999985551\n",
      "185500 12.6 0.09999999999985551\n",
      "186000 12.6 0.09999999999985551\n",
      "186500 12.2 0.09999999999985551\n",
      "187000 13.8 0.09999999999985551\n",
      "187500 9.8 0.09999999999985551\n",
      "188000 13.9 0.09999999999985551\n",
      "188500 13.9 0.09999999999985551\n",
      "189000 10.4 0.09999999999985551\n",
      "189500 10.5 0.09999999999985551\n",
      "190000 11.7 0.09999999999985551\n",
      "190500 10.8 0.09999999999985551\n",
      "191000 13.5 0.09999999999985551\n",
      "191500 12.2 0.09999999999985551\n",
      "192000 11.9 0.09999999999985551\n",
      "192500 9.5 0.09999999999985551\n",
      "193000 12.8 0.09999999999985551\n",
      "193500 10.5 0.09999999999985551\n",
      "194000 13.3 0.09999999999985551\n",
      "194500 11.7 0.09999999999985551\n",
      "195000 10.4 0.09999999999985551\n",
      "195500 10.2 0.09999999999985551\n",
      "196000 11.4 0.09999999999985551\n",
      "196500 11.2 0.09999999999985551\n",
      "197000 13.8 0.09999999999985551\n",
      "197500 11.1 0.09999999999985551\n",
      "198000 10.8 0.09999999999985551\n",
      "198500 13.6 0.09999999999985551\n",
      "199000 13.1 0.09999999999985551\n",
      "199500 13.1 0.09999999999985551\n",
      "200000 11.4 0.09999999999985551\n",
      "Saved Model\n",
      "200500 9.2 0.09999999999985551\n",
      "201000 12.2 0.09999999999985551\n",
      "201500 11.3 0.09999999999985551\n",
      "202000 13.9 0.09999999999985551\n",
      "202500 13.5 0.09999999999985551\n",
      "203000 12.4 0.09999999999985551\n",
      "203500 10.7 0.09999999999985551\n",
      "204000 9.8 0.09999999999985551\n",
      "204500 12.7 0.09999999999985551\n",
      "205000 10.8 0.09999999999985551\n",
      "205500 10.8 0.09999999999985551\n",
      "206000 11.4 0.09999999999985551\n",
      "206500 12.0 0.09999999999985551\n",
      "207000 11.8 0.09999999999985551\n",
      "207500 9.8 0.09999999999985551\n",
      "208000 12.9 0.09999999999985551\n",
      "208500 10.9 0.09999999999985551\n",
      "209000 13.9 0.09999999999985551\n",
      "209500 11.3 0.09999999999985551\n",
      "210000 12.9 0.09999999999985551\n",
      "210500 11.9 0.09999999999985551\n",
      "211000 11.0 0.09999999999985551\n",
      "211500 12.4 0.09999999999985551\n",
      "212000 11.9 0.09999999999985551\n",
      "212500 11.3 0.09999999999985551\n",
      "213000 11.9 0.09999999999985551\n",
      "213500 8.6 0.09999999999985551\n",
      "214000 10.5 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214500 11.8 0.09999999999985551\n",
      "215000 12.1 0.09999999999985551\n",
      "215500 14.9 0.09999999999985551\n",
      "216000 10.1 0.09999999999985551\n",
      "216500 12.5 0.09999999999985551\n",
      "217000 14.5 0.09999999999985551\n",
      "217500 13.8 0.09999999999985551\n",
      "218000 10.4 0.09999999999985551\n",
      "218500 13.3 0.09999999999985551\n",
      "219000 13.9 0.09999999999985551\n",
      "219500 9.5 0.09999999999985551\n",
      "220000 12.3 0.09999999999985551\n",
      "220500 10.7 0.09999999999985551\n",
      "221000 11.5 0.09999999999985551\n",
      "221500 12.1 0.09999999999985551\n",
      "222000 12.1 0.09999999999985551\n",
      "222500 13.1 0.09999999999985551\n",
      "223000 10.0 0.09999999999985551\n",
      "223500 11.4 0.09999999999985551\n",
      "224000 11.7 0.09999999999985551\n",
      "224500 13.4 0.09999999999985551\n",
      "225000 11.1 0.09999999999985551\n",
      "225500 12.3 0.09999999999985551\n",
      "226000 10.4 0.09999999999985551\n",
      "226500 11.3 0.09999999999985551\n",
      "227000 12.0 0.09999999999985551\n",
      "227500 13.7 0.09999999999985551\n",
      "228000 9.7 0.09999999999985551\n",
      "228500 12.6 0.09999999999985551\n",
      "229000 10.7 0.09999999999985551\n",
      "229500 11.6 0.09999999999985551\n",
      "230000 11.7 0.09999999999985551\n",
      "230500 12.6 0.09999999999985551\n",
      "231000 10.1 0.09999999999985551\n",
      "231500 10.6 0.09999999999985551\n",
      "232000 10.6 0.09999999999985551\n",
      "232500 12.7 0.09999999999985551\n",
      "233000 10.0 0.09999999999985551\n",
      "233500 12.1 0.09999999999985551\n",
      "234000 11.8 0.09999999999985551\n",
      "234500 10.8 0.09999999999985551\n",
      "235000 11.1 0.09999999999985551\n",
      "235500 11.5 0.09999999999985551\n",
      "236000 11.4 0.09999999999985551\n",
      "236500 9.9 0.09999999999985551\n",
      "237000 10.1 0.09999999999985551\n",
      "237500 11.6 0.09999999999985551\n",
      "238000 11.3 0.09999999999985551\n",
      "238500 12.2 0.09999999999985551\n",
      "239000 13.8 0.09999999999985551\n",
      "239500 12.2 0.09999999999985551\n",
      "240000 11.5 0.09999999999985551\n",
      "240500 11.9 0.09999999999985551\n",
      "241000 13.6 0.09999999999985551\n",
      "241500 11.5 0.09999999999985551\n",
      "242000 11.9 0.09999999999985551\n",
      "242500 12.3 0.09999999999985551\n",
      "243000 15.0 0.09999999999985551\n",
      "243500 13.3 0.09999999999985551\n",
      "244000 14.3 0.09999999999985551\n",
      "244500 12.8 0.09999999999985551\n",
      "245000 10.9 0.09999999999985551\n",
      "245500 11.6 0.09999999999985551\n",
      "246000 8.7 0.09999999999985551\n",
      "246500 12.5 0.09999999999985551\n",
      "247000 13.0 0.09999999999985551\n",
      "247500 11.9 0.09999999999985551\n",
      "248000 13.1 0.09999999999985551\n",
      "248500 15.8 0.09999999999985551\n",
      "249000 12.8 0.09999999999985551\n",
      "249500 10.1 0.09999999999985551\n",
      "250000 10.8 0.09999999999985551\n",
      "WARNING:tensorflow:From /home/fora/anaconda3/envs/RL_test/lib/python3.6/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Saved Model\n",
      "250500 15.6 0.09999999999985551\n",
      "251000 10.7 0.09999999999985551\n",
      "251500 10.6 0.09999999999985551\n",
      "252000 9.3 0.09999999999985551\n",
      "252500 12.1 0.09999999999985551\n",
      "253000 11.4 0.09999999999985551\n",
      "253500 11.6 0.09999999999985551\n",
      "254000 13.8 0.09999999999985551\n",
      "254500 17.2 0.09999999999985551\n",
      "255000 14.2 0.09999999999985551\n",
      "255500 10.8 0.09999999999985551\n",
      "256000 12.4 0.09999999999985551\n",
      "256500 10.6 0.09999999999985551\n",
      "257000 12.6 0.09999999999985551\n",
      "257500 13.2 0.09999999999985551\n",
      "258000 9.4 0.09999999999985551\n",
      "258500 6.6 0.09999999999985551\n",
      "259000 9.7 0.09999999999985551\n",
      "259500 11.4 0.09999999999985551\n",
      "260000 12.3 0.09999999999985551\n",
      "260500 12.4 0.09999999999985551\n",
      "261000 10.5 0.09999999999985551\n",
      "261500 14.6 0.09999999999985551\n",
      "262000 11.8 0.09999999999985551\n",
      "262500 12.1 0.09999999999985551\n",
      "263000 15.0 0.09999999999985551\n",
      "263500 12.7 0.09999999999985551\n",
      "264000 10.0 0.09999999999985551\n",
      "264500 13.6 0.09999999999985551\n",
      "265000 13.8 0.09999999999985551\n",
      "265500 8.6 0.09999999999985551\n",
      "266000 14.7 0.09999999999985551\n",
      "266500 14.2 0.09999999999985551\n",
      "267000 11.1 0.09999999999985551\n",
      "267500 9.5 0.09999999999985551\n",
      "268000 10.1 0.09999999999985551\n",
      "268500 11.0 0.09999999999985551\n",
      "269000 14.5 0.09999999999985551\n",
      "269500 10.2 0.09999999999985551\n",
      "270000 16.0 0.09999999999985551\n",
      "270500 14.6 0.09999999999985551\n",
      "271000 12.0 0.09999999999985551\n",
      "271500 12.4 0.09999999999985551\n",
      "272000 12.3 0.09999999999985551\n",
      "272500 12.3 0.09999999999985551\n",
      "273000 7.5 0.09999999999985551\n",
      "273500 12.3 0.09999999999985551\n",
      "274000 12.5 0.09999999999985551\n",
      "274500 9.1 0.09999999999985551\n",
      "275000 12.0 0.09999999999985551\n",
      "275500 10.8 0.09999999999985551\n",
      "276000 13.8 0.09999999999985551\n",
      "276500 11.5 0.09999999999985551\n",
      "277000 9.8 0.09999999999985551\n",
      "277500 8.7 0.09999999999985551\n",
      "278000 10.5 0.09999999999985551\n",
      "278500 13.3 0.09999999999985551\n",
      "279000 12.8 0.09999999999985551\n",
      "279500 10.5 0.09999999999985551\n",
      "280000 14.0 0.09999999999985551\n",
      "280500 12.5 0.09999999999985551\n",
      "281000 10.7 0.09999999999985551\n",
      "281500 11.1 0.09999999999985551\n",
      "282000 9.2 0.09999999999985551\n",
      "282500 9.1 0.09999999999985551\n",
      "283000 13.3 0.09999999999985551\n",
      "283500 10.5 0.09999999999985551\n",
      "284000 11.6 0.09999999999985551\n",
      "284500 13.5 0.09999999999985551\n",
      "285000 10.8 0.09999999999985551\n",
      "285500 12.8 0.09999999999985551\n",
      "286000 13.1 0.09999999999985551\n",
      "286500 14.1 0.09999999999985551\n",
      "287000 14.0 0.09999999999985551\n",
      "287500 10.8 0.09999999999985551\n",
      "288000 12.7 0.09999999999985551\n",
      "288500 14.5 0.09999999999985551\n",
      "289000 15.7 0.09999999999985551\n",
      "289500 13.5 0.09999999999985551\n",
      "290000 12.9 0.09999999999985551\n",
      "290500 13.0 0.09999999999985551\n",
      "291000 9.5 0.09999999999985551\n",
      "291500 13.3 0.09999999999985551\n",
      "292000 12.7 0.09999999999985551\n",
      "292500 11.6 0.09999999999985551\n",
      "293000 12.0 0.09999999999985551\n",
      "293500 9.8 0.09999999999985551\n",
      "294000 8.4 0.09999999999985551\n",
      "294500 12.7 0.09999999999985551\n",
      "295000 14.7 0.09999999999985551\n",
      "295500 12.6 0.09999999999985551\n",
      "296000 13.4 0.09999999999985551\n",
      "296500 14.0 0.09999999999985551\n",
      "297000 14.7 0.09999999999985551\n",
      "297500 12.9 0.09999999999985551\n",
      "298000 15.3 0.09999999999985551\n",
      "298500 13.3 0.09999999999985551\n",
      "299000 12.8 0.09999999999985551\n",
      "299500 9.3 0.09999999999985551\n",
      "300000 12.7 0.09999999999985551\n",
      "Saved Model\n",
      "300500 14.4 0.09999999999985551\n",
      "301000 10.0 0.09999999999985551\n",
      "301500 11.8 0.09999999999985551\n",
      "302000 15.3 0.09999999999985551\n",
      "302500 12.6 0.09999999999985551\n",
      "303000 14.0 0.09999999999985551\n",
      "303500 13.7 0.09999999999985551\n",
      "304000 10.5 0.09999999999985551\n",
      "304500 11.3 0.09999999999985551\n",
      "305000 13.2 0.09999999999985551\n",
      "305500 11.5 0.09999999999985551\n",
      "306000 11.9 0.09999999999985551\n",
      "306500 13.1 0.09999999999985551\n",
      "307000 13.6 0.09999999999985551\n",
      "307500 13.2 0.09999999999985551\n",
      "308000 11.6 0.09999999999985551\n",
      "308500 12.0 0.09999999999985551\n",
      "309000 12.4 0.09999999999985551\n",
      "309500 13.5 0.09999999999985551\n",
      "310000 10.8 0.09999999999985551\n",
      "310500 9.6 0.09999999999985551\n",
      "311000 12.0 0.09999999999985551\n",
      "311500 11.5 0.09999999999985551\n",
      "312000 14.3 0.09999999999985551\n",
      "312500 16.4 0.09999999999985551\n",
      "313000 12.8 0.09999999999985551\n",
      "313500 14.7 0.09999999999985551\n",
      "314000 11.9 0.09999999999985551\n",
      "314500 11.7 0.09999999999985551\n",
      "315000 14.7 0.09999999999985551\n",
      "315500 13.4 0.09999999999985551\n",
      "316000 11.9 0.09999999999985551\n",
      "316500 9.3 0.09999999999985551\n",
      "317000 13.0 0.09999999999985551\n",
      "317500 8.3 0.09999999999985551\n",
      "318000 11.8 0.09999999999985551\n",
      "318500 14.7 0.09999999999985551\n",
      "319000 12.1 0.09999999999985551\n",
      "319500 11.1 0.09999999999985551\n",
      "320000 11.3 0.09999999999985551\n",
      "320500 11.7 0.09999999999985551\n",
      "321000 14.1 0.09999999999985551\n",
      "321500 11.0 0.09999999999985551\n",
      "322000 14.3 0.09999999999985551\n",
      "322500 8.6 0.09999999999985551\n",
      "323000 11.8 0.09999999999985551\n",
      "323500 14.1 0.09999999999985551\n",
      "324000 12.1 0.09999999999985551\n",
      "324500 12.7 0.09999999999985551\n",
      "325000 12.9 0.09999999999985551\n",
      "325500 14.2 0.09999999999985551\n",
      "326000 14.1 0.09999999999985551\n",
      "326500 12.8 0.09999999999985551\n",
      "327000 11.5 0.09999999999985551\n",
      "327500 12.1 0.09999999999985551\n",
      "328000 14.7 0.09999999999985551\n",
      "328500 11.2 0.09999999999985551\n",
      "329000 13.4 0.09999999999985551\n",
      "329500 14.5 0.09999999999985551\n",
      "330000 13.5 0.09999999999985551\n",
      "330500 12.2 0.09999999999985551\n",
      "331000 13.9 0.09999999999985551\n",
      "331500 15.1 0.09999999999985551\n",
      "332000 14.2 0.09999999999985551\n",
      "332500 13.2 0.09999999999985551\n",
      "333000 13.7 0.09999999999985551\n",
      "333500 14.9 0.09999999999985551\n",
      "334000 11.7 0.09999999999985551\n",
      "334500 11.8 0.09999999999985551\n",
      "335000 11.9 0.09999999999985551\n",
      "335500 11.1 0.09999999999985551\n",
      "336000 12.4 0.09999999999985551\n",
      "336500 9.5 0.09999999999985551\n",
      "337000 14.6 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337500 12.9 0.09999999999985551\n",
      "338000 11.2 0.09999999999985551\n",
      "338500 12.4 0.09999999999985551\n",
      "339000 16.4 0.09999999999985551\n",
      "339500 12.4 0.09999999999985551\n",
      "340000 14.6 0.09999999999985551\n",
      "340500 11.2 0.09999999999985551\n",
      "341000 13.8 0.09999999999985551\n",
      "341500 10.4 0.09999999999985551\n",
      "342000 11.6 0.09999999999985551\n",
      "342500 9.6 0.09999999999985551\n",
      "343000 12.9 0.09999999999985551\n",
      "343500 14.6 0.09999999999985551\n",
      "344000 11.0 0.09999999999985551\n",
      "344500 14.0 0.09999999999985551\n",
      "345000 11.3 0.09999999999985551\n",
      "345500 14.5 0.09999999999985551\n",
      "346000 11.9 0.09999999999985551\n",
      "346500 13.2 0.09999999999985551\n",
      "347000 12.0 0.09999999999985551\n",
      "347500 9.9 0.09999999999985551\n",
      "348000 12.5 0.09999999999985551\n",
      "348500 10.1 0.09999999999985551\n",
      "349000 12.1 0.09999999999985551\n",
      "349500 9.7 0.09999999999985551\n",
      "350000 10.7 0.09999999999985551\n",
      "Saved Model\n",
      "350500 15.5 0.09999999999985551\n",
      "351000 14.9 0.09999999999985551\n",
      "351500 11.1 0.09999999999985551\n",
      "352000 16.5 0.09999999999985551\n",
      "352500 12.4 0.09999999999985551\n",
      "353000 10.4 0.09999999999985551\n",
      "353500 12.5 0.09999999999985551\n",
      "354000 14.7 0.09999999999985551\n",
      "354500 12.5 0.09999999999985551\n",
      "355000 11.5 0.09999999999985551\n",
      "355500 13.5 0.09999999999985551\n",
      "356000 13.3 0.09999999999985551\n",
      "356500 10.0 0.09999999999985551\n",
      "357000 15.1 0.09999999999985551\n",
      "357500 11.6 0.09999999999985551\n",
      "358000 9.1 0.09999999999985551\n",
      "358500 10.9 0.09999999999985551\n",
      "359000 13.9 0.09999999999985551\n",
      "359500 13.5 0.09999999999985551\n",
      "360000 14.4 0.09999999999985551\n",
      "360500 9.4 0.09999999999985551\n",
      "361000 12.6 0.09999999999985551\n",
      "361500 13.7 0.09999999999985551\n",
      "362000 12.8 0.09999999999985551\n",
      "362500 15.3 0.09999999999985551\n",
      "363000 11.0 0.09999999999985551\n",
      "363500 10.0 0.09999999999985551\n",
      "364000 11.1 0.09999999999985551\n",
      "364500 13.4 0.09999999999985551\n",
      "365000 9.5 0.09999999999985551\n",
      "365500 13.0 0.09999999999985551\n",
      "366000 12.1 0.09999999999985551\n",
      "366500 12.9 0.09999999999985551\n",
      "367000 11.9 0.09999999999985551\n",
      "367500 13.7 0.09999999999985551\n",
      "368000 14.7 0.09999999999985551\n",
      "368500 15.7 0.09999999999985551\n",
      "369000 15.9 0.09999999999985551\n",
      "369500 13.7 0.09999999999985551\n",
      "370000 11.4 0.09999999999985551\n",
      "370500 9.8 0.09999999999985551\n",
      "371000 14.5 0.09999999999985551\n",
      "371500 13.6 0.09999999999985551\n",
      "372000 12.0 0.09999999999985551\n",
      "372500 11.5 0.09999999999985551\n",
      "373000 14.9 0.09999999999985551\n",
      "373500 13.1 0.09999999999985551\n",
      "374000 10.5 0.09999999999985551\n",
      "374500 15.3 0.09999999999985551\n",
      "375000 11.1 0.09999999999985551\n",
      "375500 14.0 0.09999999999985551\n",
      "376000 11.2 0.09999999999985551\n",
      "376500 10.9 0.09999999999985551\n",
      "377000 12.6 0.09999999999985551\n",
      "377500 12.8 0.09999999999985551\n",
      "378000 12.7 0.09999999999985551\n",
      "378500 12.4 0.09999999999985551\n",
      "379000 16.1 0.09999999999985551\n",
      "379500 13.1 0.09999999999985551\n",
      "380000 10.4 0.09999999999985551\n",
      "380500 14.5 0.09999999999985551\n",
      "381000 9.7 0.09999999999985551\n",
      "381500 12.7 0.09999999999985551\n",
      "382000 14.4 0.09999999999985551\n",
      "382500 11.6 0.09999999999985551\n",
      "383000 9.4 0.09999999999985551\n",
      "383500 13.2 0.09999999999985551\n",
      "384000 16.6 0.09999999999985551\n",
      "384500 13.1 0.09999999999985551\n",
      "385000 11.8 0.09999999999985551\n",
      "385500 13.7 0.09999999999985551\n",
      "386000 10.7 0.09999999999985551\n",
      "386500 13.6 0.09999999999985551\n",
      "387000 10.3 0.09999999999985551\n",
      "387500 12.6 0.09999999999985551\n",
      "388000 11.0 0.09999999999985551\n",
      "388500 14.0 0.09999999999985551\n",
      "389000 12.7 0.09999999999985551\n",
      "389500 14.0 0.09999999999985551\n",
      "390000 13.4 0.09999999999985551\n",
      "390500 14.3 0.09999999999985551\n",
      "391000 12.1 0.09999999999985551\n",
      "391500 10.9 0.09999999999985551\n",
      "392000 10.2 0.09999999999985551\n",
      "392500 11.3 0.09999999999985551\n",
      "393000 9.2 0.09999999999985551\n",
      "393500 13.8 0.09999999999985551\n",
      "394000 12.2 0.09999999999985551\n",
      "394500 13.4 0.09999999999985551\n",
      "395000 14.9 0.09999999999985551\n",
      "395500 13.5 0.09999999999985551\n",
      "396000 10.0 0.09999999999985551\n",
      "396500 15.0 0.09999999999985551\n",
      "397000 13.7 0.09999999999985551\n",
      "397500 15.6 0.09999999999985551\n",
      "398000 13.8 0.09999999999985551\n",
      "398500 13.2 0.09999999999985551\n",
      "399000 14.2 0.09999999999985551\n",
      "399500 12.1 0.09999999999985551\n",
      "400000 10.6 0.09999999999985551\n",
      "Saved Model\n",
      "400500 13.6 0.09999999999985551\n",
      "401000 11.2 0.09999999999985551\n",
      "401500 13.1 0.09999999999985551\n",
      "402000 12.8 0.09999999999985551\n",
      "402500 11.4 0.09999999999985551\n",
      "403000 13.1 0.09999999999985551\n",
      "403500 13.2 0.09999999999985551\n",
      "404000 11.6 0.09999999999985551\n",
      "404500 13.2 0.09999999999985551\n",
      "405000 9.7 0.09999999999985551\n",
      "405500 14.4 0.09999999999985551\n",
      "406000 11.8 0.09999999999985551\n",
      "406500 11.7 0.09999999999985551\n",
      "407000 14.7 0.09999999999985551\n",
      "407500 11.8 0.09999999999985551\n",
      "408000 14.0 0.09999999999985551\n",
      "408500 10.9 0.09999999999985551\n",
      "409000 11.0 0.09999999999985551\n",
      "409500 11.7 0.09999999999985551\n",
      "410000 12.9 0.09999999999985551\n",
      "410500 11.9 0.09999999999985551\n",
      "411000 15.1 0.09999999999985551\n",
      "411500 10.5 0.09999999999985551\n",
      "412000 13.0 0.09999999999985551\n",
      "412500 13.2 0.09999999999985551\n",
      "413000 13.8 0.09999999999985551\n",
      "413500 13.3 0.09999999999985551\n",
      "414000 14.5 0.09999999999985551\n",
      "414500 14.3 0.09999999999985551\n",
      "415000 12.6 0.09999999999985551\n",
      "415500 12.0 0.09999999999985551\n",
      "416000 8.7 0.09999999999985551\n",
      "416500 12.3 0.09999999999985551\n",
      "417000 14.5 0.09999999999985551\n",
      "417500 14.8 0.09999999999985551\n",
      "418000 13.4 0.09999999999985551\n",
      "418500 12.0 0.09999999999985551\n",
      "419000 11.1 0.09999999999985551\n",
      "419500 12.8 0.09999999999985551\n",
      "420000 12.3 0.09999999999985551\n",
      "420500 12.3 0.09999999999985551\n",
      "421000 14.6 0.09999999999985551\n",
      "421500 13.5 0.09999999999985551\n",
      "422000 12.3 0.09999999999985551\n",
      "422500 10.8 0.09999999999985551\n",
      "423000 12.7 0.09999999999985551\n",
      "423500 10.7 0.09999999999985551\n",
      "424000 12.7 0.09999999999985551\n",
      "424500 9.9 0.09999999999985551\n",
      "425000 14.9 0.09999999999985551\n",
      "425500 12.4 0.09999999999985551\n",
      "426000 10.9 0.09999999999985551\n",
      "426500 11.7 0.09999999999985551\n",
      "427000 12.3 0.09999999999985551\n",
      "427500 14.2 0.09999999999985551\n",
      "428000 13.8 0.09999999999985551\n",
      "428500 9.4 0.09999999999985551\n",
      "429000 13.7 0.09999999999985551\n",
      "429500 12.9 0.09999999999985551\n",
      "430000 11.7 0.09999999999985551\n",
      "430500 13.7 0.09999999999985551\n",
      "431000 13.6 0.09999999999985551\n",
      "431500 12.4 0.09999999999985551\n",
      "432000 12.8 0.09999999999985551\n",
      "432500 11.7 0.09999999999985551\n",
      "433000 9.9 0.09999999999985551\n",
      "433500 15.7 0.09999999999985551\n",
      "434000 14.1 0.09999999999985551\n",
      "434500 13.2 0.09999999999985551\n",
      "435000 12.1 0.09999999999985551\n",
      "435500 13.9 0.09999999999985551\n",
      "436000 15.2 0.09999999999985551\n",
      "436500 12.7 0.09999999999985551\n",
      "437000 14.2 0.09999999999985551\n",
      "437500 10.8 0.09999999999985551\n",
      "438000 14.3 0.09999999999985551\n",
      "438500 14.3 0.09999999999985551\n",
      "439000 12.0 0.09999999999985551\n",
      "439500 10.3 0.09999999999985551\n",
      "440000 13.1 0.09999999999985551\n",
      "440500 11.5 0.09999999999985551\n",
      "441000 14.2 0.09999999999985551\n",
      "441500 10.5 0.09999999999985551\n",
      "442000 14.4 0.09999999999985551\n",
      "442500 10.2 0.09999999999985551\n",
      "443000 13.5 0.09999999999985551\n",
      "443500 12.3 0.09999999999985551\n",
      "444000 11.9 0.09999999999985551\n",
      "444500 12.6 0.09999999999985551\n",
      "445000 16.0 0.09999999999985551\n",
      "445500 12.3 0.09999999999985551\n",
      "446000 14.7 0.09999999999985551\n",
      "446500 11.9 0.09999999999985551\n",
      "447000 10.7 0.09999999999985551\n",
      "447500 16.5 0.09999999999985551\n",
      "448000 12.2 0.09999999999985551\n",
      "448500 11.6 0.09999999999985551\n",
      "449000 11.4 0.09999999999985551\n",
      "449500 10.8 0.09999999999985551\n",
      "450000 13.0 0.09999999999985551\n",
      "Saved Model\n",
      "450500 13.0 0.09999999999985551\n",
      "451000 14.0 0.09999999999985551\n",
      "451500 11.2 0.09999999999985551\n",
      "452000 15.0 0.09999999999985551\n",
      "452500 11.9 0.09999999999985551\n",
      "453000 10.6 0.09999999999985551\n",
      "453500 12.0 0.09999999999985551\n",
      "454000 13.8 0.09999999999985551\n",
      "454500 14.3 0.09999999999985551\n",
      "455000 15.6 0.09999999999985551\n",
      "455500 10.0 0.09999999999985551\n",
      "456000 11.3 0.09999999999985551\n",
      "456500 15.4 0.09999999999985551\n",
      "457000 9.5 0.09999999999985551\n",
      "457500 11.7 0.09999999999985551\n",
      "458000 13.2 0.09999999999985551\n",
      "458500 13.3 0.09999999999985551\n",
      "459000 13.9 0.09999999999985551\n",
      "459500 11.7 0.09999999999985551\n",
      "460000 11.0 0.09999999999985551\n",
      "460500 11.5 0.09999999999985551\n",
      "461000 16.3 0.09999999999985551\n",
      "461500 11.4 0.09999999999985551\n",
      "462000 13.9 0.09999999999985551\n",
      "462500 14.9 0.09999999999985551\n",
      "463000 10.9 0.09999999999985551\n",
      "463500 16.7 0.09999999999985551\n",
      "464000 11.3 0.09999999999985551\n",
      "464500 14.0 0.09999999999985551\n",
      "465000 14.1 0.09999999999985551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465500 14.0 0.09999999999985551\n",
      "466000 12.9 0.09999999999985551\n",
      "466500 16.3 0.09999999999985551\n",
      "467000 13.4 0.09999999999985551\n",
      "467500 13.7 0.09999999999985551\n",
      "468000 12.7 0.09999999999985551\n",
      "468500 10.0 0.09999999999985551\n",
      "469000 14.6 0.09999999999985551\n",
      "469500 13.2 0.09999999999985551\n",
      "470000 14.1 0.09999999999985551\n",
      "470500 10.7 0.09999999999985551\n",
      "471000 11.7 0.09999999999985551\n",
      "471500 13.5 0.09999999999985551\n",
      "472000 15.3 0.09999999999985551\n",
      "472500 14.9 0.09999999999985551\n",
      "473000 12.6 0.09999999999985551\n",
      "473500 14.6 0.09999999999985551\n",
      "474000 14.4 0.09999999999985551\n",
      "474500 11.3 0.09999999999985551\n",
      "475000 12.7 0.09999999999985551\n",
      "475500 16.9 0.09999999999985551\n",
      "476000 11.6 0.09999999999985551\n",
      "476500 11.2 0.09999999999985551\n",
      "477000 12.1 0.09999999999985551\n",
      "477500 15.7 0.09999999999985551\n",
      "478000 13.3 0.09999999999985551\n",
      "478500 12.9 0.09999999999985551\n",
      "479000 12.1 0.09999999999985551\n",
      "479500 14.5 0.09999999999985551\n",
      "480000 12.3 0.09999999999985551\n",
      "480500 16.4 0.09999999999985551\n",
      "481000 15.5 0.09999999999985551\n",
      "481500 12.9 0.09999999999985551\n",
      "482000 15.2 0.09999999999985551\n",
      "482500 15.4 0.09999999999985551\n",
      "483000 11.6 0.09999999999985551\n",
      "483500 14.1 0.09999999999985551\n",
      "484000 13.8 0.09999999999985551\n",
      "484500 13.9 0.09999999999985551\n",
      "485000 10.3 0.09999999999985551\n",
      "485500 12.9 0.09999999999985551\n",
      "486000 11.0 0.09999999999985551\n",
      "486500 12.7 0.09999999999985551\n",
      "487000 13.3 0.09999999999985551\n",
      "487500 15.7 0.09999999999985551\n",
      "488000 13.6 0.09999999999985551\n",
      "488500 12.9 0.09999999999985551\n",
      "489000 14.3 0.09999999999985551\n",
      "489500 14.2 0.09999999999985551\n",
      "490000 12.7 0.09999999999985551\n",
      "490500 11.6 0.09999999999985551\n",
      "491000 14.9 0.09999999999985551\n",
      "491500 13.3 0.09999999999985551\n",
      "492000 13.3 0.09999999999985551\n",
      "492500 14.8 0.09999999999985551\n",
      "493000 11.1 0.09999999999985551\n",
      "493500 13.6 0.09999999999985551\n",
      "494000 14.4 0.09999999999985551\n",
      "494500 13.1 0.09999999999985551\n",
      "495000 13.5 0.09999999999985551\n",
      "495500 11.0 0.09999999999985551\n",
      "496000 13.1 0.09999999999985551\n",
      "496500 10.9 0.09999999999985551\n",
      "497000 13.3 0.09999999999985551\n",
      "497500 12.8 0.09999999999985551\n",
      "498000 12.5 0.09999999999985551\n",
      "498500 14.8 0.09999999999985551\n",
      "499000 11.9 0.09999999999985551\n",
      "499500 14.5 0.09999999999985551\n",
      "500000 14.0 0.09999999999985551\n",
      "Percent of succesful episodes: 10.1218%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(h_size)\n",
    "targetQN = Qnetwork(h_size)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/annealing_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0,4)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d = env.step(a)\n",
    "            s1 = processState(s1)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1cf4099eb8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
    "rMean = np.average(rMat,1)\n",
    "plt.plot(rMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
